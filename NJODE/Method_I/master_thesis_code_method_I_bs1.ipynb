{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSusx7dSpn-5"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43hk8wXUpeT-",
        "outputId": "edc8a489-df46-4e2e-c1d1-07e2ffd3d407"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting iisignature\n",
            "  Downloading iisignature-0.24.tar.gz (1.3 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/1.3 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>1.7 in /usr/local/lib/python3.11/dist-packages (from iisignature) (2.0.2)\n",
            "Building wheels for collected packages: iisignature\n",
            "  Building wheel for iisignature (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iisignature: filename=iisignature-0.24-cp311-cp311-linux_x86_64.whl size=3246077 sha256=00bdd448538b79eb50200dcdc5ac27ddbfd0120e56f1b142fd66c6250eab5fff\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/f4/57/0b4d3787a07f20a3cd1a91835d6247f55ef899345267bcd6df\n",
            "Successfully built iisignature\n",
            "Installing collected packages: iisignature\n",
            "Successfully installed iisignature-0.24\n"
          ]
        }
      ],
      "source": [
        "# imports\n",
        "import numpy as np\n",
        "import json, os, time, sys\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "import copy\n",
        "import pandas as pd\n",
        "from absl import app\n",
        "from absl import flags\n",
        "from zipfile import ZipFile\n",
        "\n",
        "import torch\n",
        "import sklearn\n",
        "import scipy.linalg\n",
        "%pip install iisignature\n",
        "import iisignature as sig\n",
        "import warnings\n",
        "\n",
        "from typing import List\n",
        "import torch.nn as nn\n",
        "import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import socket\n",
        "import matplotlib\n",
        "import matplotlib.colors\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.backends import cudnn\n",
        "import gc\n",
        "import scipy.stats as stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYtrpyukptd4"
      },
      "source": [
        "# Data Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBrFWx5ups22"
      },
      "outputs": [],
      "source": [
        "# utility functions\n",
        "def makedirs(dirname):\n",
        "    if not os.path.exists(dirname):\n",
        "        os.makedirs(dirname)\n",
        "\n",
        "def compute_loss(X_obs, Y_obs, Y_obs_bj, n_obs_ot, batch_size, eps=1e-10,\n",
        "                 weight=0.5, M_obs=None, which_loss=\"easy\"):\n",
        "    \"\"\"\n",
        "    compute the loss of the true conditional expectation, as in\n",
        "    model.compute_loss\n",
        "    \"\"\"\n",
        "    loss_fun = LOSS_FUN_DICT[which_loss]\n",
        "    if M_obs is not None:\n",
        "        M_obs = torch.from_numpy(M_obs)\n",
        "    loss = loss_fun(\n",
        "        X_obs=torch.from_numpy(X_obs),\n",
        "        Y_obs=torch.from_numpy(Y_obs),\n",
        "        Y_obs_bj=torch.from_numpy(Y_obs_bj),\n",
        "        n_obs_ot=torch.from_numpy(n_obs_ot),\n",
        "        batch_size=batch_size, eps=eps, weight=weight,\n",
        "        M_obs=M_obs).detach().numpy()\n",
        "    return loss\n",
        "\n",
        "# synthetic datasets:\n",
        "#   this is only a small collection of the available datasets.\n",
        "#   more can be found in the git repo.\n",
        "class StockModel:\n",
        "    \"\"\"\n",
        "    mother class for all stock models defining the variables and methods shared\n",
        "    amongst all of them, some need to be defined individually\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, drift, volatility, S0, nb_paths, nb_steps,\n",
        "                 maturity, sine_coeff, **kwargs):\n",
        "        self.drift = drift\n",
        "        self.volatility = volatility\n",
        "        self.S0 = S0\n",
        "        self.nb_paths = nb_paths\n",
        "        self.nb_steps = nb_steps\n",
        "        self.maturity = maturity\n",
        "        self.dt = maturity / nb_steps\n",
        "        self.dimensions = np.size(S0)\n",
        "        if sine_coeff is None:\n",
        "            self.periodic_coeff = lambda t: 1\n",
        "        else:\n",
        "            self.periodic_coeff = lambda t: (1 + np.sin(sine_coeff * t))\n",
        "        self.loss = None\n",
        "        self.path_t = None\n",
        "        self.path_y = None\n",
        "        self.path_var_y = None\n",
        "\n",
        "        self.return_var_implemented = False\n",
        "        self.loss_comp_for_pow2_implemented = False\n",
        "\n",
        "    def generate_paths(self, **options):\n",
        "        \"\"\"\n",
        "        generate random paths according to the model hyperparams\n",
        "        :return: stock paths as np.array, dim: [nb_paths, data_dim, nb_steps]\n",
        "        \"\"\"\n",
        "        raise ValueError(\"not implemented yet\")\n",
        "\n",
        "    def next_cond_exp(self, *args, **kwargs):\n",
        "        \"\"\"\n",
        "        compute the next point of the conditional expectation starting from\n",
        "        given point for given time_delta\n",
        "        :return: cond. exp. at next time_point (= current_time + time_delta)\n",
        "        \"\"\"\n",
        "        raise ValueError(\"not implemented yet\")\n",
        "\n",
        "    def compute_cond_exp(self, times, time_ptr, X, obs_idx, delta_t, T, start_X,\n",
        "                         n_obs_ot, return_path=True, get_loss=False,\n",
        "                         weight=0.5, store_and_use_stored=True,\n",
        "                         start_time=None, which_loss=\"easy\",\n",
        "                         return_var=False,\n",
        "                         **kwargs):\n",
        "        \"\"\"\n",
        "        compute conditional expectation similar to computing the prediction in\n",
        "        the model.NJODE.forward\n",
        "        ATTENTION: Works correctly only for non-masked data!\n",
        "        :param times: see model.NJODE.forward\n",
        "        :param time_ptr: see model.NJODE.forward\n",
        "        :param X: see model.NJODE.forward, as np.array\n",
        "        :param obs_idx: see model.NJODE.forward, as np.array\n",
        "        :param delta_t: see model.NJODE.forward, as np.array\n",
        "        :param T: see model.NJODE.forward\n",
        "        :param start_X: see model.NJODE.forward, as np.array\n",
        "        :param n_obs_ot: see model.NJODE.forward, as np.array\n",
        "        :param return_path: see model.NJODE.forward\n",
        "        :param get_loss: see model.NJODE.forward\n",
        "        :param weight: see model.NJODE.forward\n",
        "        :param store_and_use_stored: bool, whether the loss, and cond exp path\n",
        "            should be stored and reused when calling the function again\n",
        "        :param start_time: None or float, if float, this is first time point\n",
        "        :param return_var: bool, whether to return the variance additionally to\n",
        "                the process; only if self.return_var_implemented is True\n",
        "        :param kwargs: unused, to allow for additional unused inputs\n",
        "        :return: float (loss), if wanted paths of t and y (np.arrays)\n",
        "        \"\"\"\n",
        "        if return_var and not self.return_var_implemented:\n",
        "            return_var = False\n",
        "\n",
        "        if return_path and store_and_use_stored:\n",
        "            res = [self.loss, self.path_t, self.path_y]\n",
        "            if return_var:\n",
        "                res.append(self.path_var_y)\n",
        "            if get_loss:\n",
        "                if self.path_t is not None and self.loss is not None:\n",
        "                    return res\n",
        "            else:\n",
        "                if self.path_t is not None:\n",
        "                    return res\n",
        "        elif store_and_use_stored:\n",
        "            if get_loss:\n",
        "                if self.loss is not None:\n",
        "                    return self.loss\n",
        "\n",
        "        y = start_X\n",
        "        if return_var:\n",
        "            var_y = start_X*0\n",
        "        batch_size = start_X.shape[0]\n",
        "        current_time = 0.0\n",
        "        if start_time:\n",
        "            current_time = start_time\n",
        "\n",
        "        loss = 0\n",
        "\n",
        "        if return_path:\n",
        "            if start_time:\n",
        "                path_t = []\n",
        "                path_y = []\n",
        "                if return_var:\n",
        "                    path_var_y = []\n",
        "            else:\n",
        "                path_t = [0.]\n",
        "                path_y = [y]\n",
        "                if return_var:\n",
        "                    path_var_y = [var_y]\n",
        "\n",
        "        for i, obs_time in enumerate(times):\n",
        "            # the following is needed for the combined stock model datasets\n",
        "            if obs_time > T + 1e-10*delta_t:\n",
        "                break\n",
        "            if obs_time <= current_time:\n",
        "                continue\n",
        "            # Calculate conditional expectation stepwise\n",
        "            while current_time < (obs_time - 1e-10*delta_t):\n",
        "                if current_time < obs_time - delta_t:\n",
        "                    delta_t_ = delta_t\n",
        "                else:\n",
        "                    delta_t_ = obs_time - current_time\n",
        "                y = self.next_cond_exp(y, delta_t_, current_time)\n",
        "                if return_var:\n",
        "                    var_y = self.next_cond_exp(\n",
        "                        var_y, delta_t_, current_time, variance=True)\n",
        "                current_time = current_time + delta_t_\n",
        "\n",
        "                # Storing the conditional expectation\n",
        "                if return_path:\n",
        "                    path_t.append(current_time)\n",
        "                    path_y.append(y)\n",
        "                    if return_var:\n",
        "                        path_var_y.append(var_y)\n",
        "\n",
        "            # Reached an observation - set new interval\n",
        "            start = time_ptr[i]\n",
        "            end = time_ptr[i + 1]\n",
        "            X_obs = X[start:end]\n",
        "            i_obs = obs_idx[start:end]\n",
        "\n",
        "            # Update h. Also updating loss, tau and last_X\n",
        "            Y_bj = y\n",
        "            temp = copy.deepcopy(y)\n",
        "            temp[i_obs] = X_obs\n",
        "            y = temp\n",
        "            Y = y\n",
        "            if return_var:\n",
        "                temp_var = copy.deepcopy(var_y)\n",
        "                temp_var[i_obs] = X_obs*0\n",
        "                var_y = temp_var\n",
        "\n",
        "            if get_loss:\n",
        "                loss = loss + compute_loss(\n",
        "                    X_obs=X_obs, Y_obs=Y[i_obs], Y_obs_bj=Y_bj[i_obs],\n",
        "                    n_obs_ot=n_obs_ot[i_obs],\n",
        "                    batch_size=batch_size, weight=weight, which_loss=which_loss)\n",
        "            if return_path:\n",
        "                path_t.append(obs_time)\n",
        "                path_y.append(y)\n",
        "                if return_var:\n",
        "                    path_var_y.append(var_y)\n",
        "\n",
        "        # after every observation has been processed, propagating until T\n",
        "        while current_time < T - 1e-10 * delta_t:\n",
        "            if current_time < T - delta_t:\n",
        "                delta_t_ = delta_t\n",
        "            else:\n",
        "                delta_t_ = T - current_time\n",
        "            y = self.next_cond_exp(y, delta_t_, current_time)\n",
        "            if return_var:\n",
        "                var_y = self.next_cond_exp(\n",
        "                    var_y, delta_t_, current_time, variance=True)\n",
        "            current_time = current_time + delta_t_\n",
        "\n",
        "            # Storing the predictions.\n",
        "            if return_path:\n",
        "                path_t.append(current_time)\n",
        "                path_y.append(y)\n",
        "                if return_var:\n",
        "                    path_var_y.append(var_y)\n",
        "\n",
        "        if get_loss and store_and_use_stored:\n",
        "            self.loss = loss\n",
        "        if return_path and store_and_use_stored:\n",
        "            self.path_t = np.array(path_t)\n",
        "            self.path_y = np.array(path_y)\n",
        "            if return_var:\n",
        "                self.path_var_y = np.array(path_var_y)\n",
        "\n",
        "        if return_path:\n",
        "            # path dimension: [time_steps, batch_size, output_size]\n",
        "            res = [loss, np.array(path_t), np.array(path_y)]\n",
        "            if return_var:\n",
        "                res.append(np.array(path_var_y))\n",
        "            return res\n",
        "        else:\n",
        "            return loss\n",
        "\n",
        "    def get_optimal_loss(self, times, time_ptr, X, obs_idx, delta_t, T, start_X,\n",
        "                         n_obs_ot, weight=0.5, M=None, mult=None,\n",
        "                         store_and_use_stored=True, return_var=False,\n",
        "                         which_loss=\"easy\"):\n",
        "        if mult is not None and mult > 1:\n",
        "            bs, dim = start_X.shape\n",
        "            _dim = round(dim / mult)\n",
        "            X = X[:, :_dim]\n",
        "            start_X = start_X[:, :_dim]\n",
        "            if M is not None:\n",
        "                M = M[:, :_dim]\n",
        "\n",
        "        # depending on whether method can return the variance, the result has\n",
        "        #   len 3 or 4\n",
        "        res = self.compute_cond_exp(\n",
        "            times, time_ptr, X, obs_idx, delta_t, T, start_X, n_obs_ot,\n",
        "            return_path=True, get_loss=True, weight=weight, M=M,\n",
        "            store_and_use_stored=store_and_use_stored, return_var=return_var,\n",
        "            which_loss=which_loss)\n",
        "        loss = res[0]\n",
        "        return loss\n",
        "\n",
        "class BlackScholes(StockModel):\n",
        "    \"\"\"\n",
        "    standard Black-Scholes model, see:\n",
        "    https://en.wikipedia.org/wiki/Black–Scholes_model\n",
        "    https://en.wikipedia.org/wiki/Geometric_Brownian_motion\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, drift, volatility, nb_paths, nb_steps, S0,  # initialize relevant parameters\n",
        "                 maturity, sine_coeff=None, **kwargs):\n",
        "        super(BlackScholes, self).__init__(\n",
        "            drift=drift, volatility=volatility, nb_paths=nb_paths,\n",
        "            nb_steps=nb_steps, S0=S0, maturity=maturity,\n",
        "            sine_coeff=sine_coeff\n",
        "        )\n",
        "\n",
        "    def next_cond_exp(self, y, delta_t, current_t):\n",
        "        return y * np.exp(self.drift * self.periodic_coeff(current_t) * delta_t)\n",
        "\n",
        "    def generate_paths(self, start_X=None):\n",
        "        drift = lambda x, t: self.drift * self.periodic_coeff(t) * x\n",
        "        diffusion = lambda x, t: self.volatility * x\n",
        "        spot_paths = np.empty(\n",
        "            (self.nb_paths, self.dimensions, self.nb_steps + 1))\n",
        "        dt = self.dt\n",
        "        if start_X is not None:\n",
        "            spot_paths[:, :, 0] = start_X\n",
        "        for i in range(self.nb_paths):\n",
        "            if start_X is None:\n",
        "                spot_paths[i, :, 0] = self.S0\n",
        "            for k in range(1, self.nb_steps + 1):\n",
        "                random_numbers = np.random.normal(0, 1, self.dimensions)\n",
        "                dW = random_numbers * np.sqrt(dt)\n",
        "                spot_paths[i, :, k] = (\n",
        "                        spot_paths[i, :, k - 1]\n",
        "                        + drift(spot_paths[i, :, k - 1], (k - 1) * dt) * dt\n",
        "                        + diffusion(spot_paths[i, :, k - 1], (k) * dt) * dW)\n",
        "        # stock_path dimension: [nb_paths, dimension, time_steps]\n",
        "        return spot_paths, dt\n",
        "\n",
        "class BM(StockModel):\n",
        "    \"\"\"\n",
        "    Brownian Motion\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, nb_paths, nb_steps, maturity, dimension, drift=0, **kwargs):\n",
        "        super().__init__(\n",
        "            drift=drift, volatility=None, nb_paths=nb_paths,\n",
        "            nb_steps=nb_steps, S0=0., maturity=maturity,\n",
        "            sine_coeff=None,)\n",
        "        assert dimension == 1\n",
        "        self.return_var_implemented = True\n",
        "\n",
        "    def next_cond_exp(self, y, delta_t, current_t, variance=False):\n",
        "        if variance:\n",
        "            next_y = y + delta_t\n",
        "        else:\n",
        "            next_y = y + self.drift * delta_t\n",
        "        return next_y\n",
        "\n",
        "    def generate_paths(self, start_X=None):\n",
        "        spot_paths = np.zeros(\n",
        "            (self.nb_paths, 1, self.nb_steps + 1))\n",
        "        if start_X is not None:\n",
        "            spot_paths[:, :, 0] = start_X\n",
        "        dt = self.dt\n",
        "\n",
        "        random_numbers = np.random.normal(\n",
        "            0, 1, (self.nb_paths, 1, self.nb_steps)) * np.sqrt(dt)\n",
        "        W = np.cumsum(random_numbers, axis=2)\n",
        "\n",
        "        spot_paths[:, 0, 1:] = spot_paths[:, :, 0] + W[:, 0, :] + self.drift * np.arange(\n",
        "            1, self.nb_steps+1) * dt\n",
        "\n",
        "        # stock_path dimension: [nb_paths, dimension, time_steps]\n",
        "        return spot_paths, dt\n",
        "\n",
        "class BMNoisyObs(BM):\n",
        "    \"\"\"\n",
        "    A Brownian Motion with noisy observations\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, nb_paths, nb_steps, maturity, obs_noise, dimension,\n",
        "                 **kwargs):\n",
        "        super().__init__(\n",
        "            nb_paths=nb_paths, nb_steps=nb_steps, maturity=maturity,\n",
        "            dimension=dimension,)\n",
        "        assert dimension == 1, \"dimension has to be set to 1 for this dataset\"\n",
        "        self.path_t = None\n",
        "        self.loss = None\n",
        "        self.noise_sig = obs_noise[\"scale\"]\n",
        "\n",
        "    def compute_cond_exp(self, times, time_ptr, X, obs_idx, delta_t, T, start_X,\n",
        "                         n_obs_ot, return_path=True, get_loss=False,\n",
        "                         weight=0.5, store_and_use_stored=True,\n",
        "                         start_time=None, M=None, which_loss=\"easy\",\n",
        "                         **kwargs):\n",
        "        \"\"\"\n",
        "        Compute conditional expectation\n",
        "        :param times: np.array, of observation times\n",
        "        :param time_ptr: list, start indices of X and obs_idx for a given\n",
        "                observation time, first element is 0, this pointer tells how\n",
        "                many (and which) of the observations of X along the batch-dim\n",
        "                belong to the current time, and obs_idx then tells to which of\n",
        "                the batch elements they belong. In particular, not each batch-\n",
        "                element has to jump at the same time, and only those elements\n",
        "                which jump at the current time should be updated with a jump\n",
        "        :param X: np.array, data tensor\n",
        "        :param obs_idx: list, index of the batch elements where jumps occur at\n",
        "                current time\n",
        "        :param delta_t: float, time step for Euler\n",
        "        :param T: float, the final time\n",
        "        :param start_X: np.array, the starting point of X\n",
        "        :param n_obs_ot: np.array, the number of observations over the\n",
        "                entire time interval for each element of the batch\n",
        "        :param return_path: bool, whether to return the path of h\n",
        "        :param get_loss: bool, whether to compute the loss, otherwise 0 returned\n",
        "        :param until_T: bool, whether to continue until T (for eval) or only\n",
        "                until last observation (for training)\n",
        "        :param M: None or np.array, if not None: the mask for the data, same\n",
        "                size as X, with 0 or 1 entries\n",
        "        :return: float (loss), if wanted paths of t and y (np.arrays)\n",
        "        \"\"\"\n",
        "        if return_path and store_and_use_stored:\n",
        "            if get_loss:\n",
        "                if self.path_t is not None and self.loss is not None:\n",
        "                    return self.loss, self.path_t, self.path_y\n",
        "            else:\n",
        "                if self.path_t is not None:\n",
        "                    return self.loss, self.path_t, self.path_y\n",
        "        elif store_and_use_stored:\n",
        "            if get_loss:\n",
        "                if self.loss is not None:\n",
        "                    return self.loss\n",
        "\n",
        "        bs = start_X.shape[0]\n",
        "        self.observations = [[] for x in range(bs)]\n",
        "        self.observed_t_all = [[] for x in range(bs)]\n",
        "\n",
        "        y = start_X\n",
        "        batch_size = bs\n",
        "        current_time = 0.0\n",
        "        if start_time:\n",
        "            current_time = start_time\n",
        "\n",
        "        loss = 0\n",
        "\n",
        "        if return_path:\n",
        "            if start_time:\n",
        "                path_t = []\n",
        "                path_y = []\n",
        "            else:\n",
        "                path_t = [0.]\n",
        "                path_y = [y]\n",
        "\n",
        "        for i, obs_time in enumerate(times):\n",
        "            # Calculate conditional expectation stepwise\n",
        "            while current_time < (obs_time - 1e-10 * delta_t):\n",
        "                if current_time < obs_time - delta_t:\n",
        "                    delta_t_ = delta_t\n",
        "                else:\n",
        "                    delta_t_ = obs_time - current_time\n",
        "                y = self.next_cond_exp(y, delta_t_, current_time)\n",
        "                current_time = current_time + delta_t_\n",
        "\n",
        "                # Storing the conditional expectation\n",
        "                if return_path:\n",
        "                    path_t.append(current_time)\n",
        "                    path_y.append(y)\n",
        "\n",
        "            # Reached an observation - set new interval\n",
        "            start = time_ptr[i]\n",
        "            end = time_ptr[i + 1]\n",
        "            X_obs = X[start:end]\n",
        "            i_obs = obs_idx[start:end]\n",
        "\n",
        "            # Update h. Also updating loss, tau and last_X\n",
        "            Y_bj = y\n",
        "            temp = copy.copy(y)\n",
        "            for j, jj in enumerate(i_obs):\n",
        "                self.observations[jj].append(X_obs[j])\n",
        "                self.observed_t_all[jj].append(obs_time)\n",
        "                size = len(self.observed_t_all[jj])\n",
        "                Sig = np.zeros((size, size))\n",
        "                for k in range(size):\n",
        "                    tmin = self.observed_t_all[jj][k]\n",
        "                    Sig[k, k+1:] = tmin\n",
        "                    Sig[k+1:, k] = tmin\n",
        "                    Sig[k, k] = tmin + self.noise_sig**2\n",
        "                sigvec = np.array(self.observed_t_all[jj])\n",
        "                Sig_inv = np.linalg.inv(Sig)\n",
        "                obs = np.array(self.observations[jj])\n",
        "                mu = np.dot(np.dot(sigvec, Sig_inv), obs)\n",
        "                temp[jj] = mu\n",
        "            y = temp\n",
        "            Y = y\n",
        "\n",
        "            if get_loss:\n",
        "                loss = loss + compute_loss(\n",
        "                    X_obs=X_obs, Y_obs=Y[i_obs], Y_obs_bj=Y_bj[i_obs],\n",
        "                    n_obs_ot=n_obs_ot[i_obs], batch_size=batch_size,\n",
        "                    weight=weight, M_obs=None, which_loss=which_loss)\n",
        "            if return_path:\n",
        "                path_t.append(obs_time)\n",
        "                path_y.append(y)\n",
        "\n",
        "        # after every observation has been processed, propagating until T\n",
        "        while current_time < T - 1e-10 * delta_t:\n",
        "            if current_time < T - delta_t:\n",
        "                delta_t_ = delta_t\n",
        "            else:\n",
        "                delta_t_ = T - current_time\n",
        "            y = self.next_cond_exp(y, delta_t_)\n",
        "            current_time = current_time + delta_t_\n",
        "\n",
        "            # Storing the predictions.\n",
        "            if return_path:\n",
        "                path_t.append(current_time)\n",
        "                path_y.append(y)\n",
        "\n",
        "        if get_loss and store_and_use_stored:\n",
        "            self.loss = loss\n",
        "        if return_path and store_and_use_stored:\n",
        "            self.path_t = np.array(path_t)\n",
        "            self.path_y = np.array(path_y)\n",
        "\n",
        "        if return_path:\n",
        "            # path dimension: [time_steps, batch_size, output_size]\n",
        "            return loss, np.array(path_t), np.array(path_y)\n",
        "        else:\n",
        "            return loss\n",
        "\n",
        "class BMFiltering(StockModel):\n",
        "    \"\"\"\n",
        "    A Brownian Motion filtering example. The Signal process is a BM $X$ and the\n",
        "    observation process is given by\n",
        "        $ Y = \\\\alpha X + W, $\n",
        "    where $W$ is also a BM independent of $X$ and $\\\\alpha \\\\in \\\\R$.\n",
        "    $ Z = (Y, X) $, i.e. the first coordinate is $Y$ and is always observed.\n",
        "    expectation for incomplete observations\n",
        "    https://en.wikipedia.org/wiki/Multivariate_normal_distribution\n",
        "\n",
        "    optionally, in the IO_version, Y is the input and X the output coordinate\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, nb_paths, nb_steps, maturity, alpha, dimension,\n",
        "                 IO_version=False, **kwargs):\n",
        "        super().__init__(\n",
        "            drift=None, volatility=None, nb_paths=nb_paths,\n",
        "            nb_steps=nb_steps, S0=np.array([0,0]), maturity=maturity,\n",
        "            sine_coeff=None\n",
        "        )\n",
        "        self.alpha = alpha\n",
        "        assert dimension == 2, \"dimension has to be set to 2 for this dataset\"\n",
        "        self.path_t = None\n",
        "        self.loss = None\n",
        "        self.IO_version = IO_version\n",
        "        if self.IO_version:\n",
        "            self.output_coords = [1]\n",
        "        else:\n",
        "            self.output_coords = [0, 1]\n",
        "\n",
        "    def next_cond_exp(self, y, delta_t, current_t):\n",
        "        return y\n",
        "\n",
        "    def get_mu(self, jj, which_coord_obs):\n",
        "        if self.IO_version:\n",
        "            N = len(self.observed_t_all[jj])\n",
        "            sig_11 = np.zeros((N,N))\n",
        "            for i in range(N):\n",
        "                for j in range(N):\n",
        "                    sig_11[i,j] = ((self.alpha**2+1) *\n",
        "                                   self.observed_t_all[jj][min(i,j)])\n",
        "            sig_21 = self.alpha * np.array(\n",
        "                self.observed_t_all[jj]).reshape((1,-1))\n",
        "            sig_22 = self.observed_t_all[jj][-1]\n",
        "            sig_11_inv = np.linalg.inv(sig_11)\n",
        "            mu = np.dot(sig_21, np.dot(\n",
        "                sig_11_inv, np.array(self.observed_X0[jj])))\n",
        "            return mu\n",
        "\n",
        "        sig = np.diag(self.observed_t_all_inc[jj]*2)\n",
        "        M0 = np.tri(N=len(self.observed_0[jj]), k=0)[\n",
        "            np.array(self.observed_0[jj])==1]\n",
        "        M1 = np.tri(N=len(self.observed_1[jj]), k=0)[\n",
        "            np.array(self.observed_1[jj])==1]\n",
        "        r1, c1 = M0.shape\n",
        "        r2, c2 = M1.shape\n",
        "        M = np.zeros((r1+r2, c1*2))\n",
        "        M[:r1, :c1] = self.alpha*M0\n",
        "        M[:r1, c1:c1*2] = M0\n",
        "        M[r1:, :c1] = M1\n",
        "        sig_bar_22_inv = np.linalg.inv(\n",
        "            np.dot(np.dot(M, sig), np.transpose(M)))\n",
        "        m = np.zeros((1,c1*2))\n",
        "        m[0, :c1] = 1\n",
        "        sig_bar_12 = np.dot(np.dot(m, sig), np.transpose(M))\n",
        "        obs_arr = np.array(\n",
        "            self.observed_X0[jj]+self.observed_X1[jj])\n",
        "        mu = np.dot(np.dot(sig_bar_12, sig_bar_22_inv), obs_arr)\n",
        "        return mu\n",
        "\n",
        "    def compute_cond_exp(self, times, time_ptr, X, obs_idx, delta_t, T, start_X,\n",
        "                         n_obs_ot, return_path=True, get_loss=False,\n",
        "                         weight=0.5, store_and_use_stored=True,\n",
        "                         start_time=None, M=None, which_loss=\"easy\",\n",
        "                         **kwargs):\n",
        "        \"\"\"\n",
        "        Compute conditional expectation\n",
        "        :param times: np.array, of observation times\n",
        "        :param time_ptr: list, start indices of X and obs_idx for a given\n",
        "                observation time, first element is 0, this pointer tells how\n",
        "                many (and which) of the observations of X along the batch-dim\n",
        "                belong to the current time, and obs_idx then tells to which of\n",
        "                the batch elements they belong. In particular, not each batch-\n",
        "                element has to jump at the same time, and only those elements\n",
        "                which jump at the current time should be updated with a jump\n",
        "        :param X: np.array, data tensor\n",
        "        :param obs_idx: list, index of the batch elements where jumps occur at\n",
        "                current time\n",
        "        :param delta_t: float, time step for Euler\n",
        "        :param T: float, the final time\n",
        "        :param start_X: np.array, the starting point of X\n",
        "        :param n_obs_ot: np.array, the number of observations over the\n",
        "                entire time interval for each element of the batch\n",
        "        :param return_path: bool, whether to return the path of h\n",
        "        :param get_loss: bool, whether to compute the loss, otherwise 0 returned\n",
        "        :param until_T: bool, whether to continue until T (for eval) or only\n",
        "                until last observation (for training)\n",
        "        :param M: None or np.array, if not None: the mask for the data, same\n",
        "                size as X, with 0 or 1 entries\n",
        "        :return: float (loss), if wanted paths of t and y (np.arrays)\n",
        "        \"\"\"\n",
        "        if return_path and store_and_use_stored:\n",
        "            if get_loss:\n",
        "                if self.path_t is not None and self.loss is not None:\n",
        "                    return self.loss, self.path_t, self.path_y\n",
        "            else:\n",
        "                if self.path_t is not None:\n",
        "                    return self.loss, self.path_t, self.path_y\n",
        "        elif store_and_use_stored:\n",
        "            if get_loss:\n",
        "                if self.loss is not None:\n",
        "                    return self.loss\n",
        "\n",
        "        # in case of the IO version\n",
        "        if M is None:\n",
        "            M = np.ones_like(X)\n",
        "\n",
        "        bs = start_X.shape[0]\n",
        "        self.observed_0 = [[] for x in range(bs)]\n",
        "        self.observed_1 = [[] for x in range(bs)]\n",
        "        self.observed_X0 = [[] for x in range(bs)]\n",
        "        self.observed_X1 = [[] for x in range(bs)]\n",
        "        self.observed_t_all = [[] for x in range(bs)]\n",
        "        self.observed_t_all_inc = [[] for x in range(bs)]\n",
        "\n",
        "        y = start_X\n",
        "        batch_size = bs\n",
        "        current_time = 0.0\n",
        "        if start_time:\n",
        "            current_time = start_time\n",
        "\n",
        "        loss = 0\n",
        "\n",
        "        if return_path:\n",
        "            if start_time:\n",
        "                path_t = []\n",
        "                path_y = []\n",
        "            else:\n",
        "                path_t = [0.]\n",
        "                path_y = [y]\n",
        "\n",
        "        for i, obs_time in enumerate(times):\n",
        "            # Calculate conditional expectation stepwise\n",
        "            while current_time < (obs_time - 1e-10 * delta_t):\n",
        "                if current_time < obs_time - delta_t:\n",
        "                    delta_t_ = delta_t\n",
        "                else:\n",
        "                    delta_t_ = obs_time - current_time\n",
        "                y = self.next_cond_exp(y, delta_t_, current_time)\n",
        "                current_time = current_time + delta_t_\n",
        "\n",
        "                # Storing the conditional expectation\n",
        "                if return_path:\n",
        "                    path_t.append(current_time)\n",
        "                    path_y.append(y)\n",
        "\n",
        "            # Reached an observation - set new interval\n",
        "            start = time_ptr[i]\n",
        "            end = time_ptr[i + 1]\n",
        "            X_obs = X[start:end]\n",
        "            i_obs = obs_idx[start:end]\n",
        "            M_obs = M[start:end]\n",
        "\n",
        "            # Update h. Also updating loss, tau and last_X\n",
        "            Y_bj = y\n",
        "            temp = copy.deepcopy(y)\n",
        "            for j, jj in enumerate(i_obs):\n",
        "                if M_obs[j, 0] == 1:\n",
        "                    self.observed_X0[jj].append(X_obs[j, 0])\n",
        "                    self.observed_0[jj].append(1)\n",
        "                else:\n",
        "                    self.observed_0[jj].append(0)\n",
        "                if M_obs[j, 1] == 1 and not self.IO_version:\n",
        "                    self.observed_X1[jj].append(X_obs[j, 1])\n",
        "                    self.observed_1[jj].append(1)\n",
        "                else:\n",
        "                    self.observed_1[jj].append(0)\n",
        "                assert M_obs[j, :].sum() > 0\n",
        "                self.observed_t_all[jj].append(obs_time)\n",
        "                last = [0.] + self.observed_t_all[jj]\n",
        "                self.observed_t_all_inc[jj].append(obs_time - last[-2])\n",
        "\n",
        "                if (M_obs[j, 0] == 1 and M_obs[j, 1] == 1\n",
        "                        and not self.IO_version):\n",
        "                    temp[jj, 0] = X_obs[j, 0]\n",
        "                    temp[jj, 1] = X_obs[j, 1]\n",
        "                else:\n",
        "                    assert M_obs[j, 0] == 1\n",
        "                    temp[jj, 0] = X_obs[j, 0]\n",
        "                    temp[jj, 1] = self.get_mu(jj=jj, which_coord_obs=0)\n",
        "            y = temp\n",
        "            Y = y\n",
        "\n",
        "            if get_loss:\n",
        "                loss = loss + compute_loss(\n",
        "                    X_obs=X_obs[:, self.output_coords],\n",
        "                    Y_obs=Y[i_obs][:, self.output_coords],\n",
        "                    Y_obs_bj=Y_bj[i_obs][:, self.output_coords],\n",
        "                    n_obs_ot=n_obs_ot[i_obs], batch_size=batch_size,\n",
        "                    weight=weight, M_obs=M_obs[:, self.output_coords],\n",
        "                    which_loss=which_loss)\n",
        "            if return_path:\n",
        "                path_t.append(obs_time)\n",
        "                path_y.append(y)\n",
        "\n",
        "        # after every observation has been processed, propagating until T\n",
        "        while current_time < T - 1e-10 * delta_t:\n",
        "            if current_time < T - delta_t:\n",
        "                delta_t_ = delta_t\n",
        "            else:\n",
        "                delta_t_ = T - current_time\n",
        "            y = self.next_cond_exp(y, delta_t_)\n",
        "            current_time = current_time + delta_t_\n",
        "\n",
        "            # Storing the predictions.\n",
        "            if return_path:\n",
        "                path_t.append(current_time)\n",
        "                path_y.append(y)\n",
        "\n",
        "        if get_loss and store_and_use_stored:\n",
        "            self.loss = loss\n",
        "        if return_path and store_and_use_stored:\n",
        "            self.path_t = np.array(path_t)\n",
        "            self.path_y = np.array(path_y)[:, :, self.output_coords]\n",
        "\n",
        "        if return_path:\n",
        "            # path dimension: [time_steps, batch_size, output_size]\n",
        "            return (loss, np.array(path_t),\n",
        "                    np.array(path_y)[:, :, self.output_coords])\n",
        "        else:\n",
        "            return loss\n",
        "\n",
        "    def generate_paths(self):\n",
        "        spot_paths = np.zeros(\n",
        "            (self.nb_paths, 2, self.nb_steps + 1))\n",
        "        dt = self.dt\n",
        "\n",
        "        random_numbers = np.random.normal(\n",
        "            0, 1, (self.nb_paths, 2, self.nb_steps)) * np.sqrt(dt)\n",
        "        W = np.cumsum(random_numbers, axis=2)\n",
        "\n",
        "        spot_paths[:, 0, 1:] = W[:, 0, :] * self.alpha + W[:, 1, :]\n",
        "        spot_paths[:, 1, 1:] = W[:, 0, :]\n",
        "\n",
        "        # stock_path dimension: [nb_paths, dimension, time_steps]\n",
        "        return spot_paths, dt\n",
        "\n",
        "class Combined(StockModel):\n",
        "    def __init__(self, stock_model_names, hyperparam_dicts, **kwargs):\n",
        "        self.stock_model_names = stock_model_names\n",
        "        self.hyperparam_dicts = hyperparam_dicts\n",
        "\n",
        "    def compute_cond_exp(self, times, time_ptr, X, obs_idx, delta_t, T, start_X,\n",
        "                         n_obs_ot, return_path=True, get_loss=False,\n",
        "                         weight=0.5, which_loss=\"easy\", **kwargs):\n",
        "        # get first stockmodel\n",
        "        stockmodel = DATASETS[self.stock_model_names[0]](\n",
        "            **self.hyperparam_dicts[0])\n",
        "        T = self.hyperparam_dicts[0]['maturity']\n",
        "        loss, path_t, path_y = stockmodel.compute_cond_exp(\n",
        "            times, time_ptr, X, obs_idx, delta_t,\n",
        "            T, start_X,\n",
        "            n_obs_ot, return_path=True, get_loss=get_loss,\n",
        "            weight=weight, store_and_use_stored=False, which_loss=which_loss)\n",
        "        for i in range(1, len(self.stock_model_names)):\n",
        "            start_X = path_y[-1, :, :]\n",
        "            start_time = path_t[-1]\n",
        "            T += self.hyperparam_dicts[i]['maturity']\n",
        "            stockmodel = DATASETS[self.stock_model_names[i]](\n",
        "                **self.hyperparam_dicts[i])\n",
        "            _loss, _path_t, _path_y = stockmodel.compute_cond_exp(\n",
        "                times, time_ptr, X, obs_idx, delta_t,\n",
        "                T, start_X,\n",
        "                n_obs_ot, return_path=True, get_loss=get_loss,\n",
        "                weight=weight, start_time=start_time,\n",
        "                store_and_use_stored=False, which_loss=which_loss)\n",
        "            loss += _loss\n",
        "            path_t = np.concatenate([path_t, _path_t])\n",
        "            path_y = np.concatenate([path_y, _path_y], axis=0)\n",
        "\n",
        "        if return_path:\n",
        "            # path dimension: [time_steps, batch_size, output_size]\n",
        "            return loss, np.array(path_t), np.array(path_y)\n",
        "        else:\n",
        "            return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTQT4y0Wp04q"
      },
      "outputs": [],
      "source": [
        "# collection of synthetic data models (find more in the git repo)\n",
        "DATASETS = {\n",
        "    \"BlackScholes\": BlackScholes,\n",
        "    \"BM\": BM,\n",
        "    \"BMNoisyObs\": BMNoisyObs,\n",
        "    \"BMFiltering\": BMFiltering,\n",
        "    \"combined\": Combined,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZP5hUl8CqFw4"
      },
      "source": [
        "# Data generation and handeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVi1QZMWqFSs"
      },
      "outputs": [],
      "source": [
        "def create_dataset(\n",
        "        stock_model_name=\"BlackScholes\",\n",
        "        hyperparam_dict=None,\n",
        "        seed=0):\n",
        "    \"\"\"\n",
        "    create a synthetic dataset using one of the stock-models\n",
        "    :param stock_model_name: str, name of the stockmodel, see _STOCK_MODELS\n",
        "    :param hyperparam_dict: dict, contains all needed parameters for the model\n",
        "            it can also contain additional options for dataset generation:\n",
        "                - masked    None, float or array of floats. if None: no mask is\n",
        "                            used; if float: lambda of the poisson distribution;\n",
        "                            if array of floats: gives the bernoulli probability\n",
        "                            for each coordinate to be observed\n",
        "                - obs_noise    dict, if given: add noise to the observations\n",
        "                            the dict needs the following keys: 'distribution'\n",
        "                            (defining the distribution of the noise), and keys\n",
        "                            for the parameters of the distribution (depending on\n",
        "                            the used distribution); supported distributions\n",
        "                            {'normal'}. Be aware that the noise needs to be\n",
        "                            centered for the model to be able to learn the\n",
        "                            correct dynamics.\n",
        "\n",
        "    :param seed: int, random seed for the generation of the dataset\n",
        "    :return: stock_paths, observed_dates, nb_obs, hyperparam_dict, obs_noise\n",
        "    \"\"\"\n",
        "    np.random.seed(seed=seed)\n",
        "    hyperparam_dict['model_name'] = stock_model_name\n",
        "    obs_perc = hyperparam_dict['obs_perc']\n",
        "    masked = False\n",
        "    masked_lambda = None\n",
        "    mask_probs = None\n",
        "    if (\"masked\" in hyperparam_dict\n",
        "            and hyperparam_dict['masked'] not in [None, False]):\n",
        "        masked = True\n",
        "        if isinstance(hyperparam_dict['masked'], float):\n",
        "            masked_lambda = hyperparam_dict['masked']\n",
        "        elif isinstance(hyperparam_dict['masked'], (tuple, list)):\n",
        "            mask_probs = hyperparam_dict['masked']\n",
        "            assert len(mask_probs) == hyperparam_dict['dimension']\n",
        "        else:\n",
        "            raise ValueError(\"please provide a float (poisson lambda) \"\n",
        "                             \"in hyperparam_dict['masked']\")\n",
        "\n",
        "    stockmodel = DATASETS[stock_model_name](**hyperparam_dict)\n",
        "    # stock paths shape: [nb_paths, dim, time_steps]\n",
        "    stock_paths, dt = stockmodel.generate_paths()\n",
        "    size = stock_paths.shape\n",
        "    observed_dates = np.random.random(size=(size[0], size[2]))\n",
        "    observed_dates = (observed_dates < obs_perc)*1\n",
        "    observed_dates[:, 0] = 1\n",
        "    nb_obs = np.sum(observed_dates[:, 1:], axis=1)\n",
        "    if masked:\n",
        "        mask = np.zeros(shape=size)\n",
        "        mask[:,:,0] = 1\n",
        "        for i in range(size[0]):\n",
        "            for j in range(1, size[2]):\n",
        "                if observed_dates[i,j] == 1:\n",
        "                    if masked_lambda is not None:\n",
        "                        amount = min(1+np.random.poisson(masked_lambda),\n",
        "                                     size[1])\n",
        "                        observed = np.random.choice(\n",
        "                            size[1], amount, replace=False)\n",
        "                        mask[i, observed, j] = 1\n",
        "                    elif mask_probs is not None:\n",
        "                        for k in range(size[1]):\n",
        "                            mask[i, k, j] = np.random.binomial(1, mask_probs[k])\n",
        "        observed_dates = mask\n",
        "    if \"obs_noise\" in hyperparam_dict:\n",
        "        obs_noise_dict = hyperparam_dict[\"obs_noise\"]\n",
        "        if obs_noise_dict[\"distribution\"] == \"normal\":\n",
        "            obs_noise = np.random.normal(\n",
        "                loc=obs_noise_dict[\"loc\"],\n",
        "                scale=obs_noise_dict[\"scale\"],\n",
        "                size=size)\n",
        "            if 'noise_at_start' in obs_noise_dict and \\\n",
        "                    obs_noise_dict['noise_at_start']:\n",
        "                pass\n",
        "            else:\n",
        "                obs_noise[:,:,0] = 0\n",
        "        else:\n",
        "            raise ValueError(\"obs_noise distribution {} not implemented\".format(\n",
        "                obs_noise_dict[\"distribution\"]))\n",
        "    else:\n",
        "        obs_noise = None\n",
        "\n",
        "    hyperparam_dict['dt'] = dt\n",
        "\n",
        "    # stock_path dimension: [nb_paths, dimension, time_steps]\n",
        "    return stock_paths, observed_dates, nb_obs, hyperparam_dict, obs_noise\n",
        "\n",
        "def create_combined_dataset(\n",
        "        stock_model_names=(\"BlackScholes\", \"BM\"),\n",
        "        hyperparam_dicts=(None, None),\n",
        "        seed=0):\n",
        "    \"\"\"\n",
        "    create a synthetic dataset using one of the stock-models\n",
        "    :param stock_model_names: list of str, each str is a name of a stockmodel,\n",
        "            see _STOCK_MODELS\n",
        "    :param hyperparam_dicts: list of dict, each dict contains all needed\n",
        "            parameters for the model\n",
        "    :param seed: int, random seed for the generation of the dataset\n",
        "    :return: stock_paths, observed_dates, nb_obs, metadata, None\n",
        "    \"\"\"\n",
        "\n",
        "    assert len(stock_model_names) == len(hyperparam_dicts)\n",
        "    np.random.seed(seed=seed)\n",
        "\n",
        "    # start to create paths from first model\n",
        "    maturity = hyperparam_dicts[0]['maturity']\n",
        "    hyperparam_dicts[0]['model_name'] = stock_model_names[0]\n",
        "    obs_perc = hyperparam_dicts[0]['obs_perc']\n",
        "    stockmodel = DATASETS[stock_model_names[0]](**hyperparam_dicts[0])\n",
        "    stock_paths, dt = stockmodel.generate_paths()\n",
        "    last = stock_paths[:, :, -1]\n",
        "    size = stock_paths.shape\n",
        "    observed_dates = np.random.random(size=(size[0], size[2]))\n",
        "    observed_dates = (observed_dates < obs_perc)*1\n",
        "    observed_dates[:, 0] = 1\n",
        "\n",
        "    # for every other model, add the paths created with this model starting at\n",
        "    #   last point of previous model\n",
        "    for i in range(1, len(stock_model_names)):\n",
        "        dt_last = dt\n",
        "        assert hyperparam_dicts[i]['dimension'] == \\\n",
        "               hyperparam_dicts[i-1]['dimension']\n",
        "        assert hyperparam_dicts[i]['nb_paths'] == \\\n",
        "               hyperparam_dicts[i-1]['nb_paths']\n",
        "        maturity += hyperparam_dicts[i]['maturity']\n",
        "        hyperparam_dicts[i]['model_name'] = stock_model_names[i]\n",
        "        stockmodel = DATASETS[stock_model_names[i]](**hyperparam_dicts[i])\n",
        "        _stock_paths, dt = stockmodel.generate_paths(start_X=last)\n",
        "        size = _stock_paths.shape\n",
        "        obs_perc = hyperparam_dicts[i]['obs_perc']\n",
        "        _observed_dates = np.random.random(size=(size[0], size[2]))\n",
        "        _observed_dates = (_observed_dates < obs_perc)*1\n",
        "        assert dt_last == dt\n",
        "        last = _stock_paths[:, :, -1]\n",
        "        stock_paths = np.concatenate(\n",
        "            [stock_paths, _stock_paths[:, :, 1:]], axis=2)\n",
        "        observed_dates = np.concatenate(\n",
        "            [observed_dates, _observed_dates[:, 1:]], axis=1)\n",
        "    nb_obs = np.sum(observed_dates[:, 1:], axis=1)\n",
        "\n",
        "    metadata = {'dt': dt, 'maturity': maturity,\n",
        "                'dimension': hyperparam_dicts[0]['dimension'],\n",
        "                'nb_paths': hyperparam_dicts[0]['nb_paths'],\n",
        "                'model_name': 'combined',\n",
        "                'stock_model_names': stock_model_names,\n",
        "                'hyperparam_dicts': hyperparam_dicts}\n",
        "\n",
        "    return stock_paths, observed_dates, nb_obs, metadata, None\n",
        "\n",
        "\n",
        "class IrregularDataset(Dataset):\n",
        "    \"\"\"\n",
        "    class for iterating over a dataset\n",
        "    \"\"\"\n",
        "    def __init__(self, dataset_collection, idx=None):\n",
        "        stock_paths, observed_dates, nb_obs, hyperparam_dict, obs_noise = \\\n",
        "            dataset_collection\n",
        "        if idx is None:\n",
        "            idx = np.arange(hyperparam_dict['nb_paths'])\n",
        "        self.metadata = hyperparam_dict\n",
        "        self.stock_paths = stock_paths[idx]\n",
        "        self.observed_dates = observed_dates[idx]\n",
        "        self.nb_obs = nb_obs[idx]\n",
        "        self.obs_noise = obs_noise\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.nb_obs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if type(idx) == int:\n",
        "            idx = [idx]\n",
        "        if self.obs_noise is None:\n",
        "            obs_noise = None\n",
        "        else:\n",
        "            obs_noise = self.obs_noise[idx]\n",
        "        # stock_path dimension: [BATCH_SIZE, DIMENSION, TIME_STEPS]\n",
        "        return {\"idx\": idx, \"stock_path\": self.stock_paths[idx],\n",
        "                \"observed_dates\": self.observed_dates[idx],\n",
        "                \"nb_obs\": self.nb_obs[idx], \"dt\": self.metadata['dt'],\n",
        "                \"obs_noise\": obs_noise}\n",
        "\n",
        "def _get_func(name):\n",
        "    \"\"\"\n",
        "    transform a function given as str to a python function\n",
        "    :param name: str, correspond to a function,\n",
        "            supported: 'exp', 'power-x' (x the wanted power)\n",
        "    :return: numpy fuction\n",
        "    \"\"\"\n",
        "    if name in ['exp', 'exponential']:\n",
        "        return np.exp\n",
        "    if 'power-' in name:\n",
        "        x = float(name.split('-')[1])\n",
        "        def pow(input):\n",
        "            return np.power(input, x)\n",
        "        return pow\n",
        "    else:\n",
        "        try:\n",
        "            return eval(name)\n",
        "        except Exception:\n",
        "            return None\n",
        "\n",
        "\n",
        "def _get_X_with_func_appl(X, functions, axis):\n",
        "    \"\"\"\n",
        "    apply a list of functions to the paths in X and append X by the outputs\n",
        "    along the given axis\n",
        "    :param X: np.array, with the data,\n",
        "    :param functions: list of functions to be applied\n",
        "    :param axis: int, the data_dimension (not batch and not time dim) along\n",
        "            which the new paths are appended\n",
        "    :return: np.array\n",
        "    \"\"\"\n",
        "    Y = X\n",
        "    for f in functions:\n",
        "        Y = np.concatenate([Y, f(X)], axis=axis)\n",
        "    return Y\n",
        "\n",
        "\n",
        "def CustomCollateFnGen(func_names=None):\n",
        "    \"\"\"\n",
        "    a function to get the costume collate function that can be used in\n",
        "    torch.DataLoader with the wanted functions applied to the data as new\n",
        "    dimensions\n",
        "    -> the functions are applied on the fly to the dataset, and this additional\n",
        "    data doesn't have to be saved\n",
        "\n",
        "    :param func_names: list of str, with all function names, see _get_func\n",
        "    :return: collate function, int (multiplication factor of dimension before\n",
        "                and after applying the functions)\n",
        "    \"\"\"\n",
        "    # get functions that should be applied to X, additionally to identity\n",
        "    functions = []\n",
        "    if func_names is not None:\n",
        "        for func_name in func_names:\n",
        "            f = _get_func(func_name)\n",
        "            if f is not None:\n",
        "                functions.append(f)\n",
        "    mult = len(functions) + 1\n",
        "\n",
        "    def custom_collate_fn(batch):\n",
        "        dt = batch[0]['dt']\n",
        "        stock_paths = np.concatenate([b['stock_path'] for b in batch], axis=0)\n",
        "        observed_dates = np.concatenate([b['observed_dates'] for b in batch],\n",
        "                                        axis=0)\n",
        "        obs_noise = None\n",
        "        if batch[0][\"obs_noise\"] is not None:\n",
        "            obs_noise = np.concatenate([b['obs_noise'] for b in batch], axis=0)\n",
        "        masked = False\n",
        "        mask = None\n",
        "        if len(observed_dates.shape) == 3:\n",
        "            masked = True\n",
        "            mask = observed_dates\n",
        "            observed_dates = observed_dates.max(axis=1)\n",
        "        nb_obs = torch.tensor(\n",
        "            np.concatenate([b['nb_obs'] for b in batch], axis=0))\n",
        "\n",
        "        # here axis=1, since we have elements of dim\n",
        "        #    [batch_size, data_dimension] => add as new data_dimensions\n",
        "        sp = stock_paths[:, :, 0]\n",
        "        if obs_noise is not None:\n",
        "            sp = stock_paths[:, :, 0] + obs_noise[:, :, 0]\n",
        "        start_X = torch.tensor(\n",
        "            _get_X_with_func_appl(sp, functions, axis=1),\n",
        "            dtype=torch.float32)\n",
        "        X = []\n",
        "        if masked:\n",
        "            M = []\n",
        "            start_M = torch.tensor(mask[:,:,0], dtype=torch.float32).repeat(\n",
        "                (1,mult))\n",
        "        else:\n",
        "            M = None\n",
        "            start_M = None\n",
        "        times = []\n",
        "        time_ptr = [0]\n",
        "        obs_idx = []\n",
        "        current_time = 0.\n",
        "        counter = 0\n",
        "        for t in range(1, observed_dates.shape[-1]):\n",
        "            current_time += dt\n",
        "            if observed_dates[:, t].sum() > 0:\n",
        "                times.append(current_time)\n",
        "                for i in range(observed_dates.shape[0]):\n",
        "                    if observed_dates[i, t] == 1:\n",
        "                        counter += 1\n",
        "                        # here axis=0, since only 1 dim (the data_dimension),\n",
        "                        #    i.e. the batch-dim is cummulated outside together\n",
        "                        #    with the time dimension\n",
        "                        sp = stock_paths[i, :, t]\n",
        "                        if obs_noise is not None:\n",
        "                            sp = stock_paths[i, :, t] + obs_noise[i, :, t]\n",
        "                        X.append(_get_X_with_func_appl(sp, functions, axis=0))\n",
        "                        if masked:\n",
        "                            M.append(np.tile(mask[i, :, t], reps=mult))\n",
        "                        obs_idx.append(i)\n",
        "                time_ptr.append(counter)\n",
        "        # if obs_noise is not None:\n",
        "        #     print(\"noisy observations used\")\n",
        "\n",
        "        assert len(obs_idx) == observed_dates[:, 1:].sum()\n",
        "        if masked:\n",
        "            M = torch.tensor(np.array(M), dtype=torch.float32)\n",
        "        res = {'times': np.array(times), 'time_ptr': np.array(time_ptr),\n",
        "               'obs_idx': torch.tensor(obs_idx, dtype=torch.long),\n",
        "               'start_X': start_X, 'n_obs_ot': nb_obs,\n",
        "               'X': torch.tensor(np.array(X), dtype=torch.float32),\n",
        "               'true_paths': stock_paths, 'observed_dates': observed_dates,\n",
        "               'true_mask': mask, 'obs_noise': obs_noise,\n",
        "               'M': M, 'start_M': start_M}\n",
        "        return res\n",
        "\n",
        "    return custom_collate_fn, mult"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uft6O4V6qQQu"
      },
      "outputs": [],
      "source": [
        "def create_dataset_Z(\n",
        "        stock_model_name=\"BlackScholes\",\n",
        "        hyperparam_dict=None,\n",
        "        seed=0):\n",
        "    \"\"\"\n",
        "    Create a synthetic dataset generating process Z using a stock model.\n",
        "\n",
        "    :param stock_model_name: str, name of the stock model, see _STOCK_MODELS\n",
        "    :param hyperparam_dict: dict, contains all needed parameters for the model\n",
        "            it can also contain additional options for dataset generation:\n",
        "                - masked    None, float or array of floats. if None: no mask is\n",
        "                            used; if float: lambda of the poisson distribution;\n",
        "                            if array of floats: gives the bernoulli probability\n",
        "                            for each coordinate to be observed\n",
        "                - obs_noise    dict, if given: add noise to the observations\n",
        "                            the dict needs the following keys: 'distribution'\n",
        "                            (defining the distribution of the noise), and keys\n",
        "                            for the parameters of the distribution (depending on\n",
        "                            the used distribution); supported distributions\n",
        "                            {'normal'}. Be aware that the noise needs to be\n",
        "                            centered for the model to be able to learn the\n",
        "                            correct dynamics.\n",
        "    :param seed: int, random seed for the generation of the dataset\n",
        "    :return: Z_flattened, observed_dates, nb_obs, hyperparam_dict, obs_noise\n",
        "             - Z_flattened: array of shape [nb_paths, dim*dim, time_steps],\n",
        "                            flattened version of Z_t = (X_t - X_{\\tau(t)}) (X_t - X_{\\tau(t)})^T\n",
        "                            for t >= 1, Z_0 = 0, and \\tau(t) is the last observed time before t\n",
        "             - observed_dates: observation indicators, shape [nb_paths, time_steps]\n",
        "                               if not masked, or [nb_paths, dim, time_steps] if masked\n",
        "             - nb_obs: array of shape [nb_paths], number of observed time steps per path (excluding t=0)\n",
        "             - hyperparam_dict: updated hyperparameter dictionary\n",
        "             - obs_noise: noise array of shape [nb_paths, dim, time_steps] or None\n",
        "    \"\"\"\n",
        "    np.random.seed(seed=seed)\n",
        "    hyperparam_dict['model_name'] = stock_model_name\n",
        "    obs_perc = hyperparam_dict['obs_perc']\n",
        "    masked = False\n",
        "    masked_lambda = None\n",
        "    mask_probs = None\n",
        "    if (\"masked\" in hyperparam_dict\n",
        "            and hyperparam_dict['masked'] not in [None, False]):\n",
        "        masked = True\n",
        "        if isinstance(hyperparam_dict['masked'], float):\n",
        "            masked_lambda = hyperparam_dict['masked']\n",
        "        elif isinstance(hyperparam_dict['masked'], (tuple, list)):\n",
        "            mask_probs = hyperparam_dict['masked']\n",
        "            assert len(mask_probs) == hyperparam_dict['dimension']\n",
        "        else:\n",
        "            raise ValueError(\"please provide a float (poisson lambda) \"\n",
        "                             \"in hyperparam_dict['masked']\")\n",
        "\n",
        "    stockmodel = DATASETS[stock_model_name](**hyperparam_dict)\n",
        "    # stock paths shape: [nb_paths, dim, time_steps]\n",
        "    stock_paths, dt = stockmodel.generate_paths()\n",
        "    size = stock_paths.shape\n",
        "    observed_dates = np.random.random(size=(size[0], size[2]))\n",
        "    observed_dates = (observed_dates < obs_perc)*1\n",
        "    observed_dates[:, 0] = 1\n",
        "    nb_obs = np.sum(observed_dates[:, 1:], axis=1)\n",
        "    if masked:\n",
        "        mask = np.zeros(shape=size)\n",
        "        mask[:,:,0] = 1\n",
        "        for i in range(size[0]):\n",
        "            for j in range(1, size[2]):\n",
        "                if observed_dates[i,j] == 1:\n",
        "                    if masked_lambda is not None:\n",
        "                        amount = min(1+np.random.poisson(masked_lambda),\n",
        "                                     size[1])\n",
        "                        observed = np.random.choice(\n",
        "                            size[1], amount, replace=False)\n",
        "                        mask[i, observed, j] = 1\n",
        "                    elif mask_probs is not None:\n",
        "                        for k in range(size[1]):\n",
        "                            mask[i, k, j] = np.random.binomial(1, mask_probs[k])\n",
        "        observed_dates = mask\n",
        "    if \"obs_noise\" in hyperparam_dict:\n",
        "        obs_noise_dict = hyperparam_dict[\"obs_noise\"]\n",
        "        if obs_noise_dict[\"distribution\"] == \"normal\":\n",
        "            obs_noise = np.random.normal(\n",
        "                loc=obs_noise_dict[\"loc\"],\n",
        "                scale=obs_noise_dict[\"scale\"],\n",
        "                size=size)\n",
        "            if 'noise_at_start' in obs_noise_dict and \\\n",
        "                    obs_noise_dict['noise_at_start']:\n",
        "                pass\n",
        "            else:\n",
        "                obs_noise[:,:,0] = 0\n",
        "        else:\n",
        "            raise ValueError(\"obs_noise distribution {} not implemented\".format(\n",
        "                obs_noise_dict[\"distribution\"]))\n",
        "    else:\n",
        "        obs_noise = None\n",
        "\n",
        "    hyperparam_dict['dt'] = dt\n",
        "\n",
        "    return stock_paths**2, observed_dates, nb_obs, hyperparam_dict, obs_noise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjpgZGaJqiSO"
      },
      "source": [
        "# NJODE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYowuftVqwfT"
      },
      "source": [
        "# Loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xeW1P7Hxqbul"
      },
      "outputs": [],
      "source": [
        "def compute_var_loss(X_obs, Y_obs, Y_obs_bj, n_obs_ot, batch_size, eps=1e-10,\n",
        "        weight=0.5, M_obs=None,\n",
        "        compute_variance=None, var_weight=1.,\n",
        "        Y_var_bj=None, Y_var=None, dim_to=None, type=1):\n",
        "    if dim_to is None:\n",
        "        dim_to = Y_obs.shape[1]\n",
        "    if compute_variance == \"variance\":\n",
        "        Y_var_bj_v = Y_var_bj[:, :dim_to] ** 2\n",
        "        Y_var_v = Y_var[:, :dim_to] ** 2\n",
        "        true_var_bj = (X_obs - Y_obs_bj.detach()) ** 2\n",
        "        true_var = (X_obs - Y_obs.detach()) ** 2\n",
        "        M_obs_var = M_obs\n",
        "        sum_dim = 1\n",
        "    elif compute_variance == \"covariance\":\n",
        "        d2 = Y_var.shape[1]\n",
        "        d = int(np.sqrt(d2))\n",
        "        Y_var_bj_v = Y_var_bj.view(-1, d, d)\n",
        "        Y_var_bj_v = Y_var_bj_v[:, :dim_to, :dim_to]\n",
        "        Y_var_bj_v = torch.matmul(Y_var_bj_v.transpose(1, 2), Y_var_bj_v)\n",
        "        Y_var_v = Y_var.view(-1, d, d)\n",
        "        Y_var_v = Y_var_v[:, :dim_to, :dim_to]\n",
        "        Y_var_v = torch.matmul(Y_var_v.transpose(1, 2), Y_var_v)\n",
        "        # the following is a row vector for each batch sample\n",
        "        true_var_bj = (X_obs - Y_obs_bj.detach()).unsqueeze(1)\n",
        "        true_var = (X_obs - Y_obs.detach()).unsqueeze(1)\n",
        "        true_var_bj = torch.matmul(true_var_bj.transpose(1, 2), true_var_bj)\n",
        "        true_var = torch.matmul(true_var.transpose(1, 2), true_var)\n",
        "        M_obs_var = M_obs.unsqueeze(1)\n",
        "        M_obs_var = torch.matmul(M_obs_var.transpose(1, 2), M_obs_var)\n",
        "        sum_dim = (1, 2)\n",
        "    else:\n",
        "        raise ValueError(\"compute_variance must be either 'variance' or \"\n",
        "                         \"'covariance'\")\n",
        "    if type == 1:\n",
        "        inner_var = (2 * weight * torch.sqrt(\n",
        "            torch.sum(M_obs_var * (true_var - Y_var_v)**2, dim=sum_dim) + eps) +\n",
        "                     2 * (1 - weight) * torch.sqrt(\n",
        "                    torch.sum(M_obs_var * (true_var_bj - Y_var_bj_v) ** 2,\n",
        "                              dim=sum_dim) + eps)) ** 2\n",
        "    elif type == 2:\n",
        "        inner_var = 2 * weight * torch.sum(\n",
        "            M_obs_var * (true_var - Y_var_v) ** 2, dim=sum_dim) + \\\n",
        "                    2 * (1 - weight) * torch.sum(\n",
        "            M_obs_var * (true_var_bj - Y_var_bj_v) ** 2, dim=sum_dim)\n",
        "    elif type == 3:\n",
        "        inner_var = torch.sum(M_obs_var * (true_var_bj - Y_var_bj_v) ** 2,\n",
        "                              dim=sum_dim)\n",
        "    else:\n",
        "        raise ValueError(\"type must be in {1, 2, 3}\")\n",
        "\n",
        "    outer = var_weight * torch.sum(inner_var / n_obs_ot)\n",
        "\n",
        "    return outer\n",
        "\n",
        "def compute_loss_2(\n",
        "        X_obs, Y_obs, Y_obs_bj, n_obs_ot, batch_size, eps=1e-10,\n",
        "        weight=0.5, M_obs=None,\n",
        "        compute_variance=None, var_weight=1.,\n",
        "        Y_var_bj=None, Y_var=None, dim_to=None, which_var_loss=None):\n",
        "    \"\"\"\n",
        "    similar to compute_loss, but using X_obs also in second part of loss\n",
        "    instead of Y_obs -> should make the learning easier\n",
        "    \"\"\"\n",
        "    if M_obs is None:\n",
        "        M_obs = 1.\n",
        "\n",
        "    inner = (2*weight * torch.sqrt(\n",
        "        torch.sum(M_obs * (X_obs - Y_obs) ** 2, dim=1) + eps) +\n",
        "             2*(1 - weight) * torch.sqrt(\n",
        "                torch.sum(M_obs * (Y_obs_bj - X_obs) ** 2, dim=1)\n",
        "                + eps)) ** 2\n",
        "    outer = torch.sum(inner / n_obs_ot)\n",
        "\n",
        "    # compute the variance loss term if wanted\n",
        "    if compute_variance is not None:\n",
        "        var_loss_type = 1\n",
        "        if which_var_loss is not None:\n",
        "            var_loss_type = which_var_loss\n",
        "        outer += compute_var_loss(\n",
        "            X_obs, Y_obs, Y_obs_bj, n_obs_ot, batch_size, eps=1e-10,\n",
        "            weight=weight, M_obs=M_obs,\n",
        "            compute_variance=compute_variance, var_weight=var_weight,\n",
        "            Y_var_bj=Y_var_bj, Y_var=Y_var, dim_to=dim_to, type=var_loss_type)\n",
        "\n",
        "    return outer / batch_size\n",
        "\n",
        "def compute_loss_3(\n",
        "        X_obs_bj, X_obs, Y_obs, Y_obs_bj, n_obs_ot, batch_size, eps=1e-10,\n",
        "        weight=0.5, M_obs=None,\n",
        "        compute_variance=None, var_weight=1.,\n",
        "        Y_var_bj=None, Y_var=None, dim_to=None, which_var_loss=None):\n",
        "    \"\"\"\n",
        "    similar to compute_loss, but using X_obs also in second part of loss\n",
        "    instead of Y_obs -> should make the learning easier\n",
        "    \"\"\"\n",
        "    if M_obs is None:\n",
        "        M_obs = 1.\n",
        "\n",
        "    d2 = Y_obs_bj.shape[1]\n",
        "    d = int(np.sqrt(d2))\n",
        "    Y_obs_bj_mat = Y_obs_bj.view(-1, d, d)\n",
        "    Y_obs_bj_mat1 = torch.matmul(Y_obs_bj_mat.transpose(1, 2),Y_obs_bj_mat)\n",
        "    Y_obs_bj_mod = Y_obs_bj_mat1.view(-1, d2)\n",
        "\n",
        "    #inner = torch.sum(M_obs * (Y_obs_bj_mod - X_obs) ** 2, dim=1)\n",
        "\n",
        "    d2 = Y_obs.shape[1]\n",
        "    d = int(np.sqrt(d2))\n",
        "    Y_obs_mat = Y_obs_bj.view(-1, d, d)\n",
        "    Y_obs_mat1 = torch.matmul(Y_obs_mat.transpose(1, 2),Y_obs_mat)\n",
        "    Y_obs_mod = Y_obs_mat1.view(-1, d2)\n",
        "\n",
        "    inner = (2*weight * torch.sqrt(\n",
        "        torch.sum(M_obs * (Y_obs_bj_mod - X_obs_bj) ** 2, dim=1) + eps) +\n",
        "             2*(1 - weight) * torch.sqrt(\n",
        "                torch.sum(M_obs * (Y_obs_mod-X_obs) ** 2, dim=1)\n",
        "                + eps)) ** 2\n",
        "\n",
        "    outer = torch.sum(inner / n_obs_ot)\n",
        "\n",
        "    return outer / batch_size\n",
        "\n",
        "def compute_loss_IO(\n",
        "        X_obs, Y_obs, Y_obs_bj, n_obs_ot, batch_size, eps=1e-10,\n",
        "        weight=0.5, M_obs=None,\n",
        "        compute_variance=None, var_weight=1.,\n",
        "        Y_var_bj=None, Y_var=None, dim_to=None, which_var_loss=None):\n",
        "    \"\"\"\n",
        "    similar to compute_loss, but using X_obs also in second part of loss\n",
        "    instead of Y_obs and squaring the two terms directly instead of squaring the\n",
        "    sum of the two terms\n",
        "    \"\"\"\n",
        "    if M_obs is None:\n",
        "        M_obs = 1.\n",
        "\n",
        "    inner = 2*weight * torch.sum(M_obs * (X_obs - Y_obs) ** 2, dim=1) +\\\n",
        "            2*(1-weight) * torch.sum(M_obs * (Y_obs_bj - X_obs) ** 2, dim=1)\n",
        "\n",
        "    outer = torch.sum(inner / n_obs_ot)\n",
        "\n",
        "    # compute the variance loss term if wanted\n",
        "    if compute_variance is not None:\n",
        "        var_loss_type = 2\n",
        "        if which_var_loss is not None:\n",
        "            var_loss_type = which_var_loss\n",
        "        outer += compute_var_loss(\n",
        "            X_obs, Y_obs, Y_obs_bj, n_obs_ot, batch_size, eps=1e-10,\n",
        "            weight=weight, M_obs=M_obs,\n",
        "            compute_variance=compute_variance, var_weight=var_weight,\n",
        "            Y_var_bj=Y_var_bj, Y_var=Y_var, dim_to=dim_to, type=var_loss_type)\n",
        "\n",
        "    return outer / batch_size\n",
        "\n",
        "def compute_loss_noisy_obs(\n",
        "        X_obs, Y_obs, Y_obs_bj, n_obs_ot, batch_size, eps=1e-10,\n",
        "        weight=0.5, M_obs=None,\n",
        "        compute_variance=None, var_weight=1.,\n",
        "        Y_var_bj=None, Y_var=None, dim_to=None, which_var_loss=None):\n",
        "    \"\"\"\n",
        "    similar to compute_loss, but only using the 2nd term of the original loss\n",
        "    function, which enables training with noisy observations\n",
        "    \"\"\"\n",
        "    if M_obs is None:\n",
        "        M_obs = 1.\n",
        "\n",
        "    inner = torch.sum(M_obs * (Y_obs_bj - X_obs) ** 2, dim=1)\n",
        "\n",
        "    outer = torch.sum(inner / n_obs_ot)\n",
        "\n",
        "    # compute the variance loss term if wanted\n",
        "    if compute_variance is not None:\n",
        "        var_loss_type = 3\n",
        "        if which_var_loss is not None:\n",
        "            var_loss_type = which_var_loss\n",
        "        outer += compute_var_loss(\n",
        "            X_obs, Y_obs, Y_obs_bj, n_obs_ot, batch_size, eps=1e-10,\n",
        "            weight=weight, M_obs=M_obs,\n",
        "            compute_variance=compute_variance, var_weight=var_weight,\n",
        "            Y_var_bj=Y_var_bj, Y_var=Y_var, dim_to=dim_to, type=var_loss_type)\n",
        "\n",
        "    return outer / batch_size\n",
        "\n",
        "def compute_jump_loss(\n",
        "        X_obs, Y_obs, Y_obs_bj, n_obs_ot, batch_size, eps=1e-10,\n",
        "        weight=0.5, M_obs=None, compute_variance=None, **kwargs):\n",
        "    \"\"\"\n",
        "    loss function with 1-norm instead of 2-norm for the two terms\n",
        "    intuitively this should lead to the conditional median instead of mean (not\n",
        "    proven)\n",
        "\n",
        "    :param X_obs: torch.tensor, the true X values at the observations\n",
        "    :param Y_obs: torch.tensor, the predicted values at the observation\n",
        "    :param Y_obs_bj: torch.tensor, the predicted values before the jump at the\n",
        "            observation\n",
        "    :param n_obs_ot: torch.tensor, the number of observations over the entire\n",
        "            time-line for each element of the batch\n",
        "    :param batch_size: int or float\n",
        "    :param eps: float, a small constant which is added before taking torch.sqrt\n",
        "            s.t. the sqrt never becomes zero (which would yield NaNs for the\n",
        "            gradient)\n",
        "    :param weight: float in [0,1], weighting of the two parts of the loss\n",
        "            function,\n",
        "                0.5: standard loss as described in paper\n",
        "                (0.5, 1): more weight to be correct after the jump, can be\n",
        "                theoretically justified similar to standard loss\n",
        "                1: only the value after the jump is trained\n",
        "    :param M_obs: None or torch.tensor, if not None: same size as X_obs with\n",
        "            0  and 1 entries, telling which coordinates were observed\n",
        "    :param kwargs: additional arguments, not used; to be compatible with the\n",
        "            other loss functions which allow for variance computations\n",
        "    :return: torch.tensor (with the loss, reduced to 1 dim)\n",
        "    \"\"\"\n",
        "    if M_obs is None:\n",
        "        M_obs = 1.\n",
        "\n",
        "    inner = torch.sum(M_obs * (X_obs - Y_obs) ** 2, dim=1)\n",
        "    outer = torch.sum(inner / n_obs_ot)\n",
        "\n",
        "    if compute_variance is not None:\n",
        "        warnings.warn(\"compute_variance not implemented for the loss function \"\n",
        "                      \"'compute_jump_loss'\", UserWarning)\n",
        "\n",
        "    return outer / batch_size\n",
        "\n",
        "LOSS_FUN_DICT = {\n",
        "    'easy': compute_loss_2,\n",
        "    'IO': compute_loss_IO,\n",
        "    'noisy_obs': compute_loss_noisy_obs,\n",
        "    'jump': compute_jump_loss,\n",
        "    'easy_vol': compute_loss_3,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9d_OfDcqm_s"
      },
      "outputs": [],
      "source": [
        "def init_weights(m, bias=0.0):  # initialize weights for model for linear NN\n",
        "    if type(m) == torch.nn.Linear:\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            m.bias.data.fill_(bias)\n",
        "\n",
        "nonlinears = {  # dictionary of used non-linear activation functions. Reminder inputs\n",
        "    'tanh': torch.nn.Tanh,\n",
        "    'relu': torch.nn.ReLU,\n",
        "    'prelu': torch.nn.PReLU,\n",
        "}\n",
        "\n",
        "def get_ffnn(input_size, output_size, nn_desc, dropout_rate, bias):\n",
        "    \"\"\"\n",
        "    function to get a feed-forward neural network with the given description\n",
        "    :param input_size: int, input dimension\n",
        "    :param output_size: int, output dimension\n",
        "    :param nn_desc: list of lists or None, each inner list defines one hidden\n",
        "            layer and has 2 elements: 1. int, the hidden dim, 2. str, the\n",
        "            activation function that should be applied (see dict nonlinears for\n",
        "            possible options)\n",
        "    :param dropout_rate: float,\n",
        "    :param bias: bool, whether a bias is used in the layers\n",
        "    :return: torch.nn.Sequential, the NN function\n",
        "    \"\"\"\n",
        "    if nn_desc is not None and len(nn_desc) == 0:\n",
        "        return torch.nn.Identity()\n",
        "    if nn_desc is None:\n",
        "        layers = [torch.nn.Linear(in_features=input_size, out_features=output_size, bias=bias)]  # take linear NN if\n",
        "        # not specified otherwise\n",
        "    else:\n",
        "        layers = [torch.nn.Linear(in_features=input_size, out_features=nn_desc[0][0], bias=bias)]  # first linear\n",
        "        # layer to specified dimension\n",
        "        if len(nn_desc) > 1:\n",
        "            for i in range(len(nn_desc) - 1):  # add multiple layers if multiple were given as input\n",
        "                layers.append(nonlinears[nn_desc[i][1]]())  # add layer with specified activation function\n",
        "                layers.append(torch.nn.Dropout(p=dropout_rate))  # add dropout layer\n",
        "                layers.append(\n",
        "                    torch.nn.Linear(nn_desc[i][0], nn_desc[i + 1][0],  # add linear layer between specified dimensions\n",
        "                                    bias=bias))\n",
        "        layers.append(nonlinears[nn_desc[-1][1]]())  # last specified activation function\n",
        "        layers.append(torch.nn.Dropout(p=dropout_rate))  # add another dropout layer\n",
        "        layers.append(torch.nn.Linear(in_features=nn_desc[-1][0], out_features=output_size, bias=bias))  # linear\n",
        "        # output layer\n",
        "    return torch.nn.Sequential(*layers)  # return the constructed NN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szfprPTYq7Ma"
      },
      "source": [
        "# NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAf18QxEq6hJ"
      },
      "outputs": [],
      "source": [
        "class ODEFunc(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    implementing continuous update between observatios, f_{\\theta} in paper\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, ode_nn, dropout_rate=0.0,\n",
        "                 bias=True, input_current_t=False, input_sig=False,\n",
        "                 sig_depth=3, coord_wise_tau=False, input_scaling_func=\"tanh\",\n",
        "                 use_current_y_for_ode=False, input_var_t_helper=False):\n",
        "        super().__init__()  # initialize class with given parameters\n",
        "        self.input_current_t = input_current_t\n",
        "        self.input_sig = input_sig\n",
        "        self.sig_depth = sig_depth\n",
        "        self.use_current_y_for_ode = use_current_y_for_ode\n",
        "        self.input_var_t_helper = input_var_t_helper\n",
        "        if input_scaling_func in [\"id\", \"identity\"]:\n",
        "            self.sc_fun = torch.nn.Identity()\n",
        "            print(\"neuralODE use input scaling with identity (no scaling)\")\n",
        "        else:\n",
        "            self.sc_fun = torch.tanh\n",
        "            print(\"neuralODE use input scaling with tanh\")\n",
        "\n",
        "        # create feed-forward NN, f(H,X,tau,t-tau)\n",
        "        if coord_wise_tau:\n",
        "            add = 2*input_size\n",
        "        else:\n",
        "            add = 2\n",
        "        if input_current_t:\n",
        "            if coord_wise_tau:\n",
        "                add += input_size\n",
        "            else:\n",
        "                add += 1\n",
        "        if input_var_t_helper:\n",
        "            if coord_wise_tau:\n",
        "                add += input_size\n",
        "            else:\n",
        "                add += 1\n",
        "        if input_sig:\n",
        "            add += sig_depth\n",
        "        if use_current_y_for_ode:\n",
        "            add += input_size\n",
        "        self.f = get_ffnn(  # get a feedforward NN with the given specifications\n",
        "            input_size=input_size + hidden_size + add, output_size=hidden_size,\n",
        "            nn_desc=ode_nn, dropout_rate=dropout_rate, bias=bias\n",
        "        )\n",
        "\n",
        "    def forward(self, x, h, tau, tdiff, signature=None, current_y=None,\n",
        "                delta_t=None):\n",
        "        # dimension should be (batch, input_size) for x, (batch, hidden) for h,\n",
        "        #    (batch, 1) for times\n",
        "\n",
        "        input_f = torch.cat([self.sc_fun(x), self.sc_fun(h), tau, tdiff], dim=1)\n",
        "\n",
        "        if self.input_current_t:\n",
        "            input_f = torch.cat([input_f, tau+tdiff], dim=1)\n",
        "        if self.input_var_t_helper:\n",
        "            input_f = torch.cat([input_f, 1/torch.sqrt(tdiff+delta_t)], dim=1)\n",
        "        if self.input_sig:\n",
        "            input_f = torch.cat([input_f, signature], dim=1)\n",
        "        if self.use_current_y_for_ode:\n",
        "            input_f = torch.cat([input_f, self.sc_fun(current_y)], dim=1)\n",
        "\n",
        "        df = self.f(input_f)\n",
        "        return df\n",
        "\n",
        "class FFNN(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Implements feed-forward neural networks with tanh applied to inputs and the\n",
        "    option to use a residual NN version\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_size, output_size, nn_desc, dropout_rate=0.0,\n",
        "                 bias=True, residual=False, masked=False, recurrent=False,\n",
        "                 input_sig=False, sig_depth=3, clamp=None, input_t=False,\n",
        "                 t_size=None, nb_outputs=None,\n",
        "                 **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "        self.use_lstm = False\n",
        "        if nn_desc is not None and isinstance(nn_desc[0][0], str) \\\n",
        "                and nn_desc[0][0].lower() == \"lstm\":\n",
        "            self.use_lstm = True\n",
        "            print(\"USE LSTM\")\n",
        "        in_size = input_size\n",
        "        if masked:\n",
        "            in_size = 2 * input_size\n",
        "        if recurrent and not self.use_lstm:\n",
        "            in_size += output_size\n",
        "        if input_sig:\n",
        "            in_size += sig_depth\n",
        "        self.masked = masked\n",
        "        self.recurrent = recurrent\n",
        "        self.output_size = output_size\n",
        "        self.nb_outputs = nb_outputs\n",
        "        if self.nb_outputs is None:\n",
        "            self.nb_outputs = 1\n",
        "        self.input_sig = input_sig\n",
        "        self.sig_depth = sig_depth\n",
        "        self.input_t = input_t\n",
        "        if self.input_t:\n",
        "            in_size += t_size\n",
        "        self.clamp = clamp\n",
        "        self.lstm = None\n",
        "        if self.use_lstm:\n",
        "            self.lstm = torch.nn.LSTMCell(\n",
        "                input_size=in_size, hidden_size=nn_desc[0][1], bias=bias)\n",
        "            self.c_h = None\n",
        "            in_size = nn_desc[0][1]*2\n",
        "            assert in_size == output_size, \\\n",
        "                \"when using an LSTM, the hidden_size has to be 2* \" \\\n",
        "                \"the LSTM output size\"\n",
        "            nn_desc = nn_desc[1:]\n",
        "        self.ffnn = get_ffnn(\n",
        "            input_size=in_size, output_size=self.output_size*self.nb_outputs,\n",
        "            nn_desc=nn_desc, dropout_rate=dropout_rate, bias=bias)\n",
        "\n",
        "        if residual:\n",
        "            print('use residual network: input_size={}, output_size={}'.format(\n",
        "                input_size, output_size))\n",
        "            if input_size <= output_size:\n",
        "                self.case = 1\n",
        "            if input_size > output_size:\n",
        "                self.case = 2\n",
        "        else:\n",
        "            self.case = 0\n",
        "\n",
        "    def forward(self, nn_input, mask=None, sig=None, h=None, t=None):\n",
        "        identity = None\n",
        "        if self.case == 1:\n",
        "            identity = torch.zeros((nn_input.shape[0], self.output_size)).to(\n",
        "                self.device)\n",
        "            identity[:, 0:nn_input.shape[1]] = nn_input\n",
        "        elif self.case == 2:\n",
        "            identity = nn_input[:, 0:self.output_size]\n",
        "\n",
        "        if self.recurrent or self.use_lstm:\n",
        "            assert h is not None\n",
        "            # x = torch.tanh(nn_input)\n",
        "            x = nn_input\n",
        "        else:\n",
        "            x = torch.tanh(nn_input)  # maybe not helpful\n",
        "        if self.recurrent and not self.use_lstm:\n",
        "            x = torch.cat((x, h), dim=1)\n",
        "        if self.input_t:\n",
        "            x = torch.cat((x, t), dim=1)\n",
        "        if self.masked:\n",
        "            assert mask is not None\n",
        "            x = torch.cat((x, mask), dim=1)\n",
        "        if self.input_sig:\n",
        "            assert sig is not None\n",
        "            x = torch.cat((x, sig), dim=1)\n",
        "        if self.use_lstm:\n",
        "            h_, c_ = torch.chunk(h, chunks=2, dim=1)\n",
        "            h_, c_ = self.lstm(x.float(), (h_, c_))\n",
        "            x = torch.concat((h_, c_), dim=1)\n",
        "        out = self.ffnn(x.float())\n",
        "\n",
        "        if self.nb_outputs > 1:\n",
        "            out = out.reshape(-1, self.output_size, self.nb_outputs)\n",
        "            if self.case > 0:\n",
        "                identity = identity.reshape(-1, self.output_size, 1).repeat(\n",
        "                    1, 1, self.nb_outputs)\n",
        "\n",
        "        if self.case == 0:\n",
        "            pass\n",
        "        else:\n",
        "            out = identity + out\n",
        "\n",
        "        if self.clamp is not None:\n",
        "            out = torch.clamp(out, min=-self.clamp, max=self.clamp)\n",
        "\n",
        "        return out\n",
        "\n",
        "    @property\n",
        "    def device(self):\n",
        "        device = next(self.parameters()).device\n",
        "        return device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dakQuNyrBwd"
      },
      "source": [
        "# model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9sQKgBqrDNu"
      },
      "outputs": [],
      "source": [
        "class NJODE(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    NJ-ODE model\n",
        "    \"\"\"\n",
        "    def __init__(  # initialize the class by naming relevant features\n",
        "            self, input_size, hidden_size, output_size,\n",
        "            ode_nn, readout_nn, enc_nn, use_rnn,\n",
        "            bias=True, dropout_rate=0, solver=\"euler\",\n",
        "            input_coords=None, output_coords=None,\n",
        "            signature_coords=None, compute_variance=None, var_size=0,\n",
        "            **options\n",
        "    ):\n",
        "        \"\"\"\n",
        "        init the model\n",
        "        :param input_size: int\n",
        "        :param hidden_size: int, size of latent variable process\n",
        "        :param output_size: int\n",
        "        :param ode_nn: list of list, defining the NN f, see get_ffnn\n",
        "        :param readout_nn: list of list, defining the NN g, see get_ffnn\n",
        "        :param enc_nn: list of list, defining the NN e, see get_ffnn\n",
        "        :param use_rnn: bool, whether to use the RNN for 'jumps'\n",
        "        :param bias: bool, whether to use a bias for the NNs\n",
        "        :param dropout_rate: float\n",
        "        :param solver: str, specifying the ODE solver, suppoorted: {'euler'}\n",
        "        :param weight: float in [0.5, 1], the initial weight used in the loss\n",
        "        :param weight_decay: float in [0,1], the decay applied to the weight of\n",
        "                the loss function after each epoch, decaying towards 0.5\n",
        "                    1: no decay, weight stays the same\n",
        "                    0: immediate decay to 0.5 after 1st epoch\n",
        "                    (0,1): exponential decay towards 0.5\n",
        "        :param level: level for signature transform\n",
        "        :param input_coords: list of int, the coordinates of the input\n",
        "        :param output_coords: list of int, the coordinates of the output\n",
        "        :param signature_coords: list of int, the coordinates of the signature\n",
        "        :param compute_variance: None or one of {\"variance\", \"covariance\"},\n",
        "                whether to compute the (marginal) variance or covariance matrix\n",
        "        :param var_size: int, the size of the model variance estimate; this is\n",
        "                already included in the output_size, but the variance\n",
        "                coordinates are not included in the output_coords\n",
        "        :param options: kwargs, used:\n",
        "                - \"classifier_nn\"\n",
        "                - \"options\" with arg a dict passed from train.train\n",
        "                    used kwords: 'which_loss', 'residual_enc_dec',\n",
        "                    'residual_enc', 'residual_dec',\n",
        "                    'masked', 'input_current_t', 'input_sig', 'level',\n",
        "                    'use_y_for_ode', 'enc_input_t', 'use_current_y_for_ode',\n",
        "                    'use_observation_as_input', 'coord_wise_tau', 'clamp',\n",
        "                    'ode_input_scaling_func', 'use_sig_for_classifier',\n",
        "                    'classifier_loss_weight'\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.epoch = 1\n",
        "        self.retrain_epoch = 0\n",
        "        self.weight = 0.5\n",
        "        self.use_rnn = use_rnn\n",
        "        self.input_coords = input_coords\n",
        "        self.output_coords = output_coords\n",
        "        self.signature_coords = signature_coords\n",
        "        self.compute_variance = compute_variance\n",
        "        self.var_size = var_size\n",
        "        self.var_weight = 1.\n",
        "        self.which_var_loss = None\n",
        "\n",
        "        # get options from the options of train input\n",
        "        options1 = options['options']\n",
        "        if 'which_loss' in options1:\n",
        "            self.which_loss = options1['which_loss']\n",
        "        else:\n",
        "            self.which_loss = 'easy'\n",
        "        assert self.which_loss in LOSS_FUN_DICT\n",
        "        print('using loss: {}'.format(self.which_loss))\n",
        "        if \"var_weight\" in options1:\n",
        "            self.var_weight = options1['var_weight']\n",
        "            print(\"using variance loss weight:\", self.var_weight)\n",
        "        if \"which_var_loss\" in options1:\n",
        "            self.which_var_loss = options1['which_var_loss']\n",
        "            print(\"using variance loss:\", self.which_var_loss)\n",
        "\n",
        "        self.residual_enc = True\n",
        "        self.residual_dec = True\n",
        "        if 'residual_enc_dec' in options1:\n",
        "            residual_enc_dec = options1['residual_enc_dec']\n",
        "            self.residual_enc = residual_enc_dec\n",
        "            self.residual_dec = residual_enc_dec\n",
        "        if 'residual_enc' in options1:\n",
        "            self.residual_enc = options1['residual_enc']\n",
        "        if 'residual_dec' in options1:\n",
        "            self.residual_dec = options1['residual_dec']\n",
        "\n",
        "        self.input_current_t = False\n",
        "        if 'input_current_t' in options1:\n",
        "            self.input_current_t = options1['input_current_t']\n",
        "        self.input_var_t_helper = False\n",
        "        if 'input_var_t_helper' in options1:\n",
        "            self.input_var_t_helper = options1['input_var_t_helper']\n",
        "        self.input_sig = False\n",
        "        if 'input_sig' in options1:\n",
        "            self.input_sig = options1['input_sig']\n",
        "        self.level = 2\n",
        "        if 'level' in options1:\n",
        "            self.level = options1['level']\n",
        "        self.sig_depth = sig.siglength(len(self.signature_coords)+1, self.level)\n",
        "        self.masked = False\n",
        "        if 'masked' in options1:\n",
        "            self.masked = options1['masked']\n",
        "        self.use_y_for_ode = False\n",
        "        if 'use_y_for_ode' in options1:\n",
        "            self.use_y_for_ode = options1['use_y_for_ode']\n",
        "        self.use_current_y_for_ode = False\n",
        "        if 'use_current_y_for_ode' in options1:\n",
        "            self.use_current_y_for_ode = options1['use_current_y_for_ode']\n",
        "        self.coord_wise_tau = False\n",
        "        if 'coord_wise_tau' in options1 and self.masked:\n",
        "            self.coord_wise_tau = options1['coord_wise_tau']\n",
        "        self.enc_input_t = False\n",
        "        if 'enc_input_t' in options1:\n",
        "            self.enc_input_t = options1['enc_input_t']\n",
        "        self.clamp = None\n",
        "        if 'clamp' in options1:\n",
        "            self.clamp = options1['clamp']\n",
        "        self.ode_input_scaling_func = \"tanh\"\n",
        "        if 'ode_input_scaling_func' in options1:\n",
        "            self.ode_input_scaling_func = options1['ode_input_scaling_func']\n",
        "        self.loss_weight = 1.\n",
        "        t_size = 2\n",
        "        if self.coord_wise_tau:\n",
        "            t_size = 2*input_size\n",
        "        use_observation_as_input = None\n",
        "        if 'use_observation_as_input' in options1:\n",
        "            use_observation_as_input = options1['use_observation_as_input']\n",
        "        if use_observation_as_input is None:\n",
        "            self.use_observation_as_input = lambda x: True\n",
        "        elif isinstance(use_observation_as_input, bool):\n",
        "            self.use_observation_as_input = \\\n",
        "                lambda x: use_observation_as_input\n",
        "        elif isinstance(use_observation_as_input, float):\n",
        "            self.use_observation_as_input = \\\n",
        "                lambda x: np.random.random() < use_observation_as_input\n",
        "        elif isinstance(use_observation_as_input, str):\n",
        "            self.use_observation_as_input = \\\n",
        "                eval(use_observation_as_input)\n",
        "        val_use_observation_as_input = None\n",
        "        if 'val_use_observation_as_input' in options1:\n",
        "            val_use_observation_as_input = \\\n",
        "                options1['val_use_observation_as_input']\n",
        "        if val_use_observation_as_input is None:\n",
        "            self.val_use_observation_as_input = self.use_observation_as_input\n",
        "        elif isinstance(val_use_observation_as_input, bool):\n",
        "            self.val_use_observation_as_input = \\\n",
        "                lambda x: val_use_observation_as_input\n",
        "        elif isinstance(val_use_observation_as_input, float):\n",
        "            self.val_use_observation_as_input = \\\n",
        "                lambda x: np.random.random() < val_use_observation_as_input\n",
        "        elif isinstance(val_use_observation_as_input, str):\n",
        "            self.val_use_observation_as_input = \\\n",
        "                eval(val_use_observation_as_input)\n",
        "\n",
        "        self.ode_f = ODEFunc(\n",
        "            input_size=input_size, hidden_size=hidden_size, ode_nn=ode_nn,\n",
        "            dropout_rate=dropout_rate, bias=bias,\n",
        "            input_current_t=self.input_current_t, input_sig=self.input_sig,\n",
        "            sig_depth=self.sig_depth, coord_wise_tau=self.coord_wise_tau,\n",
        "            input_scaling_func=self.ode_input_scaling_func,\n",
        "            use_current_y_for_ode=self.use_current_y_for_ode,\n",
        "            input_var_t_helper=self.input_var_t_helper)\n",
        "        self.encoder_map = FFNN(\n",
        "            input_size=input_size, output_size=hidden_size, nn_desc=enc_nn,\n",
        "            dropout_rate=dropout_rate, bias=bias, recurrent=self.use_rnn,\n",
        "            masked=self.masked, residual=self.residual_enc,\n",
        "            input_sig=self.input_sig, sig_depth=self.sig_depth,\n",
        "            input_t=self.enc_input_t, t_size=t_size)\n",
        "        self.readout_map = FFNN(\n",
        "            input_size=hidden_size, output_size=output_size, nn_desc=readout_nn,\n",
        "            dropout_rate=dropout_rate, bias=bias,\n",
        "            residual=self.residual_dec, clamp=self.clamp,\n",
        "            nb_outputs=None)\n",
        "\n",
        "        self.solver = solver\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.apply(init_weights)\n",
        "\n",
        "    @property\n",
        "    def device(self):\n",
        "        device = next(self.parameters()).device\n",
        "        return device\n",
        "\n",
        "    def ode_step(self, h, delta_t, current_time, last_X, tau, signature=None,\n",
        "                 current_y=None):\n",
        "        \"\"\"Executes a single ODE step\"\"\"\n",
        "        if not self.input_sig:\n",
        "            signature = None\n",
        "        if self.solver == \"euler\":\n",
        "            h = h + delta_t * self.ode_f(\n",
        "                x=last_X, h=h, tau=tau, tdiff=current_time - tau,\n",
        "                signature=signature, current_y=current_y, delta_t=delta_t)\n",
        "        else:\n",
        "            raise ValueError(\"Unknown solver '{}'.\".format(self.solver))\n",
        "\n",
        "        current_time += delta_t\n",
        "        return h, current_time\n",
        "\n",
        "    def recreate_data(self, times, time_ptr, X, obs_idx, start_X):\n",
        "        \"\"\"\n",
        "        recreates matrix of all observations\n",
        "        first dim: which data path\n",
        "        second dim: which time\n",
        "        \"\"\"\n",
        "        # shape: [batch_size, time_steps+1, dimension]\n",
        "        data = np.empty(shape=(start_X.shape[0], 1+len(times), start_X.shape[1]))\n",
        "        data[:] = np.nan\n",
        "        data[:,0,:] = start_X.detach().cpu().numpy()\n",
        "\n",
        "        X = X.detach().cpu().numpy()\n",
        "        for j, time in enumerate(times):\n",
        "            start = time_ptr[j]\n",
        "            end = time_ptr[j + 1]\n",
        "            X_obs = X[start:end]\n",
        "            i_obs = obs_idx[start:end]\n",
        "            data[i_obs, j+1, :] = X_obs\n",
        "        times_new = np.concatenate(([0], times), axis=0)\n",
        "\n",
        "        return times_new, data\n",
        "\n",
        "    def get_signature(self, times, time_ptr, X, obs_idx, start_X):\n",
        "        \"\"\"\n",
        "        Input: See forward\n",
        "        Returns: signature of paths as nested list\n",
        "        \"\"\"\n",
        "        # reconstructing the data, shape: [batch_size, time_steps+1, dim]\n",
        "        times_new, data = self.recreate_data(\n",
        "            times=times, time_ptr=time_ptr, X=X, obs_idx=obs_idx,\n",
        "            start_X=start_X)\n",
        "\n",
        "        # list of list of lists, shape: [batch_size, obs_dates[j], sig_length]\n",
        "        signature = []\n",
        "        for j in range(data.shape[0]):  # iterate over batch\n",
        "            data_j = data[j, :, :]\n",
        "            observed_j = []\n",
        "            for i in range(data_j.shape[0]):\n",
        "                # if the current batch-sample has an observation at the current\n",
        "                #   time, add it to the list of observations\n",
        "                if not np.all(np.isnan(data_j[i])):\n",
        "                    observed_j += [i]\n",
        "            data_j = data_j[observed_j, :]\n",
        "\n",
        "            # replace no observations with last observation\n",
        "            for i in range(1, data_j.shape[0]):\n",
        "                # # OLD VERSION (SLOW)\n",
        "                # for k in range(data_j.shape[1]):\n",
        "                #     if np.isnan(data_j[i, k]):\n",
        "                #         data_j[i, k] = data_j[i-1, k]\n",
        "                ks = np.isnan(data_j[i, :])\n",
        "                data_j[i, ks] = data_j[i-1, ks]\n",
        "\n",
        "            times_j = times_new[observed_j].reshape(-1, 1)\n",
        "            # add times to data for signature call\n",
        "            path_j = np.concatenate((times_j, data_j), axis=1)\n",
        "            # the following computes the signatures of all partial paths, from\n",
        "            #   start to each point of the path\n",
        "            signature.append(sig.sig(path_j, self.level, 2))\n",
        "\n",
        "        return signature\n",
        "\n",
        "    def forward(self, times, time_ptr, X, obs_idx, delta_t, T, start_X,\n",
        "                n_obs_ot, return_path=False, get_loss=True, until_T=False,\n",
        "                M=None, start_M=None, which_loss=None, dim_to=None,\n",
        "                predict_labels=None, return_classifier_out=False,\n",
        "                return_at_last_obs=False, compute_variance_loss=True):\n",
        "        \"\"\"\n",
        "        the forward run of this module class, used when calling the module\n",
        "        instance without a method\n",
        "        :param times: np.array, of observation times\n",
        "        :param time_ptr: list, start indices of X and obs_idx for a given\n",
        "                observation time, first element is 0, this pointer tells how\n",
        "                many (and which) of the observations of X along the batch-dim\n",
        "                belong to the current time, and obs_idx then tells to which of\n",
        "                the batch elements they belong. In particular, not each batch-\n",
        "                element has to jump at the same time, and only those elements\n",
        "                which jump at the current time should be updated with a jump\n",
        "        :param X: torch.tensor, data tensor\n",
        "        :param obs_idx: list, index of the batch elements where jumps occur at\n",
        "                current time\n",
        "        :param delta_t: float, time step for Euler\n",
        "        :param T: float, the final time\n",
        "        :param start_X: torch.tensor, the starting point of X\n",
        "        :param n_obs_ot: torch.tensor, the number of observations over the\n",
        "                entire time interval for each element of the batch\n",
        "        :param return_path: bool, whether to return the path of h\n",
        "        :param get_loss: bool, whether to compute the loss, otherwise 0 returned\n",
        "        :param until_T: bool, whether to continue until T (for eval) or only\n",
        "                until last observation (for training)\n",
        "        :param M: None or torch.tensor, if not None: the mask for the data, same\n",
        "                size as X, with 0 or 1 entries\n",
        "        :param start_M: None or torch.tensor, if not None: the mask for start_X,\n",
        "                same size as start_X\n",
        "        :param which_loss: see train.train, to overwrite which loss for eval\n",
        "        :param dim_to: None or int, if given not all coordinates along the\n",
        "                data-dimension axis are used but only up to dim_to. this can be\n",
        "                used if func_appl_X is used in train, but the loss etc. should\n",
        "                only be computed for the original coordinates (without those\n",
        "                resulting from the function applications)\n",
        "        :param predict_labels: None or torch.tensor with the true labels to\n",
        "                predict\n",
        "        :param return_classifier_out: bool, whether to return the output of the\n",
        "                classifier\n",
        "        :param return_at_last_obs: bool, whether to return the hidden state at\n",
        "                the last observation time or at the final time\n",
        "        :param epoch: int, the current epoch\n",
        "        :param compute_variance_loss: bool, whether to compute the variance\n",
        "                loss (in case self.compute_variance is not None). default: True\n",
        "\n",
        "        :return: torch.tensor (hidden state at final time), torch.tensor (loss),\n",
        "                    if wanted the paths of t (np.array) and h, y (torch.tensors)\n",
        "        \"\"\"\n",
        "        if which_loss is None:\n",
        "            which_loss = self.which_loss\n",
        "        LOSS = LOSS_FUN_DICT[which_loss]\n",
        "\n",
        "        last_X = start_X\n",
        "        batch_size = start_X.size()[0]\n",
        "        data_dim = start_X.size()[1]\n",
        "        if dim_to is None:\n",
        "            dim_to = len(self.output_coords)\n",
        "        out_coords = self.output_coords[:dim_to]\n",
        "\n",
        "        impute = False\n",
        "        if (len(self.input_coords) == len(self.output_coords) and\n",
        "                np.all(self.input_coords == self.output_coords)):\n",
        "            impute = True\n",
        "        if not impute and self.use_y_for_ode:\n",
        "            raise ValueError(\n",
        "                \"use_y_for_ode can only be used when imputation is possible, \"\n",
        "                \"i.e., when input and output coordinates are the same\")\n",
        "\n",
        "\n",
        "        if self.coord_wise_tau:\n",
        "            tau = torch.tensor([[0.0]]).repeat(batch_size, self.input_size).to(\n",
        "                self.device)\n",
        "        else:\n",
        "            tau = torch.tensor([[0.0]]).repeat(batch_size, 1).to(\n",
        "                self.device)\n",
        "        current_time = 0.0\n",
        "        loss = torch.tensor(0.).to(self.device)\n",
        "        c_sig = None\n",
        "\n",
        "        if self.input_sig:\n",
        "            if X.shape[0] == 0:  # if no data, set signature to 0\n",
        "                pass\n",
        "            elif self.masked:\n",
        "                Mdc = M.clone()\n",
        "                Mdc[Mdc==0] = np.nan\n",
        "                X_obs_impute = X * Mdc\n",
        "                signature = self.get_signature(\n",
        "                    times=times, time_ptr=time_ptr,\n",
        "                    X=X_obs_impute[:, self.signature_coords],\n",
        "                    obs_idx=obs_idx, start_X=start_X[:, self.signature_coords])\n",
        "            else:\n",
        "                signature = self.get_signature(\n",
        "                    times=times, time_ptr=time_ptr,\n",
        "                    X=X[:, self.signature_coords],\n",
        "                    obs_idx=obs_idx, start_X=start_X[:, self.signature_coords])\n",
        "\n",
        "            # in beginning, no path was observed => set sig to 0\n",
        "            current_sig = np.zeros((batch_size, self.sig_depth))\n",
        "            current_sig_nb = np.zeros(batch_size).astype(int)\n",
        "            c_sig = torch.from_numpy(current_sig).float().to(self.device)\n",
        "\n",
        "        if self.masked:\n",
        "            if start_M is None:\n",
        "                start_M = torch.ones_like(start_X)\n",
        "                start_M = start_M[:, self.input_coords]\n",
        "        else:\n",
        "            start_M = None\n",
        "\n",
        "        h = self.encoder_map(\n",
        "            start_X[:, self.input_coords], mask=start_M,\n",
        "            sig=c_sig,\n",
        "            h=torch.zeros((batch_size, self.hidden_size)).to(self.device),\n",
        "            t=torch.cat((tau, current_time - tau), dim=1).to(self.device))\n",
        "\n",
        "        if return_path:\n",
        "            path_t = [0]\n",
        "            path_h = [h]\n",
        "            y = self.readout_map(h)\n",
        "            if self.var_size > 0:\n",
        "                path_y = [y[:, :-self.var_size]]\n",
        "                path_var = [y[:, -self.var_size:]]\n",
        "            else:\n",
        "                path_y = [y]\n",
        "                path_var = None\n",
        "        h_at_last_obs = h.clone()\n",
        "        sig_at_last_obs = c_sig\n",
        "\n",
        "        assert len(times) + 1 == len(time_ptr)\n",
        "\n",
        "        for i, obs_time in enumerate(times):\n",
        "            # Propagation of the ODE until next observation\n",
        "            while current_time < (obs_time - 1e-10 * delta_t):  # 0.0001 delta_t used for numerical consistency.\n",
        "                if current_time < obs_time - delta_t:\n",
        "                    delta_t_ = delta_t\n",
        "                else:\n",
        "                    delta_t_ = obs_time - current_time\n",
        "                if self.solver == 'euler':\n",
        "                    h, current_time = self.ode_step(\n",
        "                        h, delta_t_, current_time,\n",
        "                        last_X=last_X[:, self.input_coords], tau=tau,\n",
        "                        signature=c_sig, current_y=self.readout_map(h))\n",
        "                    current_time_nb = int(round(current_time / delta_t))\n",
        "                else:\n",
        "                    raise NotImplementedError\n",
        "\n",
        "                # Storing the predictions.\n",
        "                if return_path:\n",
        "                    path_t.append(current_time)\n",
        "                    path_h.append(h)\n",
        "                    y = self.readout_map(h)\n",
        "                    if self.var_size > 0:\n",
        "                        path_y.append(y[:, :-self.var_size])\n",
        "                        path_var.append(y[:, -self.var_size:])\n",
        "                    else:\n",
        "                        path_y.append(y)\n",
        "\n",
        "            # Reached an observation - only update those elements of the batch,\n",
        "            #    for which an observation is made\n",
        "            start = time_ptr[i]\n",
        "            end = time_ptr[i + 1]\n",
        "            X_obs = X[start:end]\n",
        "            i_obs = obs_idx[start:end]\n",
        "            if self.masked:\n",
        "                if isinstance(M, np.ndarray):\n",
        "                    M_obs = torch.from_numpy(M[start:end]).to(self.device)\n",
        "                else:\n",
        "                    M_obs = M[start:end]\n",
        "                M_obs_in = M_obs[:, self.input_coords]\n",
        "                M_obs_out = M_obs[:, out_coords]\n",
        "                M_obs_sig = M_obs[:, self.signature_coords]\n",
        "            else:\n",
        "                M_obs = None\n",
        "                M_obs_in = None\n",
        "                M_obs_out = None\n",
        "                M_obs_sig = None\n",
        "\n",
        "            # decide whether to use observation as input\n",
        "            if self.training:  # check whether model is in training or eval mode\n",
        "                use_as_input = self.use_observation_as_input(self.epoch)\n",
        "            else:\n",
        "                use_as_input = self.val_use_observation_as_input(self.epoch)\n",
        "\n",
        "            # update signature\n",
        "            if self.input_sig:\n",
        "                for ij, j in enumerate(i_obs):\n",
        "                    # the signature is updated only if one of the sig-coords is\n",
        "                    #   observed -> hence, it can happen that even though the\n",
        "                    #   j-th batch sample is observed, the signature is not\n",
        "                    #   updated because none of the sig-coords is observed\n",
        "                    if M_obs_sig is None or M_obs_sig[ij].sum() > 0:\n",
        "                        current_sig[j, :] = signature[j][current_sig_nb[j]]\n",
        "                        current_sig_nb[j] += 1\n",
        "                if use_as_input:\n",
        "                    c_sig = torch.from_numpy(current_sig).float().to(\n",
        "                        self.device)\n",
        "\n",
        "            # Using RNNCell to update h. Also updating loss, tau and last_X\n",
        "            Y_bj = self.readout_map(h)\n",
        "            if use_as_input:\n",
        "                X_obs_impute = X_obs\n",
        "                temp = h.clone()\n",
        "                if self.masked:\n",
        "                    if impute:\n",
        "                        # self imputation only possible if input and output are\n",
        "                        #    the same and no quantile loss is used\n",
        "                        X_obs_impute = X_obs * M_obs + (torch.ones_like(\n",
        "                            M_obs.long()) - M_obs) * Y_bj[i_obs.long(), :data_dim]\n",
        "                    else:\n",
        "                        # otherwise set all masked entries to last value of X\n",
        "                        X_obs_impute = X_obs * M_obs + (1-M_obs) * last_X\n",
        "                c_sig_iobs = None\n",
        "                if self.input_sig:\n",
        "                    c_sig_iobs = c_sig[i_obs]\n",
        "                temp[i_obs.long()] = self.encoder_map(\n",
        "                    X_obs_impute[:, self.input_coords],\n",
        "                    mask=M_obs_in, sig=c_sig_iobs, h=h[i_obs],\n",
        "                    t=torch.cat((tau[i_obs], current_time - tau[i_obs]), dim=1))\n",
        "                h = temp\n",
        "                Y = self.readout_map(h)\n",
        "\n",
        "                # update h and sig at last observation\n",
        "                h_at_last_obs[i_obs.long()] = h[i_obs.long()].clone()\n",
        "                sig_at_last_obs = c_sig\n",
        "            else:\n",
        "                Y = Y_bj\n",
        "\n",
        "            if get_loss:\n",
        "                Y_var_bj = None\n",
        "                Y_var = None\n",
        "                if self.var_size > 0:\n",
        "                    Y_var_bj = Y_bj[i_obs.long(), -self.var_size:]\n",
        "                    Y_var = Y[i_obs.long(), -self.var_size:]\n",
        "\n",
        "                # INFO: X_obs has input and output coordinates, out_coords only\n",
        "                #   has the output coordinates until dim_to; Y_obs has only the\n",
        "                #   output coordinates (+ the var coords appended in the end),\n",
        "                #   so taking them until dim_to (which is at max the size of the\n",
        "                #   output_coords) corresponds to the out_coords\n",
        "                if compute_variance_loss:\n",
        "                    compute_variance = self.compute_variance\n",
        "                else:\n",
        "                    compute_variance = None\n",
        "                if which_loss=='easy_vol':\n",
        "                    unused_coords = [0]\n",
        "                    loss = loss + LOSS(\n",
        "                        X_obs_bj=X_obs[:,unused_coords ] , X_obs=X_obs[:, out_coords], Y_obs=Y[i_obs.long(), :dim_to],\n",
        "                        Y_obs_bj=Y_bj[i_obs.long(), :dim_to],\n",
        "                        n_obs_ot=n_obs_ot[i_obs.long()], batch_size=batch_size,\n",
        "                        weight=self.weight, M_obs=M_obs_out,\n",
        "                        compute_variance=compute_variance,\n",
        "                        var_weight=self.var_weight,\n",
        "                        Y_var_bj=Y_var_bj, Y_var=Y_var, dim_to=dim_to,\n",
        "                        which_var_loss=self.which_var_loss)\n",
        "                else:\n",
        "                  loss = loss + LOSS(\n",
        "                      X_obs=X_obs[:, out_coords], Y_obs=Y[i_obs.long(), :dim_to],\n",
        "                      Y_obs_bj=Y_bj[i_obs.long(), :dim_to],\n",
        "                      n_obs_ot=n_obs_ot[i_obs.long()], batch_size=batch_size,\n",
        "                      weight=self.weight, M_obs=M_obs_out,\n",
        "                      compute_variance=compute_variance,\n",
        "                      var_weight=self.var_weight,\n",
        "                      Y_var_bj=Y_var_bj, Y_var=Y_var, dim_to=dim_to,\n",
        "                      which_var_loss=self.which_var_loss)\n",
        "\n",
        "            # make update of last_X and tau, that is not inplace\n",
        "            #    (otherwise problems in autograd)\n",
        "            if use_as_input:\n",
        "              temp_X = last_X.clone()\n",
        "              temp_tau = tau.clone()\n",
        "              if self.use_y_for_ode:\n",
        "                  temp_X[i_obs.long()] = Y[i_obs.long(), :data_dim]\n",
        "              else:\n",
        "                  temp_X[i_obs.long()] = X_obs_impute\n",
        "              if self.coord_wise_tau:\n",
        "                  _M = torch.zeros_like(temp_tau)\n",
        "                  _M[i_obs] = M_obs[:, self.input_coords]\n",
        "                  temp_tau[_M==1] = obs_time.astype(np.float64)\n",
        "              else:\n",
        "                  temp_tau[i_obs.long()] = obs_time.astype(np.float64)\n",
        "              last_X = temp_X\n",
        "              tau = temp_tau\n",
        "\n",
        "            if return_path:\n",
        "                path_t.append(obs_time)\n",
        "                path_h.append(h)\n",
        "                if self.var_size > 0:\n",
        "                    path_y.append(Y[:, :-self.var_size])\n",
        "                    path_var.append(Y[:, -self.var_size:])\n",
        "                else:\n",
        "                    path_y.append(Y)\n",
        "\n",
        "        # after every observation has been processed, propagating until T\n",
        "        if until_T:\n",
        "            while current_time < T - 1e-10 * delta_t:\n",
        "                if current_time < T - delta_t:\n",
        "                    delta_t_ = delta_t\n",
        "                else:\n",
        "                    delta_t_ = T - current_time\n",
        "                if self.solver == 'euler':\n",
        "                    h, current_time = self.ode_step(\n",
        "                        h, delta_t_, current_time, last_X=last_X, tau=tau,\n",
        "                        signature=c_sig, current_y=self.readout_map(h))\n",
        "                else:\n",
        "                    raise NotImplementedError\n",
        "\n",
        "                # Storing the predictions.\n",
        "                if return_path:\n",
        "                    path_t.append(current_time)\n",
        "                    path_h.append(h)\n",
        "                    y = self.readout_map(h)\n",
        "                    if self.var_size > 0:\n",
        "                        path_y.append(y[:, :-self.var_size])\n",
        "                        path_var.append(y[:, -self.var_size:])\n",
        "                    else:\n",
        "                        path_y.append(y)\n",
        "\n",
        "        if return_at_last_obs:\n",
        "            return h_at_last_obs, sig_at_last_obs\n",
        "        if return_path:\n",
        "            # path dimension: [time_steps, batch_size, output_size]\n",
        "            var_path = None\n",
        "            if self.var_size > 0:\n",
        "                var_path = torch.stack(path_var)\n",
        "            return h, loss, np.array(path_t), torch.stack(path_h), \\\n",
        "                   torch.stack(path_y)[:, :, :dim_to], var_path\n",
        "        else:\n",
        "            return h, loss\n",
        "\n",
        "    def evaluate(self, times, time_ptr, X, obs_idx, delta_t, T, start_X,\n",
        "                 n_obs_ot, stockmodel, cond_exp_fun_kwargs=None,\n",
        "                 diff_fun=lambda x, y: np.nanmean((x - y) ** 2),\n",
        "                 return_paths=False, M=None, true_paths=None, start_M=None,\n",
        "                 true_mask=None, mult=None, use_stored_cond_exp=False,):\n",
        "        \"\"\"\n",
        "        evaluate the model at its current training state against the true\n",
        "        conditional expectation\n",
        "        :param times: see forward\n",
        "        :param time_ptr: see forward\n",
        "        :param X: see forward\n",
        "        :param obs_idx: see forward\n",
        "        :param delta_t: see forward\n",
        "        :param T: see forward\n",
        "        :param start_X: see forward\n",
        "        :param n_obs_ot: see forward\n",
        "        :param stockmodel: stock_model.StockModel instance, used to compute true\n",
        "                cond. exp.\n",
        "        :param cond_exp_fun_kwargs: dict, the kwargs for the cond. exp. function\n",
        "                currently not used\n",
        "        :param diff_fun: function, to compute difference between optimal and\n",
        "                predicted cond. exp\n",
        "        :param return_paths: bool, whether to return also the paths\n",
        "        :param M: see forward\n",
        "        :param start_M: see forward\n",
        "        :param true_paths: np.array, shape [batch_size, dimension, time_steps+1]\n",
        "        :param true_mask: as true_paths, with mask entries\n",
        "        :param mult: None or int, if given not all coordinates along the\n",
        "                data-dimension axis are used but only up to dim/mult. this can be\n",
        "                used if func_appl_X is used in train, but the loss etc. should\n",
        "                only be computed for the original coordinates (without those\n",
        "                resulting from the function applications)\n",
        "        :param use_stored_cond_exp: bool, whether to recompute the cond. exp.\n",
        "\n",
        "        :return: eval-loss, if wanted paths t, y for true and pred\n",
        "        \"\"\"\n",
        "        self.eval()\n",
        "\n",
        "        dim = start_X.shape[1]\n",
        "        dim_to = dim\n",
        "        output_dim_to = len(self.output_coords)\n",
        "        if mult is not None and mult > 1:\n",
        "            dim_to = round(dim/mult)\n",
        "            output_dim_to = round(len(self.output_coords)/mult)\n",
        "\n",
        "        _, _, path_t, path_h, path_y, path_var = self.forward(\n",
        "            times, time_ptr, X, obs_idx, delta_t, T, start_X, None,\n",
        "            return_path=True, get_loss=False, until_T=True, M=M,\n",
        "            start_M=start_M, dim_to=output_dim_to)\n",
        "\n",
        "        if true_paths is None:\n",
        "            if M is not None:\n",
        "                M = M.detach().numpy()[:, :dim_to]\n",
        "            if X.shape[0] > 0:  # if no data (eg. bc. obs_perc=0, not possible)\n",
        "                X = X.detach().numpy()[:, :dim_to]\n",
        "            _, true_path_t, true_path_y = stockmodel.compute_cond_exp(\n",
        "                times, time_ptr, X,\n",
        "                obs_idx.detach().numpy(),\n",
        "                delta_t, T, start_X.detach().numpy()[:, :dim_to],\n",
        "                n_obs_ot.detach().numpy(),\n",
        "                return_path=True, get_loss=False, M=M,\n",
        "                store_and_use_stored=use_stored_cond_exp)\n",
        "        else:\n",
        "            true_t = np.linspace(0, T, true_paths.shape[2])\n",
        "            which_t_ind = []\n",
        "            for t in path_t:\n",
        "                which_t_ind.append(np.argmin(np.abs(true_t - t)))\n",
        "            # INFO: first get the correct output coordinate, then the correct\n",
        "            #   time index; afterwards transpose to [time, batch_size, dim]\n",
        "            true_path_y = true_paths[:, self.output_coords[:output_dim_to], :][\n",
        "                :, :, which_t_ind]\n",
        "            true_path_y = np.transpose(true_path_y, axes=(2, 0, 1))\n",
        "            true_path_t = true_t[which_t_ind]\n",
        "\n",
        "        if path_y.detach().numpy().shape == true_path_y.shape:\n",
        "            eval_metric = diff_fun(path_y.detach().numpy(), true_path_y)\n",
        "        else:\n",
        "            print(path_y.detach().numpy().shape)\n",
        "            print(true_path_y.shape)\n",
        "            raise ValueError(\"Shapes do not match!\")\n",
        "        if return_paths:\n",
        "            return eval_metric, path_t, true_path_t, path_y, true_path_y\n",
        "        else:\n",
        "            return eval_metric\n",
        "\n",
        "    def get_pred(self, times, time_ptr, X, obs_idx, delta_t, T, start_X,\n",
        "                 n_obs_ot, M=None, start_M=None, which_loss=None):\n",
        "        \"\"\"\n",
        "        get predicted path\n",
        "        :return: dict, with prediction y and times t\n",
        "        \"\"\"\n",
        "        self.eval()\n",
        "        h, loss, path_t, path_h, path_y, path_var = self.forward(\n",
        "            times=times, time_ptr=time_ptr, X=X, obs_idx=obs_idx,\n",
        "            delta_t=delta_t, T=T, start_X=start_X, n_obs_ot=n_obs_ot,\n",
        "            return_path=True, get_loss=True, until_T=True, M=M,\n",
        "            start_M=start_M, which_loss=which_loss)\n",
        "        return {'pred': path_y, 'pred_t': path_t, 'loss': loss,\n",
        "                'pred_var': path_var}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WF8Y9aqrK6p"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJx1TNtWrPfo"
      },
      "outputs": [],
      "source": [
        "METR_COLUMNS: List[str] = [\n",
        "    'epoch', 'train_time', 'val_time', 'train_loss', 'val_loss',\n",
        "    'optimal_val_loss', 'test_loss', 'optimal_test_loss', 'evaluation_mean_diff']\n",
        "default_nn = ((50, 'tanh'), (50, 'tanh'))\n",
        "\n",
        "def train(\n",
        "    model=None, seed=None,\n",
        "    data_train=None, data_val=None, data_test=None,\n",
        "    dataset_metadata=None, testset_metadata=None,\n",
        "    epochs=100, batch_size=100, save_every=1,\n",
        "    learning_rate=0.001,\n",
        "    hidden_size=10, bias=True, dropout_rate=0.1,\n",
        "    ode_nn=default_nn, readout_nn=default_nn,\n",
        "    enc_nn=default_nn, use_rnn=False,\n",
        "    solver=\"euler\",\n",
        "    **options\n",
        "):\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    training function for NJODE model (models.NJODE),\n",
        "    the model is automatically saved in the model-save-path with the given\n",
        "    model id, also all evaluations of the model are saved there\n",
        "\n",
        "    :param model: None or a NJODE model instance\n",
        "    :param data_train: see data_utils\n",
        "    :param data_val: see data_utils\n",
        "    :param data_test: see data_utils\n",
        "    :param dataset_metadata: see data_utils\n",
        "    :param testset_metadata: see data_utils\n",
        "    :param epochs: int, number of epochs to train, each epoch is one cycle\n",
        "            through all (random) batches of the training data\n",
        "    :param batch_size: int\n",
        "    :param save_every: int, defined number of epochs after each of which the\n",
        "            model is saved and plotted if wanted. whenever the model has a new\n",
        "            best eval-loss it is also saved, independent of this number (but not\n",
        "            plotted)\n",
        "    :param learning_rate: float\n",
        "    :param hidden_size: see models.NJODE\n",
        "    :param bias: see models.NJODE\n",
        "    :param dropout_rate: float\n",
        "    :param ode_nn: see models.NJODE\n",
        "    :param readout_nn: see models.NJODE\n",
        "    :param enc_nn: see models.NJODE\n",
        "    :param use_rnn: see models.NJODE\n",
        "    :param solver: see models.NJODE\n",
        "    :param saved_models_path: str, where to save the models\n",
        "    :param options: kwargs, used keywords:\n",
        "        'test_data_dict'    None, str or dict, if no None, this data_dict is\n",
        "                        used to define the dataset for plot_only and\n",
        "                        evaluation (if evaluate=True)\n",
        "        'func_appl_X'   list of functions (as str, see data_utils)\n",
        "                        to apply to X\n",
        "        'masked'        bool, whether the data is masked (i.e. has\n",
        "                        incomplete observations)\n",
        "        'which_loss'    default: 'standard', see models.LOSS_FUN_DICT for\n",
        "                        choices. suggested: 'easy' or 'very_easy'\n",
        "        'residual_enc_dec'  bool, whether resNNs are used for encoder and\n",
        "                        readout NN, used by models.NJODE. the provided value\n",
        "                        is overwritten by 'residual_enc' & 'residual_dec' if\n",
        "                        they are provided. default: False\n",
        "        'residual_enc'  bool, whether resNNs are used for encoder NN,\n",
        "                        used by models.NJODE.\n",
        "                        default: True if use_rnn=False, else: False (this is\n",
        "                        for backward compatibility)\n",
        "        'residual_dec'  bool, whether resNNs are used for readout NN,\n",
        "                        used by models.NJODE. default: True\n",
        "        'use_y_for_ode' bool, whether to use y (after jump) or x_impute for\n",
        "                        the ODE as input, only in masked case, default: True\n",
        "        'use_current_y_for_ode' bool, whether to use the current y as input\n",
        "                        to the ode. this should make the training more\n",
        "                        stable in the case of long windows without\n",
        "                        observations (cf. literature about stable output\n",
        "                        feedback). default: False\n",
        "        'coord_wise_tau'    bool, whether to use a coordinate wise tau\n",
        "        'input_sig'     bool, whether to use the signature as input\n",
        "        'level'         int, level of the signature that is used\n",
        "        'input_current_t'   bool, whether to additionally input current time\n",
        "                        to the ODE function f, default: False\n",
        "        'enc_input_t'   bool, whether to use the time as input for the\n",
        "                        encoder network. default: False\n",
        "        'evaluate'      bool, whether to evaluate the model in the test set\n",
        "                        (i.e. not only compute the val_loss, but also\n",
        "                        compute the mean difference between the true and the\n",
        "                        predicted paths comparing at each time point)\n",
        "        'use_observation_as_input'  bool, whether to use the observations as\n",
        "                        input to the model or whether to only use them for\n",
        "                        the loss function (this can be used to make the\n",
        "                        model learn to predict well far into the future).\n",
        "                        can be a float in (0,1) to use an observation with\n",
        "                        this probability as input. can also be a string\n",
        "                        defining a function (when evaluated) that takes the\n",
        "                        current epoch as input and returns a bool whether to\n",
        "                        use the current observation as input (this can be a\n",
        "                        random function, i.e. the output can depend on\n",
        "                        sampling a random variable). default: true\n",
        "        'val_use_observation_as_input'  bool, None, float or str, same as\n",
        "                        'use_observation_as_input', but for the validation\n",
        "                        set. default: None, i.e. same as for training set\n",
        "        'ode_input_scaling_func'    None or str in {'id', 'tanh'}, the\n",
        "                        function used to scale inputs to the neuralODE.\n",
        "                        default: tanh\n",
        "        'use_cond_exp'  bool, whether to use the conditional expectation\n",
        "                        as reference for model evaluation, default: True\n",
        "        'which_val_loss'   str, see models.LOSS_FUN_DICT for choices, which\n",
        "                        loss to use for evaluation, default: 'easy'\n",
        "        'input_coords'  list of int or None, which coordinates to use as\n",
        "                        input. overwrites the setting from dataset_metadata.\n",
        "                        if None, then all coordinates are used.\n",
        "        'output_coords' list of int or None, which coordinates to use as\n",
        "                        output. overwrites the setting from\n",
        "                        dataset_metadata. if None, then all coordinates are\n",
        "                        used.\n",
        "        'signature_coords'  list of int or None, which coordinates to use as\n",
        "                        signature coordinates. overwrites the setting from\n",
        "                        dataset_metadata. if None, then all input\n",
        "                        coordinates are used.\n",
        "        'compute_variance'   None, bool or str, if None, then no variance\n",
        "                        computation is done. if bool, then the (marginal)\n",
        "                        variance is computed. if str \"covariance\", then the\n",
        "                        covariance matrix is computed. ATTENTION: the model\n",
        "                        output corresponds to the square root of the\n",
        "                        variance (or the Cholesky decomposition of the\n",
        "                        covariance matrix, respectivel), so if W is the\n",
        "                        model's output corresponding to the variance, then\n",
        "                        the models variance estimate is V=W^T*W or W^2,\n",
        "                        depending whether the covariance or marginal\n",
        "                        variance is estimated.\n",
        "                        default: None\n",
        "        'var_weight'    float, weight of the variance loss term in the loss\n",
        "                        function, default: 1\n",
        "        'input_var_t_helper'    bool, whether to use 1/sqrt(Delta_t) as\n",
        "                        additional input to the ODE function f. this should help\n",
        "                        to better learn the variance of the process.\n",
        "                        default: False\n",
        "        'which_var_loss'   None or int, which loss to use for the variance loss\n",
        "                        term. default: None, which leads to using default choice\n",
        "                        of the main loss function (which aligns with structure\n",
        "                        of main loss function as far as reasonable). see\n",
        "                        models.LOSS_FUN_DICT for choices (currently in {1,2,3}).\n",
        "\n",
        "    :return: model, df_metric, dl, dl_val, dl_test, stockmodel, stockmodel_test\n",
        "    \"\"\"\n",
        "    use_cond_exp = True\n",
        "    masked = False\n",
        "    if 'masked' in options:\n",
        "        masked = options['masked']\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "    if seed is not None:\n",
        "        torch.manual_seed(seed)\n",
        "        np.random.seed(seed)\n",
        "\n",
        "    # get input and output coordinates of the dataset\n",
        "    input_coords = None\n",
        "    output_coords = None\n",
        "    signature_coords = None\n",
        "    if \"input_coords\" in options:\n",
        "        input_coords = options[\"input_coords\"]\n",
        "    elif \"input_coords\" in dataset_metadata:\n",
        "        input_coords = dataset_metadata[\"input_coords\"]\n",
        "    if \"output_coords\" in options:\n",
        "        output_coords = options[\"output_coords\"]\n",
        "    elif \"output_coords\" in dataset_metadata:\n",
        "        output_coords = dataset_metadata[\"output_coords\"]\n",
        "    if \"signature_coords\" in options:\n",
        "        signature_coords = options[\"signature_coords\"]\n",
        "    elif \"signature_coords\" in dataset_metadata:\n",
        "        signature_coords = dataset_metadata[\"signature_coords\"]\n",
        "    if input_coords is None:\n",
        "        input_size = dataset_metadata['dimension']\n",
        "        input_coords = np.arange(input_size)\n",
        "    else:\n",
        "        input_size = len(input_coords)\n",
        "    if output_coords is None:\n",
        "        output_size = dataset_metadata['dimension']\n",
        "        output_coords = np.arange(output_size)\n",
        "    else:\n",
        "        output_size = len(output_coords)\n",
        "    if signature_coords is None:\n",
        "        signature_coords = input_coords\n",
        "\n",
        "    initial_print = '\\ninput_coords: {}\\noutput_coords: {}'.format(\n",
        "        input_coords, output_coords)\n",
        "    initial_print += '\\ninput_size: {}\\noutput_size: {}'.format(\n",
        "        input_size, output_size)\n",
        "    initial_print += '\\nsignature_coords: {}'.format(signature_coords)\n",
        "    dimension = dataset_metadata['dimension']\n",
        "    T = dataset_metadata['maturity']\n",
        "    delta_t = dataset_metadata['dt']\n",
        "    original_output_dim = output_size\n",
        "    original_input_dim = input_size\n",
        "\n",
        "    # get functions to apply to the paths in X\n",
        "    if 'func_appl_X' in options:  # list of functions to apply to the paths in X\n",
        "        initial_print += '\\napply functions to X'\n",
        "        functions = options['func_appl_X']\n",
        "        collate_fn, mult = CustomCollateFnGen(functions)\n",
        "        input_size = input_size * mult\n",
        "        output_size = output_size * mult\n",
        "        input_coords = np.concatenate(\n",
        "            [np.array(input_coords)+dimension*i for i in range(mult)])\n",
        "        output_coords = np.concatenate(\n",
        "            [np.array(output_coords)+dimension*i for i in range(mult)])\n",
        "        initial_print += '\\nnew input_coords: {}'.format(input_coords)\n",
        "        initial_print += '\\nnew output_coords: {}'.format(output_coords)\n",
        "    else:\n",
        "        functions = None\n",
        "        collate_fn, mult = CustomCollateFnGen(None)\n",
        "        mult = 1\n",
        "\n",
        "    # get variance or covariance coordinates if wanted\n",
        "    compute_variance = None\n",
        "    var_size = 0\n",
        "    if 'compute_variance' in options:\n",
        "        if functions is not None:\n",
        "            warnings.warn(\n",
        "                \"function application to X and concurrent variance/covariance \"\n",
        "                \"computation might lead to problems! Use carefully!\",\n",
        "                UserWarning)\n",
        "        compute_variance = options['compute_variance']\n",
        "        if compute_variance == 'covariance':\n",
        "            var_size = output_size**2\n",
        "            initial_print += '\\ncompute covariance of size {}'.format(var_size)\n",
        "        elif compute_variance not in [None, False]:\n",
        "            compute_variance = 'variance'\n",
        "            var_size = output_size\n",
        "            initial_print += '\\ncompute (marginal) variance of size {}'.format(\n",
        "                var_size)\n",
        "        else:\n",
        "            compute_variance = None\n",
        "            initial_print += '\\nno variance computation'\n",
        "            var_size = 0\n",
        "        # the models variance output is the Cholesky decomposition of the\n",
        "        #   covariance matrix or the square root of the marginal variance.\n",
        "        # for Y being the entire model output, the variance output is\n",
        "        #   W=Y[:,-var_size:]\n",
        "        output_size += var_size\n",
        "\n",
        "    # get data-loader for training\n",
        "    dl = DataLoader(  # class to iterate over training data\n",
        "        dataset=data_train, collate_fn=collate_fn,\n",
        "        shuffle=True, batch_size=batch_size, num_workers=1)\n",
        "    dl_val = DataLoader(  # class to iterate over validation data\n",
        "        dataset=data_val, collate_fn=collate_fn,\n",
        "        shuffle=False, batch_size=len(data_val), num_workers=1)\n",
        "    stockmodel = DATASETS[\n",
        "        dataset_metadata['model_name']](**dataset_metadata)\n",
        "    if data_test is not None:\n",
        "        dl_test = DataLoader(  # class to iterate over test data\n",
        "            dataset=data_test, collate_fn=collate_fn,\n",
        "            shuffle=False, batch_size=len(data_test),\n",
        "            num_workers=1)\n",
        "        stockmodel_test = DATASETS[\n",
        "            testset_metadata['model_name']](**testset_metadata)\n",
        "    else:\n",
        "        dl_test = dl_val\n",
        "        stockmodel_test = stockmodel\n",
        "        testset_metadata = dataset_metadata\n",
        "\n",
        "    # validation loss function\n",
        "    which_val_loss = 'easy'\n",
        "    if 'which_loss' in options:\n",
        "        which_val_loss = options['which_loss']\n",
        "    if 'which_val_loss' in options:\n",
        "        which_val_loss = options['which_val_loss']\n",
        "    assert which_val_loss in LOSS_FUN_DICT\n",
        "\n",
        "    if compute_variance is not None:\n",
        "        warnings.warn(\n",
        "            \"optimal loss might be wrong, since the conditional \"\n",
        "            \"variance is also learned, which is not accounted for in \"\n",
        "            \"computation of the optimal loss\",\n",
        "            UserWarning)\n",
        "    store_cond_exp = True\n",
        "    if dl_val != dl_test:\n",
        "        store_cond_exp = False\n",
        "    if functions is not None and len(functions) > 0:\n",
        "        initial_print += '\\nWARNING: optimal loss computation for ' \\\n",
        "                          'power=2 not implemented for this model'\n",
        "        corrected_string = \"(corrected: only original X used) \"\n",
        "    else:\n",
        "        corrected_string = \"\"\n",
        "    opt_val_loss = compute_optimal_val_loss(\n",
        "        dl_val, stockmodel, delta_t, T, mult=mult,\n",
        "        store_cond_exp=store_cond_exp, return_var=False,\n",
        "        which_loss=which_val_loss)\n",
        "    initial_print += '\\noptimal {}val-loss (achieved by true cond exp): ' \\\n",
        "                  '{:.5f}'.format(corrected_string, opt_val_loss)\n",
        "\n",
        "    # get params_dict\n",
        "    params_dict = {  # create a dictionary of the wanted parameters\n",
        "        'input_size': input_size, 'epochs': epochs,\n",
        "        'hidden_size': hidden_size, 'output_size': output_size, 'bias': bias,\n",
        "        'ode_nn': ode_nn, 'readout_nn': readout_nn, 'enc_nn': enc_nn,\n",
        "        'use_rnn': use_rnn,\n",
        "        'dropout_rate': dropout_rate, 'batch_size': batch_size,\n",
        "        'solver': solver,\n",
        "        'learning_rate': learning_rate, 'test_size': test_size, 'seed': seed,\n",
        "        'optimal_val_loss': opt_val_loss, 'options': options}\n",
        "\n",
        "    # add additional values to params_dict (not to be shown in the description)\n",
        "    params_dict['input_coords'] = input_coords\n",
        "    params_dict['output_coords'] = output_coords\n",
        "    params_dict['signature_coords'] = signature_coords\n",
        "    params_dict['compute_variance'] = compute_variance\n",
        "    params_dict['var_size'] = var_size\n",
        "\n",
        "    # get the model & optimizer\n",
        "    if model is None:\n",
        "        model = NJODE(**params_dict)  # get NJODE model class from\n",
        "        initial_print += '\\ninitiate new model ...'\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.Adam(\n",
        "        model.parameters(), lr=learning_rate, weight_decay=0.0005)\n",
        "    best_val_loss = np.inf\n",
        "    metr_columns = METR_COLUMNS\n",
        "\n",
        "    # ---------------- TRAINING ----------------\n",
        "    initial_print += '\\n\\nmodel overview:'\n",
        "    print(initial_print)\n",
        "    print(use_cond_exp)\n",
        "    print(model, '\\n')\n",
        "\n",
        "    # compute number of parameters\n",
        "    nr_params = 0\n",
        "    for name, param in model.named_parameters():\n",
        "        nr_params += param.nelement()  # count number of parameters\n",
        "    print('# parameters={}\\n'.format(nr_params))\n",
        "\n",
        "    metric_app = []\n",
        "    while model.epoch <= epochs:\n",
        "        t = time.time()\n",
        "        model.train()  # set model in train mode (e.g. BatchNorm)\n",
        "        for i, b in tqdm.tqdm(enumerate(dl)):  # iterate over the dataloader\n",
        "            optimizer.zero_grad()  # reset the gradient\n",
        "            times = b[\"times\"]\n",
        "            time_ptr = b[\"time_ptr\"]\n",
        "            X = b[\"X\"].to(device)\n",
        "            M = b[\"M\"]\n",
        "            if M is not None:\n",
        "                M = M.to(device)\n",
        "            start_M = b[\"start_M\"]\n",
        "            if start_M is not None:\n",
        "                start_M = start_M.to(device)\n",
        "            start_X = b[\"start_X\"].to(device)\n",
        "            obs_idx = b[\"obs_idx\"]\n",
        "            n_obs_ot = b[\"n_obs_ot\"].to(device)\n",
        "\n",
        "            hT, loss = model(\n",
        "                times=times, time_ptr=time_ptr, X=X, obs_idx=obs_idx,\n",
        "                delta_t=delta_t, T=T, start_X=start_X, n_obs_ot=n_obs_ot,\n",
        "                return_path=False, get_loss=True, M=M, start_M=start_M,)\n",
        "            loss.backward()  # compute gradient of each weight regarding loss function\n",
        "            optimizer.step()  # update weights with ADAM optimizer\n",
        "        train_time = time.time() - t\n",
        "\n",
        "        # -------- evaluation --------\n",
        "        print(\"evaluating ...\")\n",
        "        t = time.time()\n",
        "        batch = None\n",
        "        with torch.no_grad():  # no gradient needed for evaluation\n",
        "            loss_val = 0\n",
        "            num_obs = 0\n",
        "            eval_msd = 0\n",
        "            model.eval()  # set model in evaluation mode\n",
        "            for i, b in enumerate(dl_val):\n",
        "                times = b[\"times\"]\n",
        "                time_ptr = b[\"time_ptr\"]\n",
        "                X = b[\"X\"].to(device)\n",
        "                M = b[\"M\"]\n",
        "                if M is not None:\n",
        "                    M = M.to(device)\n",
        "                start_M = b[\"start_M\"]\n",
        "                if start_M is not None:\n",
        "                    start_M = start_M.to(device)\n",
        "                start_X = b[\"start_X\"].to(device)\n",
        "                obs_idx = b[\"obs_idx\"]\n",
        "                n_obs_ot = b[\"n_obs_ot\"].to(device)\n",
        "                true_paths = b[\"true_paths\"]\n",
        "                true_mask = b[\"true_mask\"]\n",
        "\n",
        "                hT, c_loss = model(\n",
        "                    times, time_ptr, X, obs_idx, delta_t, T, start_X,\n",
        "                    n_obs_ot, return_path=False, get_loss=True, M=M,\n",
        "                    start_M=start_M, which_loss=which_val_loss,)\n",
        "                loss_val += c_loss.detach().numpy()\n",
        "                num_obs += 1  # count number of observations\n",
        "\n",
        "            # mean squared difference evaluation\n",
        "            if 'evaluate' in options and options['evaluate']:\n",
        "                eval_msd = evaluate_model(\n",
        "                    model=model, dl_test=dl_test, device=device,\n",
        "                    stockmodel_test=stockmodel_test,\n",
        "                    testset_metadata=testset_metadata,\n",
        "                    mult=mult, use_cond_exp=use_cond_exp,\n",
        "                    eval_use_true_paths=False)\n",
        "\n",
        "            val_time = time.time() - t\n",
        "            loss_val = loss_val / num_obs\n",
        "            eval_msd = eval_msd / num_obs\n",
        "            train_loss = loss.detach().numpy()\n",
        "            print_str = \"epoch {}, weight={:.5f}, train-loss={:.5f}, \" \\\n",
        "                        \"optimal-val-loss={:.5f}, val-loss={:.5f}, \".format(\n",
        "                model.epoch, model.weight, train_loss, opt_val_loss, loss_val)\n",
        "            print(print_str)\n",
        "\n",
        "        curr_metric = [model.epoch, train_time, val_time, train_loss,\n",
        "                               loss_val, opt_val_loss, None, None]\n",
        "        if 'evaluate' in options and options['evaluate']:\n",
        "            curr_metric.append(eval_msd)\n",
        "            print(\"evaluation mean square difference (test set): {:.5f}\".format(\n",
        "                eval_msd))\n",
        "        else:\n",
        "            curr_metric.append(None)\n",
        "        metric_app.append(curr_metric)\n",
        "\n",
        "        if loss_val < best_val_loss:\n",
        "            print('save new best model: last-best-loss: {:.5f}, '\n",
        "                  'new-best-loss: {:.5f}, epoch: {}'.format(\n",
        "                best_val_loss, loss_val, model.epoch))\n",
        "            best_val_loss = loss_val\n",
        "        print(\"-\"*100)\n",
        "\n",
        "        model.epoch += 1\n",
        "\n",
        "    df_metric = pd.DataFrame(data=metric_app, columns=metr_columns)\n",
        "\n",
        "    return model, df_metric, dl, dl_val, dl_test, stockmodel, stockmodel_test\n",
        "\n",
        "\n",
        "def compute_optimal_val_loss(\n",
        "        dl_val, stockmodel, delta_t, T, mult=None,\n",
        "        store_cond_exp=False, return_var=False, which_loss='easy'):\n",
        "    \"\"\"\n",
        "    compute optimal evaluation loss (with the true cond. exp.) on the\n",
        "    test-dataset\n",
        "    :param dl_val: torch.DataLoader, used for the validation dataset\n",
        "    :param stockmodel: stock_model.StockModel instance\n",
        "    :param delta_t: float, the time_delta\n",
        "    :param T: float, the terminal time\n",
        "    :param mult: None or int, the factor by which the dimension is multiplied\n",
        "    :param store_cond_exp: bool, whether to store the conditional expectation\n",
        "    :return: float (optimal loss)\n",
        "    \"\"\"\n",
        "    opt_loss = 0\n",
        "    num_obs = 0\n",
        "    for i, b in enumerate(dl_val):\n",
        "        times = b[\"times\"]\n",
        "        time_ptr = b[\"time_ptr\"]\n",
        "        X = b[\"X\"].detach().numpy()\n",
        "        start_X = b[\"start_X\"].detach().numpy()\n",
        "        obs_idx = b[\"obs_idx\"].detach().numpy()\n",
        "        n_obs_ot = b[\"n_obs_ot\"].detach().numpy()\n",
        "        M = b[\"M\"]\n",
        "        if M is not None:\n",
        "            M = M.detach().numpy()\n",
        "        num_obs += 1\n",
        "        opt_loss += stockmodel.get_optimal_loss(\n",
        "            times, time_ptr, X, obs_idx, delta_t, T, start_X, n_obs_ot, M=M,\n",
        "            mult=mult, store_and_use_stored=store_cond_exp,\n",
        "            return_var=return_var, which_loss=which_loss)\n",
        "    return opt_loss / num_obs\n",
        "\n",
        "\n",
        "def evaluate_model(\n",
        "        model, dl_test, device, stockmodel_test, testset_metadata,\n",
        "        mult, use_cond_exp, eval_use_true_paths):\n",
        "    \"\"\"\n",
        "    evaluate the model on the test set\n",
        "\n",
        "    Args:\n",
        "        model:\n",
        "        dl_test:\n",
        "        device:\n",
        "        stockmodel_test:\n",
        "        testset_metadata:\n",
        "        mult:\n",
        "        use_cond_exp:\n",
        "        eval_use_true_paths:\n",
        "\n",
        "    Returns: evaluation metric\n",
        "\n",
        "    \"\"\"\n",
        "    eval_msd = 0.\n",
        "    for i, b in enumerate(dl_test):\n",
        "        times = b[\"times\"]\n",
        "        time_ptr = b[\"time_ptr\"]\n",
        "        X = b[\"X\"].to(device)\n",
        "        M = b[\"M\"]\n",
        "        if M is not None:\n",
        "            M = M.to(device)\n",
        "        start_M = b[\"start_M\"]\n",
        "        if start_M is not None:\n",
        "            start_M = start_M.to(device)\n",
        "        start_X = b[\"start_X\"].to(device)\n",
        "        obs_idx = b[\"obs_idx\"]\n",
        "        n_obs_ot = b[\"n_obs_ot\"].to(device)\n",
        "        true_paths = b[\"true_paths\"]\n",
        "        true_mask = b[\"true_mask\"]\n",
        "\n",
        "        if use_cond_exp and not eval_use_true_paths:\n",
        "            true_paths = None\n",
        "            true_mask = None\n",
        "        _eval_msd = model.evaluate(\n",
        "            times=times, time_ptr=time_ptr, X=X,\n",
        "            obs_idx=obs_idx,\n",
        "            delta_t=testset_metadata[\"dt\"],\n",
        "            T=testset_metadata[\"maturity\"],\n",
        "            start_X=start_X, n_obs_ot=n_obs_ot,\n",
        "            stockmodel=stockmodel_test, return_paths=False, M=M,\n",
        "            start_M=start_M, true_paths=true_paths,\n",
        "            true_mask=true_mask, mult=mult,\n",
        "            use_stored_cond_exp=True, )\n",
        "        eval_msd += _eval_msd\n",
        "\n",
        "    return eval_msd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1_4PQqmrQoy"
      },
      "outputs": [],
      "source": [
        "METR_COLUMNS1: List[str] = [\n",
        "    'epoch', 'train_time', 'val_time', 'train_loss', 'val_loss',]\n",
        "default_nn = ((50, 'tanh'), (50, 'tanh'))\n",
        "\n",
        "def train1(\n",
        "    model=None, seed=None,\n",
        "    data_train=None, data_val=None, data_test=None,\n",
        "    dataset_metadata=None, testset_metadata=None,\n",
        "    epochs=100, batch_size=100, save_every=1,\n",
        "    learning_rate=0.001,\n",
        "    hidden_size=10, bias=True, dropout_rate=0.1,\n",
        "    ode_nn=default_nn, readout_nn=default_nn,\n",
        "    enc_nn=default_nn, use_rnn=False,\n",
        "    solver=\"euler\",\n",
        "    **options\n",
        "):\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    training function for NJODE model (models.NJODE),\n",
        "    the model is automatically saved in the model-save-path with the given\n",
        "    model id, also all evaluations of the model are saved there\n",
        "\n",
        "    :param model: None or a NJODE model instance\n",
        "    :param data_train: see data_utils\n",
        "    :param data_val: see data_utils\n",
        "    :param data_test: see data_utils\n",
        "    :param dataset_metadata: see data_utils\n",
        "    :param testset_metadata: see data_utils\n",
        "    :param epochs: int, number of epochs to train, each epoch is one cycle\n",
        "            through all (random) batches of the training data\n",
        "    :param batch_size: int\n",
        "    :param save_every: int, defined number of epochs after each of which the\n",
        "            model is saved and plotted if wanted. whenever the model has a new\n",
        "            best eval-loss it is also saved, independent of this number (but not\n",
        "            plotted)\n",
        "    :param learning_rate: float\n",
        "    :param hidden_size: see models.NJODE\n",
        "    :param bias: see models.NJODE\n",
        "    :param dropout_rate: float\n",
        "    :param ode_nn: see models.NJODE\n",
        "    :param readout_nn: see models.NJODE\n",
        "    :param enc_nn: see models.NJODE\n",
        "    :param use_rnn: see models.NJODE\n",
        "    :param solver: see models.NJODE\n",
        "    :param saved_models_path: str, where to save the models\n",
        "    :param options: kwargs, used keywords:\n",
        "        'test_data_dict'    None, str or dict, if no None, this data_dict is\n",
        "                        used to define the dataset for plot_only and\n",
        "                        evaluation (if evaluate=True)\n",
        "        'func_appl_X'   list of functions (as str, see data_utils)\n",
        "                        to apply to X\n",
        "        'masked'        bool, whether the data is masked (i.e. has\n",
        "                        incomplete observations)\n",
        "        'which_loss'    default: 'standard', see models.LOSS_FUN_DICT for\n",
        "                        choices. suggested: 'easy' or 'very_easy'\n",
        "        'residual_enc_dec'  bool, whether resNNs are used for encoder and\n",
        "                        readout NN, used by models.NJODE. the provided value\n",
        "                        is overwritten by 'residual_enc' & 'residual_dec' if\n",
        "                        they are provided. default: False\n",
        "        'residual_enc'  bool, whether resNNs are used for encoder NN,\n",
        "                        used by models.NJODE.\n",
        "                        default: True if use_rnn=False, else: False (this is\n",
        "                        for backward compatibility)\n",
        "        'residual_dec'  bool, whether resNNs are used for readout NN,\n",
        "                        used by models.NJODE. default: True\n",
        "        'use_y_for_ode' bool, whether to use y (after jump) or x_impute for\n",
        "                        the ODE as input, only in masked case, default: True\n",
        "        'use_current_y_for_ode' bool, whether to use the current y as input\n",
        "                        to the ode. this should make the training more\n",
        "                        stable in the case of long windows without\n",
        "                        observations (cf. literature about stable output\n",
        "                        feedback). default: False\n",
        "        'coord_wise_tau'    bool, whether to use a coordinate wise tau\n",
        "        'input_sig'     bool, whether to use the signature as input\n",
        "        'level'         int, level of the signature that is used\n",
        "        'input_current_t'   bool, whether to additionally input current time\n",
        "                        to the ODE function f, default: False\n",
        "        'enc_input_t'   bool, whether to use the time as input for the\n",
        "                        encoder network. default: False\n",
        "        'evaluate'      bool, whether to evaluate the model in the test set\n",
        "                        (i.e. not only compute the val_loss, but also\n",
        "                        compute the mean difference between the true and the\n",
        "                        predicted paths comparing at each time point)\n",
        "        'use_observation_as_input'  bool, whether to use the observations as\n",
        "                        input to the model or whether to only use them for\n",
        "                        the loss function (this can be used to make the\n",
        "                        model learn to predict well far into the future).\n",
        "                        can be a float in (0,1) to use an observation with\n",
        "                        this probability as input. can also be a string\n",
        "                        defining a function (when evaluated) that takes the\n",
        "                        current epoch as input and returns a bool whether to\n",
        "                        use the current observation as input (this can be a\n",
        "                        random function, i.e. the output can depend on\n",
        "                        sampling a random variable). default: true\n",
        "        'val_use_observation_as_input'  bool, None, float or str, same as\n",
        "                        'use_observation_as_input', but for the validation\n",
        "                        set. default: None, i.e. same as for training set\n",
        "        'ode_input_scaling_func'    None or str in {'id', 'tanh'}, the\n",
        "                        function used to scale inputs to the neuralODE.\n",
        "                        default: tanh\n",
        "        'use_cond_exp'  bool, whether to use the conditional expectation\n",
        "                        as reference for model evaluation, default: True\n",
        "        'which_val_loss'   str, see models.LOSS_FUN_DICT for choices, which\n",
        "                        loss to use for evaluation, default: 'easy'\n",
        "        'input_coords'  list of int or None, which coordinates to use as\n",
        "                        input. overwrites the setting from dataset_metadata.\n",
        "                        if None, then all coordinates are used.\n",
        "        'output_coords' list of int or None, which coordinates to use as\n",
        "                        output. overwrites the setting from\n",
        "                        dataset_metadata. if None, then all coordinates are\n",
        "                        used.\n",
        "        'signature_coords'  list of int or None, which coordinates to use as\n",
        "                        signature coordinates. overwrites the setting from\n",
        "                        dataset_metadata. if None, then all input\n",
        "                        coordinates are used.\n",
        "        'compute_variance'   None, bool or str, if None, then no variance\n",
        "                        computation is done. if bool, then the (marginal)\n",
        "                        variance is computed. if str \"covariance\", then the\n",
        "                        covariance matrix is computed. ATTENTION: the model\n",
        "                        output corresponds to the square root of the\n",
        "                        variance (or the Cholesky decomposition of the\n",
        "                        covariance matrix, respectivel), so if W is the\n",
        "                        model's output corresponding to the variance, then\n",
        "                        the models variance estimate is V=W^T*W or W^2,\n",
        "                        depending whether the covariance or marginal\n",
        "                        variance is estimated.\n",
        "                        default: None\n",
        "        'var_weight'    float, weight of the variance loss term in the loss\n",
        "                        function, default: 1\n",
        "        'input_var_t_helper'    bool, whether to use 1/sqrt(Delta_t) as\n",
        "                        additional input to the ODE function f. this should help\n",
        "                        to better learn the variance of the process.\n",
        "                        default: False\n",
        "        'which_var_loss'   None or int, which loss to use for the variance loss\n",
        "                        term. default: None, which leads to using default choice\n",
        "                        of the main loss function (which aligns with structure\n",
        "                        of main loss function as far as reasonable). see\n",
        "                        models.LOSS_FUN_DICT for choices (currently in {1,2,3}).\n",
        "\n",
        "    :return: model, df_metric, dl, dl_val, dl_test, stockmodel, stockmodel_test\n",
        "    \"\"\"\n",
        "    use_cond_exp = False\n",
        "    masked = False\n",
        "    if 'masked' in options:\n",
        "        masked = options['masked']\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "    if seed is not None:\n",
        "        torch.manual_seed(seed)\n",
        "        np.random.seed(seed)\n",
        "\n",
        "    # get input and output coordinates of the dataset\n",
        "    input_coords = None\n",
        "    output_coords = None\n",
        "    signature_coords = None\n",
        "    if \"input_coords\" in options:\n",
        "        input_coords = options[\"input_coords\"]\n",
        "    elif \"input_coords\" in dataset_metadata:\n",
        "        input_coords = dataset_metadata[\"input_coords\"]\n",
        "    if \"output_coords\" in options:\n",
        "        output_coords = options[\"output_coords\"]\n",
        "    elif \"output_coords\" in dataset_metadata:\n",
        "        output_coords = dataset_metadata[\"output_coords\"]\n",
        "    if \"signature_coords\" in options:\n",
        "        signature_coords = options[\"signature_coords\"]\n",
        "    elif \"signature_coords\" in dataset_metadata:\n",
        "        signature_coords = dataset_metadata[\"signature_coords\"]\n",
        "    if input_coords is None:\n",
        "        input_size = dataset_metadata['dimension']\n",
        "        input_coords = np.arange(input_size)\n",
        "    else:\n",
        "        input_size = len(input_coords)\n",
        "    if output_coords is None:\n",
        "        output_size = dataset_metadata['dimension']\n",
        "        output_coords = np.arange(output_size)\n",
        "    else:\n",
        "        output_size = len(output_coords)\n",
        "    if signature_coords is None:\n",
        "        signature_coords = input_coords\n",
        "\n",
        "    initial_print = '\\ninput_coords: {}\\noutput_coords: {}'.format(\n",
        "        input_coords, output_coords)\n",
        "    initial_print += '\\ninput_size: {}\\noutput_size: {}'.format(\n",
        "        input_size, output_size)\n",
        "    initial_print += '\\nsignature_coords: {}'.format(signature_coords)\n",
        "    dimension = dataset_metadata['dimension']\n",
        "    T = dataset_metadata['maturity']\n",
        "    delta_t = dataset_metadata['dt']\n",
        "    original_output_dim = output_size\n",
        "    original_input_dim = input_size\n",
        "\n",
        "\n",
        "    collate_fn, mult = CustomCollateFnGen(None)\n",
        "\n",
        "    # get data-loader for training\n",
        "    dl = DataLoader(  # class to iterate over training data\n",
        "        dataset=data_train, collate_fn=collate_fn,\n",
        "        shuffle=True, batch_size=batch_size, num_workers=1)\n",
        "    dl_val = DataLoader(  # class to iterate over validation data\n",
        "        dataset=data_val, collate_fn=collate_fn,\n",
        "        shuffle=False, batch_size=len(data_val), num_workers=1)\n",
        "\n",
        "    if data_test is not None:\n",
        "        dl_test = DataLoader(  # class to iterate over test data\n",
        "            dataset=data_test, collate_fn=collate_fn,\n",
        "            shuffle=False, batch_size=len(data_test),\n",
        "            num_workers=1)\n",
        "\n",
        "    else:\n",
        "        dl_test = dl_val\n",
        "        testset_metadata = dataset_metadata\n",
        "\n",
        "    # validation loss function\n",
        "    which_val_loss = 'easy'\n",
        "    if 'which_loss' in options:\n",
        "        which_val_loss = options['which_loss']\n",
        "    if 'which_val_loss' in options:\n",
        "        which_val_loss = options['which_val_loss']\n",
        "    assert which_val_loss in LOSS_FUN_DICT\n",
        "\n",
        "    # get params_dict\n",
        "    params_dict = {  # create a dictionary of the wanted parameters\n",
        "        'input_size': input_size, 'epochs': epochs,\n",
        "        'hidden_size': hidden_size, 'output_size': output_size, 'bias': bias,\n",
        "        'ode_nn': ode_nn, 'readout_nn': readout_nn, 'enc_nn': enc_nn,\n",
        "        'use_rnn': use_rnn,\n",
        "        'dropout_rate': dropout_rate, 'batch_size': batch_size,\n",
        "        'solver': solver,\n",
        "        'learning_rate': learning_rate, 'seed': seed,\n",
        "        'options': options}\n",
        "\n",
        "    # add additional values to params_dict (not to be shown in the description)\n",
        "    params_dict['input_coords'] = input_coords\n",
        "    params_dict['output_coords'] = output_coords\n",
        "    params_dict['signature_coords'] = signature_coords\n",
        "\n",
        "    # get the model & optimizer\n",
        "    if model is None:\n",
        "        model = NJODE(**params_dict)  # get NJODE model class from\n",
        "        initial_print += '\\ninitiate new model ...'\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.Adam(\n",
        "        model.parameters(), lr=learning_rate, weight_decay=0.0005)\n",
        "    best_val_loss = np.inf\n",
        "    metr_columns = METR_COLUMNS1\n",
        "\n",
        "    # ---------------- TRAINING ----------------\n",
        "    initial_print += '\\n\\nmodel overview:'\n",
        "    print(initial_print)\n",
        "    print(use_cond_exp)\n",
        "    print(model, '\\n')\n",
        "\n",
        "    # compute number of parameters\n",
        "    nr_params = 0\n",
        "    for name, param in model.named_parameters():\n",
        "        nr_params += param.nelement()  # count number of parameters\n",
        "    print('# parameters={}\\n'.format(nr_params))\n",
        "\n",
        "    metric_app = []\n",
        "    while model.epoch <= epochs:\n",
        "        t = time.time()\n",
        "        model.train()  # set model in train mode (e.g. BatchNorm)\n",
        "        for i, b in tqdm.tqdm(enumerate(dl)):  # iterate over the dataloader\n",
        "            optimizer.zero_grad()  # reset the gradient\n",
        "            times = b[\"times\"]\n",
        "            time_ptr = b[\"time_ptr\"]\n",
        "            X = b[\"X\"].to(device)\n",
        "            M = b[\"M\"]\n",
        "            if M is not None:\n",
        "                M = M.to(device)\n",
        "            start_M = b[\"start_M\"]\n",
        "            if start_M is not None:\n",
        "                start_M = start_M.to(device)\n",
        "            start_X = b[\"start_X\"].to(device)\n",
        "            obs_idx = b[\"obs_idx\"]\n",
        "            n_obs_ot = b[\"n_obs_ot\"].to(device)\n",
        "\n",
        "            hT, loss = model(\n",
        "                times=times, time_ptr=time_ptr, X=X, obs_idx=obs_idx,\n",
        "                delta_t=delta_t, T=T, start_X=start_X, n_obs_ot=n_obs_ot,\n",
        "                return_path=False, get_loss=True, M=M, start_M=start_M,)\n",
        "            loss.backward()  # compute gradient of each weight regarding loss function\n",
        "            optimizer.step()  # update weights with ADAM optimizer\n",
        "        train_time = time.time() - t\n",
        "\n",
        "        # -------- evaluation --------\n",
        "        print(\"evaluating ...\")\n",
        "        t = time.time()\n",
        "        batch = None\n",
        "        with torch.no_grad():  # no gradient needed for evaluation\n",
        "            loss_val = 0\n",
        "            num_obs = 0\n",
        "            eval_msd = 0\n",
        "            model.eval()  # set model in evaluation mode\n",
        "            for i, b in enumerate(dl_val):\n",
        "                times = b[\"times\"]\n",
        "                time_ptr = b[\"time_ptr\"]\n",
        "                X = b[\"X\"].to(device)\n",
        "                M = b[\"M\"]\n",
        "                if M is not None:\n",
        "                    M = M.to(device)\n",
        "                start_M = b[\"start_M\"]\n",
        "                if start_M is not None:\n",
        "                    start_M = start_M.to(device)\n",
        "                start_X = b[\"start_X\"].to(device)\n",
        "                obs_idx = b[\"obs_idx\"]\n",
        "                n_obs_ot = b[\"n_obs_ot\"].to(device)\n",
        "                true_paths = b[\"true_paths\"]\n",
        "                true_mask = b[\"true_mask\"]\n",
        "\n",
        "                hT, c_loss = model(\n",
        "                    times, time_ptr, X, obs_idx, delta_t, T, start_X,\n",
        "                    n_obs_ot, return_path=False, get_loss=True, M=M,\n",
        "                    start_M=start_M, which_loss=which_val_loss,)\n",
        "                loss_val += c_loss.detach().numpy()\n",
        "                num_obs += 1  # count number of observations\n",
        "\n",
        "            val_time = time.time() - t\n",
        "            loss_val = loss_val / num_obs\n",
        "            eval_msd = eval_msd / num_obs\n",
        "            train_loss = loss.detach().numpy()\n",
        "            print_str = \"epoch {}, weight={:.5f}, train-loss={:.5f}, \" \\\n",
        "                        \" val-loss={:.5f}, \".format(\n",
        "                model.epoch, model.weight, train_loss, loss_val)\n",
        "            print(print_str)\n",
        "\n",
        "        curr_metric = [model.epoch, train_time, val_time, train_loss,\n",
        "                               loss_val ]\n",
        "\n",
        "        metric_app.append(curr_metric)\n",
        "\n",
        "        if loss_val < best_val_loss:\n",
        "            print('save new best model: last-best-loss: {:.5f}, '\n",
        "                  'new-best-loss: {:.5f}, epoch: {}'.format(\n",
        "                best_val_loss, loss_val, model.epoch))\n",
        "            best_val_loss = loss_val\n",
        "        print(\"-\"*100)\n",
        "\n",
        "        model.epoch += 1\n",
        "\n",
        "    df_metric = pd.DataFrame(data=metric_app, columns=metr_columns)\n",
        "\n",
        "    return model, df_metric, dl, dl_val, dl_test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaLuOT91tm3J"
      },
      "source": [
        "# plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yhl-9mA7ug0O"
      },
      "outputs": [],
      "source": [
        "def plot_one_path_with_pred(\n",
        "        device, model, batch, stockmodel, delta_t, T,\n",
        "        path_to_plot=(0,),\n",
        "        plot_variance=False, plot_true_var=True,\n",
        "        functions=None, std_factor=1,\n",
        "        model_name=\"NJODE\", ylabels=None,\n",
        "        legendlabels=None,\n",
        "        use_cond_exp=True, same_yaxis=False,\n",
        "        plot_obs_prob=False,\n",
        "        reuse_cond_exp=True, output_coords=None,\n",
        "        loss_quantiles=None, input_coords=None,\n",
        "        which_loss='easy',\n",
        "):\n",
        "    \"\"\"\n",
        "    plot one path of the stockmodel together with optimal cond. exp. and its\n",
        "    prediction by the model\n",
        "    :param device: torch.device, to use for computations\n",
        "    :param model: models.NJODE instance\n",
        "    :param batch: the batch from where to take the paths\n",
        "    :param stockmodel: stock_model.StockModel instance, used to compute true\n",
        "            cond. exp.\n",
        "    :param delta_t: float\n",
        "    :param T: float\n",
        "    :param path_to_plot: list of ints, which paths to plot (i.e. which elements\n",
        "            oof the batch)\n",
        "    :param plot_variance: bool, whether to plot the variance, if supported by\n",
        "            functions (i.e. square has to be applied)\n",
        "    :param functions: list of functions (as str), the functions applied to X\n",
        "    :param std_factor: float, the factor by which std is multiplied\n",
        "    :param model_name: str or None, name used for model in plots\n",
        "    :param ylabels: None or list of str of same length as dimension of X\n",
        "    :param legendlabels: None or list of str of length 4 or 5 (labels of\n",
        "        i) true path, ii) our model, iii) true cond. exp., iv) observed values,\n",
        "        v) true values at observation times (only if noisy observations are\n",
        "        used))\n",
        "    :param use_cond_exp: bool, whether to plot the conditional expectation\n",
        "    :param same_yaxis: bool, whether to plot all coordinates with same range on\n",
        "        y-axis\n",
        "    :param plot_obs_prob: bool, whether to plot the probability of an\n",
        "        observation for all times\n",
        "    :param reuse_cond_exp: bool, whether to reuse the conditional expectation\n",
        "        from the last computation\n",
        "    :param output_coords: None or list of ints, the coordinates corresponding to\n",
        "        the model output\n",
        "    :param loss_quantiles: None or list of floats, the quantiles to plot for the\n",
        "        loss\n",
        "    :param input_coords: None or list of ints, the coordinates corresponding to\n",
        "        the model input\n",
        "    :param which_loss: str, the loss function to use for the computation\n",
        "\n",
        "    :return: optimal loss\n",
        "    \"\"\"\n",
        "    if model_name is None or model_name == \"NJODE\":\n",
        "        model_name = 'our model'\n",
        "    if device is None:\n",
        "        device = model.device\n",
        "\n",
        "    prop_cycle = plt.rcParams['axes.prop_cycle']  # change style of plot?\n",
        "    colors = prop_cycle.by_key()['color']\n",
        "    std_color = list(matplotlib.colors.to_rgb(colors[1])) + [0.5]\n",
        "    std_color2 = list(matplotlib.colors.to_rgb(colors[2])) + [0.5]\n",
        "\n",
        "    times = batch[\"times\"]\n",
        "    time_ptr = batch[\"time_ptr\"]\n",
        "    X = batch[\"X\"].to(device)\n",
        "    M = batch[\"M\"]\n",
        "    if M is not None:\n",
        "        M = M.to(device)\n",
        "    start_X = batch[\"start_X\"].to(device)\n",
        "    start_M = batch[\"start_M\"]\n",
        "    if start_M is not None:\n",
        "        start_M = start_M.to(device)\n",
        "    obs_idx = batch[\"obs_idx\"]\n",
        "    n_obs_ot = batch[\"n_obs_ot\"].to(device)\n",
        "    true_X = batch[\"true_paths\"]\n",
        "    # dim does not take the function applications into account\n",
        "    bs, dim, time_steps = true_X.shape\n",
        "    if output_coords is None:\n",
        "        output_coords = list(range(dim))\n",
        "        out_dim = dim\n",
        "    else:\n",
        "        # if output_coords is given, then they also include the function\n",
        "        #   applications\n",
        "        mult = len(functions)+1 if functions is not None else 1\n",
        "        out_dim = int(len(output_coords)/mult)\n",
        "    true_M = batch[\"true_mask\"]\n",
        "    observed_dates = batch['observed_dates']\n",
        "    if \"obs_noise\" in batch:\n",
        "        obs_noise = batch[\"obs_noise\"]\n",
        "    else:\n",
        "        obs_noise = None\n",
        "    path_t_true_X = np.linspace(0., T, int(np.round(T / delta_t)) + 1)\n",
        "\n",
        "    model.eval()  # put model in evaluation mode\n",
        "    res = model.get_pred(\n",
        "        times=times, time_ptr=time_ptr, X=X, obs_idx=obs_idx, delta_t=delta_t,\n",
        "        T=T, start_X=start_X, M=M, start_M=start_M, n_obs_ot=n_obs_ot,\n",
        "        which_loss=which_loss)\n",
        "    path_y_pred = res['pred'].detach().numpy()\n",
        "    path_t_pred = res['pred_t']\n",
        "    current_model_loss = res['loss'].detach().numpy()\n",
        "\n",
        "    # get variance path\n",
        "    if plot_variance and (functions is not None) and ('power-2' in functions):\n",
        "        which = np.argmax(np.array(functions) == 'power-2')+1\n",
        "        y2 = path_y_pred[:, :, (out_dim * which):(out_dim * (which + 1))]\n",
        "        path_var_pred = y2 - np.power(path_y_pred[:, :, 0:out_dim], 2)\n",
        "        if np.any(path_var_pred < 0):\n",
        "            print('WARNING: some predicted cond. variances below 0 -> clip')\n",
        "            path_var_pred = np.maximum(0, path_var_pred)\n",
        "        path_std_pred = np.sqrt(path_var_pred)\n",
        "    elif plot_variance and (model.compute_variance is not None):\n",
        "        path_var_pred = res[\"pred_var\"].detach().numpy()\n",
        "        if model.compute_variance == \"variance\":\n",
        "            path_var_pred = path_var_pred[:, :, 0:out_dim]**2\n",
        "        elif model.compute_variance == \"covariance\":\n",
        "            d = int(np.sqrt(path_var_pred.shape[2]))\n",
        "            path_var_pred = path_var_pred.reshape(\n",
        "                path_y_pred.shape[0], path_y_pred.shape[1], d, d)\n",
        "            path_var_pred = np.matmul(\n",
        "                path_var_pred.transpose(0,1,3,2), path_var_pred)\n",
        "            path_var_pred = np.diagonal(path_var_pred, axis1=2, axis2=3)\n",
        "            path_var_pred = path_var_pred[:, :, 0:out_dim]\n",
        "        else:\n",
        "            raise ValueError(\"compute_variance {} not implemented\".format(\n",
        "                model.compute_variance))\n",
        "        path_std_pred = np.sqrt(path_var_pred)\n",
        "    else:\n",
        "        plot_variance = False\n",
        "    path_var_true = None\n",
        "    if use_cond_exp:\n",
        "        if M is not None:\n",
        "            M = M.detach().numpy()\n",
        "        if (functions is not None and functions == [\"power-2\"] and\n",
        "                stockmodel.loss_comp_for_pow2_implemented):\n",
        "            X_ = X.detach().numpy()\n",
        "            start_X_ = start_X.detach().numpy()\n",
        "        else:\n",
        "            X_ = X.detach().numpy()[:, :dim]\n",
        "            start_X_ = start_X.detach().numpy()[:, :dim]\n",
        "            if M is not None:\n",
        "                M = M[:, :dim]\n",
        "        res_sm = stockmodel.compute_cond_exp(\n",
        "            times, time_ptr, X_, obs_idx.detach().numpy(),\n",
        "            delta_t, T, start_X_, n_obs_ot.detach().numpy(),\n",
        "            return_path=True, get_loss=True, weight=model.weight,\n",
        "            M=M, store_and_use_stored=reuse_cond_exp,\n",
        "            return_var=(plot_variance and plot_true_var),\n",
        "            which_loss=which_loss, ref_model=None)\n",
        "        opt_loss, path_t_true, path_y_true = res_sm[:3]\n",
        "        if plot_variance and len(res_sm) > 3:\n",
        "            path_var_true = res_sm[3]\n",
        "    else:\n",
        "        opt_loss = 0\n",
        "\n",
        "    for i in path_to_plot:\n",
        "        fig, axs = plt.subplots(dim, sharex=True)\n",
        "        if dim == 1:\n",
        "            axs = [axs]\n",
        "        outcoord_ind = -1\n",
        "        unobserved_coord = False\n",
        "        for j in range(dim):\n",
        "            if j in output_coords:\n",
        "                outcoord_ind += 1\n",
        "            # get the true_X at observed dates\n",
        "            path_t_obs = []\n",
        "            path_X_obs = []\n",
        "            if obs_noise is not None:\n",
        "                path_O_obs = []\n",
        "            for k, od in enumerate(observed_dates[i]):\n",
        "                if od == 1:\n",
        "                    if true_M is None or (true_M is not None and\n",
        "                                          true_M[i, j, k]==1):\n",
        "                        path_t_obs.append(path_t_true_X[k])\n",
        "                        path_X_obs.append(true_X[i, j, k])\n",
        "                        if obs_noise is not None:\n",
        "                            path_O_obs.append(\n",
        "                                true_X[i, j, k]+obs_noise[i, j, k])\n",
        "            path_t_obs = np.array(path_t_obs)\n",
        "            path_X_obs = np.array(path_X_obs)\n",
        "            if obs_noise is not None:\n",
        "                path_O_obs = np.array(path_O_obs)\n",
        "\n",
        "            # get the legend labels\n",
        "            lab0 = legendlabels[0] if legendlabels is not None else 'true path'\n",
        "            lab1 = legendlabels[1] if legendlabels is not None else model_name\n",
        "            lab2 = legendlabels[2] if legendlabels is not None \\\n",
        "                else 'true conditional expectation'\n",
        "            lab3 = legendlabels[3] if legendlabels is not None else 'observed'\n",
        "\n",
        "            axs[j].plot(path_t_true_X, true_X[i, j, :], label=lab0,\n",
        "                        color=colors[0])\n",
        "            if obs_noise is not None:\n",
        "                axs[j].scatter(path_t_obs, path_O_obs, label=lab3,\n",
        "                               color=colors[0])\n",
        "                # axs[j].scatter(recr_t, recr_X[i, :, j],label='observed recr.',\n",
        "                #                color=\"black\", marker=\"x\")\n",
        "                lab4 = legendlabels[4] if legendlabels is not None \\\n",
        "                    else 'true value at obs time'\n",
        "                axs[j].scatter(path_t_obs, path_X_obs,\n",
        "                               label=lab4,\n",
        "                               color=colors[2], marker='*')\n",
        "            else:\n",
        "                facecolors = colors[0]\n",
        "                if input_coords is not None and j not in input_coords:\n",
        "                    facecolors = 'none'\n",
        "                    lab3 = '(un)observed'\n",
        "                    unobserved_coord = True\n",
        "                axs[j].scatter(path_t_obs, path_X_obs, label=lab3,\n",
        "                               color=colors[0], facecolors=facecolors)\n",
        "            if j in output_coords:\n",
        "                if loss_quantiles is not None:\n",
        "                    for iq, q in enumerate(loss_quantiles):\n",
        "                        axs[j].plot(\n",
        "                            path_t_pred, path_y_pred[:, i, outcoord_ind, iq],\n",
        "                            label=\"q{} - {}\".format(q, lab1),\n",
        "                            color=list(matplotlib.colors.to_rgb(colors[1]))+\n",
        "                                  [2*min(q, 1-q)])\n",
        "                else:\n",
        "                    axs[j].plot(path_t_pred, path_y_pred[:, i, outcoord_ind],\n",
        "                                label=lab1, color=colors[1])\n",
        "                if plot_variance:\n",
        "                    axs[j].fill_between(\n",
        "                        path_t_pred,\n",
        "                        path_y_pred[:, i, outcoord_ind] - std_factor *\n",
        "                        path_std_pred[:, i, outcoord_ind],\n",
        "                        path_y_pred[:, i, outcoord_ind] + std_factor *\n",
        "                        path_std_pred[:, i, outcoord_ind],\n",
        "                        color=std_color)\n",
        "                if use_cond_exp:\n",
        "                    if loss_quantiles is not None:\n",
        "                        for iq, q in enumerate(loss_quantiles):\n",
        "                            axs[j].plot(\n",
        "                                path_t_true, path_y_true[:, i, outcoord_ind,iq],\n",
        "                                label=\"q{} - {}\".format(q, lab2),\n",
        "                                linestyle=':',\n",
        "                                color=list(matplotlib.colors.to_rgb(colors[2]))+\n",
        "                                      [2*min(q, 1-q)])\n",
        "                    else:\n",
        "                        axs[j].plot(path_t_true, path_y_true[:,i,outcoord_ind],\n",
        "                                    label=lab2, linestyle=':', color=colors[2])\n",
        "                    if plot_variance and path_var_true is not None:\n",
        "                        axs[j].fill_between(\n",
        "                            path_t_true,\n",
        "                            path_y_true[:, i, outcoord_ind] - std_factor *\n",
        "                            np.sqrt(path_var_true[:, i, outcoord_ind]),\n",
        "                            path_y_true[:, i, outcoord_ind] + std_factor *\n",
        "                            np.sqrt(path_var_true[:, i, outcoord_ind]),\n",
        "                            color=std_color2)\n",
        "            if ylabels:\n",
        "                axs[j].set_ylabel(ylabels[j])\n",
        "            if same_yaxis:\n",
        "                low = np.min(true_X[i, :, :])\n",
        "                high = np.max(true_X[i, :, :])\n",
        "                if obs_noise is not None:\n",
        "                    low = min(low, np.min(true_X[i]+obs_noise[i]))\n",
        "                    high = max(high, np.max(true_X[i]+obs_noise[i]))\n",
        "                eps = (high - low)*0.05\n",
        "                axs[j].set_ylim([low-eps, high+eps])\n",
        "\n",
        "        if unobserved_coord:\n",
        "            handles, labels = axs[-1].get_legend_handles_labels()\n",
        "            l, = axs[-1].plot(\n",
        "                [], [], color=colors[0], label='(un)observed',\n",
        "                linestyle='none', marker=\"o\", fillstyle=\"right\")\n",
        "\n",
        "            handles[-1] = l\n",
        "            labels[-1] = 'unobserved/observed'\n",
        "            axs[-1].legend(handles, labels)\n",
        "        else:\n",
        "            axs[-1].legend()\n",
        "        plt.xlabel('$t$')\n",
        "        plt.show()\n",
        "\n",
        "    return opt_loss, current_model_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTk7CMpEuiDO"
      },
      "outputs": [],
      "source": [
        "def plot_one_path_with_pred1(\n",
        "        device, model, batch, delta_t, T,\n",
        "        path_to_plot=(0,),\n",
        "        plot_variance=False, plot_true_var=True,\n",
        "        functions=None, std_factor=1,\n",
        "        model_name=\"NJODE\", ylabels=None,\n",
        "        legendlabels=None,\n",
        "        use_cond_exp=True, same_yaxis=False,\n",
        "        plot_obs_prob=False,\n",
        "        reuse_cond_exp=True, output_coords=None,\n",
        "        loss_quantiles=None, input_coords=None,\n",
        "        which_loss='easy_vol',\n",
        "):\n",
        "    \"\"\"\n",
        "    plot one path of the stockmodel together with optimal cond. exp. and its\n",
        "    prediction by the model\n",
        "    :param device: torch.device, to use for computations\n",
        "    :param model: models.NJODE instance\n",
        "    :param batch: the batch from where to take the paths\n",
        "    :param stockmodel: stock_model.StockModel instance, used to compute true\n",
        "            cond. exp.\n",
        "    :param delta_t: float\n",
        "    :param T: float\n",
        "    :param path_to_plot: list of ints, which paths to plot (i.e. which elements\n",
        "            oof the batch)\n",
        "    :param plot_variance: bool, whether to plot the variance, if supported by\n",
        "            functions (i.e. square has to be applied)\n",
        "    :param functions: list of functions (as str), the functions applied to X\n",
        "    :param std_factor: float, the factor by which std is multiplied\n",
        "    :param model_name: str or None, name used for model in plots\n",
        "    :param ylabels: None or list of str of same length as dimension of X\n",
        "    :param legendlabels: None or list of str of length 4 or 5 (labels of\n",
        "        i) true path, ii) our model, iii) true cond. exp., iv) observed values,\n",
        "        v) true values at observation times (only if noisy observations are\n",
        "        used))\n",
        "    :param use_cond_exp: bool, whether to plot the conditional expectation\n",
        "    :param same_yaxis: bool, whether to plot all coordinates with same range on\n",
        "        y-axis\n",
        "    :param plot_obs_prob: bool, whether to plot the probability of an\n",
        "        observation for all times\n",
        "    :param reuse_cond_exp: bool, whether to reuse the conditional expectation\n",
        "        from the last computation\n",
        "    :param output_coords: None or list of ints, the coordinates corresponding to\n",
        "        the model output\n",
        "    :param loss_quantiles: None or list of floats, the quantiles to plot for the\n",
        "        loss\n",
        "    :param input_coords: None or list of ints, the coordinates corresponding to\n",
        "        the model input\n",
        "    :param which_loss: str, the loss function to use for the computation\n",
        "\n",
        "    :return: optimal loss\n",
        "    \"\"\"\n",
        "    if model_name is None or model_name == \"NJODE\":\n",
        "        model_name = 'our model'\n",
        "    if device is None:\n",
        "        device = model.device\n",
        "\n",
        "    prop_cycle = plt.rcParams['axes.prop_cycle']  # change style of plot?\n",
        "    colors = prop_cycle.by_key()['color']\n",
        "    std_color = list(matplotlib.colors.to_rgb(colors[1])) + [0.5]\n",
        "    std_color2 = list(matplotlib.colors.to_rgb(colors[2])) + [0.5]\n",
        "\n",
        "    times = batch[\"times\"]\n",
        "    time_ptr = batch[\"time_ptr\"]\n",
        "    X = batch[\"X\"].to(device)\n",
        "    M = batch[\"M\"]\n",
        "    if M is not None:\n",
        "        M = M.to(device)\n",
        "    start_X = batch[\"start_X\"].to(device)\n",
        "    start_M = batch[\"start_M\"]\n",
        "    if start_M is not None:\n",
        "        start_M = start_M.to(device)\n",
        "    obs_idx = batch[\"obs_idx\"]\n",
        "    n_obs_ot = batch[\"n_obs_ot\"].to(device)\n",
        "    true_X = batch[\"true_paths\"]\n",
        "    # dim does not take the function applications into account\n",
        "    bs, dim, time_steps = true_X.shape\n",
        "    if output_coords is None:\n",
        "        output_coords = list(range(dim))\n",
        "        out_dim = dim\n",
        "    else:\n",
        "        # if output_coords is given, then they also include the function\n",
        "        #   applications\n",
        "        mult = len(functions)+1 if functions is not None else 1\n",
        "        out_dim = int(len(output_coords)/mult)\n",
        "    true_M = batch[\"true_mask\"]\n",
        "    observed_dates = batch['observed_dates']\n",
        "    if \"obs_noise\" in batch:\n",
        "        obs_noise = batch[\"obs_noise\"]\n",
        "    else:\n",
        "        obs_noise = None\n",
        "    path_t_true_X = np.linspace(0., T, int(np.round(T / delta_t)) + 1)\n",
        "\n",
        "    model.eval()  # put model in evaluation mode\n",
        "    res = model.get_pred(\n",
        "        times=times, time_ptr=time_ptr, X=X, obs_idx=obs_idx, delta_t=delta_t,\n",
        "        T=T, start_X=start_X, M=M, start_M=start_M, n_obs_ot=n_obs_ot,\n",
        "        which_loss=which_loss)\n",
        "    path_y_pred = res['pred'].detach().numpy()\n",
        "    path_t_pred = res['pred_t']\n",
        "    current_model_loss = res['loss'].detach().numpy()\n",
        "\n",
        "    # get variance path\n",
        "    if plot_variance and (functions is not None) and ('power-2' in functions):\n",
        "        which = np.argmax(np.array(functions) == 'power-2')+1\n",
        "        y2 = path_y_pred[:, :, (out_dim * which):(out_dim * (which + 1))]\n",
        "        path_var_pred = y2 - np.power(path_y_pred[:, :, 0:out_dim], 2)\n",
        "        if np.any(path_var_pred < 0):\n",
        "            print('WARNING: some predicted cond. variances below 0 -> clip')\n",
        "            path_var_pred = np.maximum(0, path_var_pred)\n",
        "        path_std_pred = np.sqrt(path_var_pred)\n",
        "    elif plot_variance and (model.compute_variance is not None):\n",
        "        path_var_pred = res[\"pred_var\"].detach().numpy()\n",
        "        if model.compute_variance == \"variance\":\n",
        "            path_var_pred = path_var_pred[:, :, 0:out_dim]**2\n",
        "        elif model.compute_variance == \"covariance\":\n",
        "            d = int(np.sqrt(path_var_pred.shape[2]))\n",
        "            path_var_pred = path_var_pred.reshape(\n",
        "                path_y_pred.shape[0], path_y_pred.shape[1], d, d)\n",
        "            path_var_pred = np.matmul(\n",
        "                path_var_pred.transpose(0,1,3,2), path_var_pred)\n",
        "            path_var_pred = np.diagonal(path_var_pred, axis1=2, axis2=3)\n",
        "            path_var_pred = path_var_pred[:, :, 0:out_dim]\n",
        "        else:\n",
        "            raise ValueError(\"compute_variance {} not implemented\".format(\n",
        "                model.compute_variance))\n",
        "        path_std_pred = np.sqrt(path_var_pred)\n",
        "    else:\n",
        "        plot_variance = False\n",
        "    path_var_true = None\n",
        "\n",
        "\n",
        "    for i in path_to_plot:\n",
        "        fig, axs = plt.subplots(dim, sharex=True)\n",
        "        if dim == 1:\n",
        "            axs = [axs]\n",
        "        outcoord_ind = -1\n",
        "        unobserved_coord = False\n",
        "        for j in range(dim):\n",
        "            if j in output_coords:\n",
        "                outcoord_ind += 1\n",
        "            # get the true_X at observed dates\n",
        "            path_t_obs = []\n",
        "            path_X_obs = []\n",
        "            if obs_noise is not None:\n",
        "                path_O_obs = []\n",
        "            for k, od in enumerate(observed_dates[i]):\n",
        "                if od == 1:\n",
        "                    if true_M is None or (true_M is not None and\n",
        "                                          true_M[i, j, k]==1):\n",
        "                        path_t_obs.append(path_t_true_X[k])\n",
        "                        path_X_obs.append(true_X[i, j, k])\n",
        "                        if obs_noise is not None:\n",
        "                            path_O_obs.append(\n",
        "                                true_X[i, j, k]+obs_noise[i, j, k])\n",
        "            path_t_obs = np.array(path_t_obs)\n",
        "            path_X_obs = np.array(path_X_obs)\n",
        "            if obs_noise is not None:\n",
        "                path_O_obs = np.array(path_O_obs)\n",
        "\n",
        "            # get the legend labels\n",
        "            lab0 = legendlabels[0] if legendlabels is not None else 'true path'\n",
        "            lab1 = legendlabels[1] if legendlabels is not None else model_name\n",
        "            lab2 = legendlabels[2] if legendlabels is not None \\\n",
        "                else 'true conditional expectation'\n",
        "            lab3 = legendlabels[3] if legendlabels is not None else 'observed'\n",
        "\n",
        "            axs[j].plot(path_t_true_X, true_X[i, j, :], label=lab0,\n",
        "                        color=colors[0])\n",
        "            if obs_noise is not None:\n",
        "                axs[j].scatter(path_t_obs, path_O_obs, label=lab3,\n",
        "                               color=colors[0])\n",
        "                # axs[j].scatter(recr_t, recr_X[i, :, j],label='observed recr.',\n",
        "                #                color=\"black\", marker=\"x\")\n",
        "                lab4 = legendlabels[4] if legendlabels is not None \\\n",
        "                    else 'true value at obs time'\n",
        "                axs[j].scatter(path_t_obs, path_X_obs,\n",
        "                               label=lab4,\n",
        "                               color=colors[2], marker='*')\n",
        "            else:\n",
        "                facecolors = colors[0]\n",
        "                if input_coords is not None and j not in input_coords:\n",
        "                    facecolors = 'none'\n",
        "                    lab3 = '(un)observed'\n",
        "                    unobserved_coord = True\n",
        "                axs[j].scatter(path_t_obs, path_X_obs, label=lab3,\n",
        "                               color=colors[0], facecolors=facecolors)\n",
        "            if j in output_coords:\n",
        "                if loss_quantiles is not None:\n",
        "                    for iq, q in enumerate(loss_quantiles):\n",
        "                        axs[j].plot(\n",
        "                            path_t_pred, path_y_pred[:, i, outcoord_ind, iq],\n",
        "                            label=\"q{} - {}\".format(q, lab1),\n",
        "                            color=list(matplotlib.colors.to_rgb(colors[1]))+\n",
        "                                  [2*min(q, 1-q)])\n",
        "                else:\n",
        "                    axs[j].plot(path_t_pred, path_y_pred[:, i, outcoord_ind],\n",
        "                                label=lab1, color=colors[1])\n",
        "            if ylabels:\n",
        "                axs[j].set_ylabel(ylabels[j])\n",
        "            if same_yaxis:\n",
        "                low = np.min(true_X[i, :, :])\n",
        "                high = np.max(true_X[i, :, :])\n",
        "                if obs_noise is not None:\n",
        "                    low = min(low, np.min(true_X[i]+obs_noise[i]))\n",
        "                    high = max(high, np.max(true_X[i]+obs_noise[i]))\n",
        "                eps = (high - low)*0.05\n",
        "                axs[j].set_ylim([low-eps, high+eps])\n",
        "\n",
        "        if unobserved_coord:\n",
        "            handles, labels = axs[-1].get_legend_handles_labels()\n",
        "            l, = axs[-1].plot(\n",
        "                [], [], color=colors[0], label='(un)observed',\n",
        "                linestyle='none', marker=\"o\", fillstyle=\"right\")\n",
        "\n",
        "            handles[-1] = l\n",
        "            labels[-1] = 'unobserved/observed'\n",
        "            axs[-1].legend(handles, labels)\n",
        "        else:\n",
        "            axs[-1].legend()\n",
        "        plt.xlabel('$t$')\n",
        "        plt.show()\n",
        "\n",
        "    return current_model_loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GNZQPC1wsen"
      },
      "source": [
        "# Example 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpfytpLwwsI2"
      },
      "outputs": [],
      "source": [
        "BS_dict_mu = {\n",
        "    'model_name': \"BlackScholes\",\n",
        "    'drift': 2., 'volatility': 0.3,\n",
        "    'nb_paths': 10000, 'nb_steps': 100,\n",
        "    'S0': 1, 'maturity': 1., 'dimension': 1,\n",
        "    'obs_perc': 1.0,\n",
        "}\n",
        "dataset_mu = create_dataset(BS_dict_mu[\"model_name\"], BS_dict_mu, seed=0)\n",
        "dataset_mu_metadata = dataset_mu[-2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "kHumF-vixERX",
        "outputId": "afb92cb1-01d8-4789-b6ba-5467b31d4fdd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "paths = dataset_mu[0]\n",
        "plt.plot(np.linspace(0,1,101), paths[0,0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJIYl7VZxLsX"
      },
      "outputs": [],
      "source": [
        "seed = 1\n",
        "test_size = 0.2\n",
        "train_mu_idx, val_mu_idx = train_test_split(\n",
        "        np.arange(dataset_mu_metadata[\"nb_paths\"]), test_size=test_size,\n",
        "        random_state=seed)\n",
        "\n",
        "data_mu_train = IrregularDataset(dataset_mu, idx=train_mu_idx)\n",
        "data_mu_val = IrregularDataset(dataset_mu, idx=val_mu_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6R8VRM4pxbXQ"
      },
      "outputs": [],
      "source": [
        "_nn = ((50, 'tanh'),)\n",
        "\n",
        "param_dict_BM = {\n",
        "    'seed': 2,\n",
        "    'data_train': data_mu_train,\n",
        "    'data_val': data_mu_val,\n",
        "    'dataset_metadata': dataset_mu_metadata,\n",
        "    'epochs': 100,\n",
        "    'batch_size': 200,\n",
        "    'learning_rate': 0.001,\n",
        "    'hidden_size': 10,\n",
        "    'bias': True,\n",
        "    'dropout_rate': 0.1,\n",
        "    'ode_nn': _nn,\n",
        "    'readout_nn': None,\n",
        "    'enc_nn': _nn,\n",
        "    'dataset_id': None,\n",
        "    'which_loss': 'easy',\n",
        "    'use_y_for_ode': True,\n",
        "    'use_rnn': False,\n",
        "    'input_sig': False,\n",
        "    'level': 2,\n",
        "    'masked': False,\n",
        "    'evaluate': True,\n",
        "    'compute_variance': False,\n",
        "    'func_appl_X': [\"power-2\"],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVaU2etOxcvP",
        "outputId": "8572b95a-08b5-481e-ecb4-9c29ced1507c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-10-3732291492.py:217: UserWarning: function application to X and concurrent variance/covariance computation might lead to problems! Use carefully!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using loss: easy\n",
            "neuralODE use input scaling with tanh\n",
            "use residual network: input_size=2, output_size=50\n",
            "use residual network: input_size=50, output_size=2\n",
            "\n",
            "input_coords: [0]\n",
            "output_coords: [0]\n",
            "input_size: 1\n",
            "output_size: 1\n",
            "signature_coords: [0]\n",
            "apply functions to X\n",
            "new input_coords: [0 1]\n",
            "new output_coords: [0 1]\n",
            "no variance computation\n",
            "WARNING: optimal loss computation for power=2 not implemented for this model\n",
            "optimal (corrected: only original X used) val-loss (achieved by true cond exp): 0.01223\n",
            "initiate new model ...\n",
            "\n",
            "model overview:\n",
            "True\n",
            "NJODE(\n",
            "  (ode_f): ODEFunc(\n",
            "    (f): Sequential(\n",
            "      (0): Linear(in_features=54, out_features=50, bias=True)\n",
            "      (1): Tanh()\n",
            "      (2): Dropout(p=0.1, inplace=False)\n",
            "      (3): Linear(in_features=50, out_features=50, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (encoder_map): FFNN(\n",
            "    (ffnn): Sequential(\n",
            "      (0): Linear(in_features=2, out_features=50, bias=True)\n",
            "      (1): Tanh()\n",
            "      (2): Dropout(p=0.1, inplace=False)\n",
            "      (3): Linear(in_features=50, out_features=50, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (readout_map): FFNN(\n",
            "    (ffnn): Sequential(\n",
            "      (0): Linear(in_features=50, out_features=2, bias=True)\n",
            "    )\n",
            "  )\n",
            ") \n",
            "\n",
            "# parameters=8102\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:17,  2.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1, weight=0.50000, train-loss=3.18766, optimal-val-loss=0.01223, val-loss=2.81449, \n",
            "evaluation mean square difference (test set): 0.00140\n",
            "save new best model: last-best-loss: inf, new-best-loss: 2.81449, epoch: 1\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:17,  2.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2, weight=0.50000, train-loss=3.01291, optimal-val-loss=0.01223, val-loss=2.62166, \n",
            "evaluation mean square difference (test set): 0.00087\n",
            "save new best model: last-best-loss: 2.81449, new-best-loss: 2.62166, epoch: 2\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:17,  2.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3, weight=0.50000, train-loss=2.96462, optimal-val-loss=0.01223, val-loss=2.54116, \n",
            "evaluation mean square difference (test set): 0.00076\n",
            "save new best model: last-best-loss: 2.62166, new-best-loss: 2.54116, epoch: 3\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:18,  2.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4, weight=0.50000, train-loss=2.18612, optimal-val-loss=0.01223, val-loss=2.51652, \n",
            "evaluation mean square difference (test set): 0.00059\n",
            "save new best model: last-best-loss: 2.54116, new-best-loss: 2.51652, epoch: 4\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:17,  2.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5, weight=0.50000, train-loss=2.61597, optimal-val-loss=0.01223, val-loss=2.50367, \n",
            "evaluation mean square difference (test set): 0.00059\n",
            "save new best model: last-best-loss: 2.51652, new-best-loss: 2.50367, epoch: 5\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:17,  2.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 6, weight=0.50000, train-loss=2.99671, optimal-val-loss=0.01223, val-loss=2.49243, \n",
            "evaluation mean square difference (test set): 0.00056\n",
            "save new best model: last-best-loss: 2.50367, new-best-loss: 2.49243, epoch: 6\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:17,  2.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 7, weight=0.50000, train-loss=2.20296, optimal-val-loss=0.01223, val-loss=2.48370, \n",
            "evaluation mean square difference (test set): 0.00055\n",
            "save new best model: last-best-loss: 2.49243, new-best-loss: 2.48370, epoch: 7\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:17,  2.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 8, weight=0.50000, train-loss=2.65141, optimal-val-loss=0.01223, val-loss=2.45375, \n",
            "evaluation mean square difference (test set): 0.00044\n",
            "save new best model: last-best-loss: 2.48370, new-best-loss: 2.45375, epoch: 8\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:17,  2.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 9, weight=0.50000, train-loss=2.54881, optimal-val-loss=0.01223, val-loss=2.43422, \n",
            "evaluation mean square difference (test set): 0.00040\n",
            "save new best model: last-best-loss: 2.45375, new-best-loss: 2.43422, epoch: 9\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:17,  2.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10, weight=0.50000, train-loss=2.04832, optimal-val-loss=0.01223, val-loss=2.41280, \n",
            "evaluation mean square difference (test set): 0.00031\n",
            "save new best model: last-best-loss: 2.43422, new-best-loss: 2.41280, epoch: 10\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:17,  2.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 11, weight=0.50000, train-loss=2.56059, optimal-val-loss=0.01223, val-loss=2.37876, \n",
            "evaluation mean square difference (test set): 0.00026\n",
            "save new best model: last-best-loss: 2.41280, new-best-loss: 2.37876, epoch: 11\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:17,  2.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 12, weight=0.50000, train-loss=1.81399, optimal-val-loss=0.01223, val-loss=2.34923, \n",
            "evaluation mean square difference (test set): 0.00025\n",
            "save new best model: last-best-loss: 2.37876, new-best-loss: 2.34923, epoch: 12\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:17,  2.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 13, weight=0.50000, train-loss=2.26777, optimal-val-loss=0.01223, val-loss=2.33212, \n",
            "evaluation mean square difference (test set): 0.00037\n",
            "save new best model: last-best-loss: 2.34923, new-best-loss: 2.33212, epoch: 13\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:16,  2.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 14, weight=0.50000, train-loss=2.08967, optimal-val-loss=0.01223, val-loss=2.30849, \n",
            "evaluation mean square difference (test set): 0.00031\n",
            "save new best model: last-best-loss: 2.33212, new-best-loss: 2.30849, epoch: 14\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:16,  2.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 15, weight=0.50000, train-loss=2.19994, optimal-val-loss=0.01223, val-loss=2.30304, \n",
            "evaluation mean square difference (test set): 0.00038\n",
            "save new best model: last-best-loss: 2.30849, new-best-loss: 2.30304, epoch: 15\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:17,  2.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 16, weight=0.50000, train-loss=2.33860, optimal-val-loss=0.01223, val-loss=2.29270, \n",
            "evaluation mean square difference (test set): 0.00033\n",
            "save new best model: last-best-loss: 2.30304, new-best-loss: 2.29270, epoch: 16\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:17,  2.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 17, weight=0.50000, train-loss=2.38308, optimal-val-loss=0.01223, val-loss=2.28642, \n",
            "evaluation mean square difference (test set): 0.00038\n",
            "save new best model: last-best-loss: 2.29270, new-best-loss: 2.28642, epoch: 17\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:17,  2.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 18, weight=0.50000, train-loss=2.52294, optimal-val-loss=0.01223, val-loss=2.27430, \n",
            "evaluation mean square difference (test set): 0.00035\n",
            "save new best model: last-best-loss: 2.28642, new-best-loss: 2.27430, epoch: 18\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:16,  2.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 19, weight=0.50000, train-loss=2.69572, optimal-val-loss=0.01223, val-loss=2.28785, \n",
            "evaluation mean square difference (test set): 0.00029\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:16,  2.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 20, weight=0.50000, train-loss=2.63108, optimal-val-loss=0.01223, val-loss=2.27228, \n",
            "evaluation mean square difference (test set): 0.00029\n",
            "save new best model: last-best-loss: 2.27430, new-best-loss: 2.27228, epoch: 20\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:17,  2.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 21, weight=0.50000, train-loss=2.05793, optimal-val-loss=0.01223, val-loss=2.26868, \n",
            "evaluation mean square difference (test set): 0.00028\n",
            "save new best model: last-best-loss: 2.27228, new-best-loss: 2.26868, epoch: 21\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:17,  2.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 22, weight=0.50000, train-loss=1.92312, optimal-val-loss=0.01223, val-loss=2.26079, \n",
            "evaluation mean square difference (test set): 0.00026\n",
            "save new best model: last-best-loss: 2.26868, new-best-loss: 2.26079, epoch: 22\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:17,  2.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 23, weight=0.50000, train-loss=2.17575, optimal-val-loss=0.01223, val-loss=2.27296, \n",
            "evaluation mean square difference (test set): 0.00026\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:17,  2.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 24, weight=0.50000, train-loss=1.99165, optimal-val-loss=0.01223, val-loss=2.25949, \n",
            "evaluation mean square difference (test set): 0.00024\n",
            "save new best model: last-best-loss: 2.26079, new-best-loss: 2.25949, epoch: 24\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:16,  2.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 25, weight=0.50000, train-loss=2.38715, optimal-val-loss=0.01223, val-loss=2.26167, \n",
            "evaluation mean square difference (test set): 0.00026\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:17,  2.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 26, weight=0.50000, train-loss=2.26884, optimal-val-loss=0.01223, val-loss=2.26245, \n",
            "evaluation mean square difference (test set): 0.00024\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:16,  2.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 27, weight=0.50000, train-loss=2.39259, optimal-val-loss=0.01223, val-loss=2.26810, \n",
            "evaluation mean square difference (test set): 0.00024\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:17,  2.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 28, weight=0.50000, train-loss=2.64250, optimal-val-loss=0.01223, val-loss=2.25865, \n",
            "evaluation mean square difference (test set): 0.00025\n",
            "save new best model: last-best-loss: 2.25949, new-best-loss: 2.25865, epoch: 28\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:17,  2.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 29, weight=0.50000, train-loss=1.96697, optimal-val-loss=0.01223, val-loss=2.25601, \n",
            "evaluation mean square difference (test set): 0.00023\n",
            "save new best model: last-best-loss: 2.25865, new-best-loss: 2.25601, epoch: 29\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:16,  2.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 30, weight=0.50000, train-loss=2.04053, optimal-val-loss=0.01223, val-loss=2.25406, \n",
            "evaluation mean square difference (test set): 0.00023\n",
            "save new best model: last-best-loss: 2.25601, new-best-loss: 2.25406, epoch: 30\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:16,  2.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 31, weight=0.50000, train-loss=2.85043, optimal-val-loss=0.01223, val-loss=2.25113, \n",
            "evaluation mean square difference (test set): 0.00022\n",
            "save new best model: last-best-loss: 2.25406, new-best-loss: 2.25113, epoch: 31\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:16,  2.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 32, weight=0.50000, train-loss=2.31057, optimal-val-loss=0.01223, val-loss=2.25998, \n",
            "evaluation mean square difference (test set): 0.00022\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:17,  2.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 33, weight=0.50000, train-loss=1.99532, optimal-val-loss=0.01223, val-loss=2.25235, \n",
            "evaluation mean square difference (test set): 0.00022\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:17,  2.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 34, weight=0.50000, train-loss=1.85746, optimal-val-loss=0.01223, val-loss=2.24754, \n",
            "evaluation mean square difference (test set): 0.00022\n",
            "save new best model: last-best-loss: 2.25113, new-best-loss: 2.24754, epoch: 34\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:17,  2.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 35, weight=0.50000, train-loss=2.39993, optimal-val-loss=0.01223, val-loss=2.25188, \n",
            "evaluation mean square difference (test set): 0.00022\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:16,  2.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 36, weight=0.50000, train-loss=1.74577, optimal-val-loss=0.01223, val-loss=2.24930, \n",
            "evaluation mean square difference (test set): 0.00022\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:16,  2.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 37, weight=0.50000, train-loss=2.50132, optimal-val-loss=0.01223, val-loss=2.24685, \n",
            "evaluation mean square difference (test set): 0.00023\n",
            "save new best model: last-best-loss: 2.24754, new-best-loss: 2.24685, epoch: 37\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:16,  2.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 38, weight=0.50000, train-loss=2.11457, optimal-val-loss=0.01223, val-loss=2.24691, \n",
            "evaluation mean square difference (test set): 0.00022\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:17,  2.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 39, weight=0.50000, train-loss=2.23664, optimal-val-loss=0.01223, val-loss=2.24394, \n",
            "evaluation mean square difference (test set): 0.00021\n",
            "save new best model: last-best-loss: 2.24685, new-best-loss: 2.24394, epoch: 39\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:17,  2.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 40, weight=0.50000, train-loss=2.18994, optimal-val-loss=0.01223, val-loss=2.24576, \n",
            "evaluation mean square difference (test set): 0.00021\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:17,  2.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 41, weight=0.50000, train-loss=2.52591, optimal-val-loss=0.01223, val-loss=2.25019, \n",
            "evaluation mean square difference (test set): 0.00023\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:17,  2.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 42, weight=0.50000, train-loss=2.44059, optimal-val-loss=0.01223, val-loss=2.25037, \n",
            "evaluation mean square difference (test set): 0.00021\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:17,  2.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 43, weight=0.50000, train-loss=1.94281, optimal-val-loss=0.01223, val-loss=2.24508, \n",
            "evaluation mean square difference (test set): 0.00021\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:17,  2.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 44, weight=0.50000, train-loss=2.32146, optimal-val-loss=0.01223, val-loss=2.24431, \n",
            "evaluation mean square difference (test set): 0.00021\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:17,  2.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 45, weight=0.50000, train-loss=2.13828, optimal-val-loss=0.01223, val-loss=2.24218, \n",
            "evaluation mean square difference (test set): 0.00021\n",
            "save new best model: last-best-loss: 2.24394, new-best-loss: 2.24218, epoch: 45\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:18,  2.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 46, weight=0.50000, train-loss=2.49823, optimal-val-loss=0.01223, val-loss=2.25131, \n",
            "evaluation mean square difference (test set): 0.00021\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:18,  2.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 47, weight=0.50000, train-loss=2.52825, optimal-val-loss=0.01223, val-loss=2.23771, \n",
            "evaluation mean square difference (test set): 0.00021\n",
            "save new best model: last-best-loss: 2.24218, new-best-loss: 2.23771, epoch: 47\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 48, weight=0.50000, train-loss=2.33232, optimal-val-loss=0.01223, val-loss=2.24159, \n",
            "evaluation mean square difference (test set): 0.00021\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:18,  2.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 49, weight=0.50000, train-loss=1.99500, optimal-val-loss=0.01223, val-loss=2.24289, \n",
            "evaluation mean square difference (test set): 0.00023\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:18,  2.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 50, weight=0.50000, train-loss=2.10965, optimal-val-loss=0.01223, val-loss=2.23979, \n",
            "evaluation mean square difference (test set): 0.00021\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:18,  2.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 51, weight=0.50000, train-loss=2.69988, optimal-val-loss=0.01223, val-loss=2.23933, \n",
            "evaluation mean square difference (test set): 0.00023\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:17,  2.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 52, weight=0.50000, train-loss=2.57952, optimal-val-loss=0.01223, val-loss=2.24138, \n",
            "evaluation mean square difference (test set): 0.00022\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:17,  2.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 53, weight=0.50000, train-loss=2.24984, optimal-val-loss=0.01223, val-loss=2.23622, \n",
            "evaluation mean square difference (test set): 0.00021\n",
            "save new best model: last-best-loss: 2.23771, new-best-loss: 2.23622, epoch: 53\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:17,  2.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 54, weight=0.50000, train-loss=2.40507, optimal-val-loss=0.01223, val-loss=2.23460, \n",
            "evaluation mean square difference (test set): 0.00021\n",
            "save new best model: last-best-loss: 2.23622, new-best-loss: 2.23460, epoch: 54\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:18,  2.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 55, weight=0.50000, train-loss=2.41469, optimal-val-loss=0.01223, val-loss=2.23395, \n",
            "evaluation mean square difference (test set): 0.00020\n",
            "save new best model: last-best-loss: 2.23460, new-best-loss: 2.23395, epoch: 55\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:18,  2.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 56, weight=0.50000, train-loss=2.24593, optimal-val-loss=0.01223, val-loss=2.23782, \n",
            "evaluation mean square difference (test set): 0.00024\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:18,  2.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 57, weight=0.50000, train-loss=2.57427, optimal-val-loss=0.01223, val-loss=2.23871, \n",
            "evaluation mean square difference (test set): 0.00020\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:18,  2.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 58, weight=0.50000, train-loss=2.27959, optimal-val-loss=0.01223, val-loss=2.23484, \n",
            "evaluation mean square difference (test set): 0.00020\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 59, weight=0.50000, train-loss=1.78413, optimal-val-loss=0.01223, val-loss=2.23246, \n",
            "evaluation mean square difference (test set): 0.00021\n",
            "save new best model: last-best-loss: 2.23395, new-best-loss: 2.23246, epoch: 59\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 60, weight=0.50000, train-loss=2.16422, optimal-val-loss=0.01223, val-loss=2.23451, \n",
            "evaluation mean square difference (test set): 0.00020\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 61, weight=0.50000, train-loss=1.99048, optimal-val-loss=0.01223, val-loss=2.23424, \n",
            "evaluation mean square difference (test set): 0.00021\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 62, weight=0.50000, train-loss=2.48398, optimal-val-loss=0.01223, val-loss=2.23152, \n",
            "evaluation mean square difference (test set): 0.00022\n",
            "save new best model: last-best-loss: 2.23246, new-best-loss: 2.23152, epoch: 62\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 63, weight=0.50000, train-loss=2.54677, optimal-val-loss=0.01223, val-loss=2.23129, \n",
            "evaluation mean square difference (test set): 0.00020\n",
            "save new best model: last-best-loss: 2.23152, new-best-loss: 2.23129, epoch: 63\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 64, weight=0.50000, train-loss=2.17273, optimal-val-loss=0.01223, val-loss=2.23193, \n",
            "evaluation mean square difference (test set): 0.00020\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:20,  1.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 65, weight=0.50000, train-loss=2.24015, optimal-val-loss=0.01223, val-loss=2.23049, \n",
            "evaluation mean square difference (test set): 0.00020\n",
            "save new best model: last-best-loss: 2.23129, new-best-loss: 2.23049, epoch: 65\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 66, weight=0.50000, train-loss=3.07821, optimal-val-loss=0.01223, val-loss=2.23314, \n",
            "evaluation mean square difference (test set): 0.00021\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 67, weight=0.50000, train-loss=2.23748, optimal-val-loss=0.01223, val-loss=2.22997, \n",
            "evaluation mean square difference (test set): 0.00020\n",
            "save new best model: last-best-loss: 2.23049, new-best-loss: 2.22997, epoch: 67\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 68, weight=0.50000, train-loss=2.52299, optimal-val-loss=0.01223, val-loss=2.22861, \n",
            "evaluation mean square difference (test set): 0.00021\n",
            "save new best model: last-best-loss: 2.22997, new-best-loss: 2.22861, epoch: 68\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 69, weight=0.50000, train-loss=2.30366, optimal-val-loss=0.01223, val-loss=2.22764, \n",
            "evaluation mean square difference (test set): 0.00021\n",
            "save new best model: last-best-loss: 2.22861, new-best-loss: 2.22764, epoch: 69\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 70, weight=0.50000, train-loss=2.17790, optimal-val-loss=0.01223, val-loss=2.22968, \n",
            "evaluation mean square difference (test set): 0.00020\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 71, weight=0.50000, train-loss=2.10431, optimal-val-loss=0.01223, val-loss=2.22885, \n",
            "evaluation mean square difference (test set): 0.00020\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 72, weight=0.50000, train-loss=2.30540, optimal-val-loss=0.01223, val-loss=2.22957, \n",
            "evaluation mean square difference (test set): 0.00020\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 73, weight=0.50000, train-loss=2.44204, optimal-val-loss=0.01223, val-loss=2.23154, \n",
            "evaluation mean square difference (test set): 0.00021\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 74, weight=0.50000, train-loss=2.77790, optimal-val-loss=0.01223, val-loss=2.22626, \n",
            "evaluation mean square difference (test set): 0.00020\n",
            "save new best model: last-best-loss: 2.22764, new-best-loss: 2.22626, epoch: 74\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 75, weight=0.50000, train-loss=2.25604, optimal-val-loss=0.01223, val-loss=2.23191, \n",
            "evaluation mean square difference (test set): 0.00020\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 76, weight=0.50000, train-loss=2.47441, optimal-val-loss=0.01223, val-loss=2.23001, \n",
            "evaluation mean square difference (test set): 0.00020\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 77, weight=0.50000, train-loss=2.20458, optimal-val-loss=0.01223, val-loss=2.22600, \n",
            "evaluation mean square difference (test set): 0.00020\n",
            "save new best model: last-best-loss: 2.22626, new-best-loss: 2.22600, epoch: 77\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 78, weight=0.50000, train-loss=2.27266, optimal-val-loss=0.01223, val-loss=2.22531, \n",
            "evaluation mean square difference (test set): 0.00020\n",
            "save new best model: last-best-loss: 2.22600, new-best-loss: 2.22531, epoch: 78\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 79, weight=0.50000, train-loss=2.09481, optimal-val-loss=0.01223, val-loss=2.22554, \n",
            "evaluation mean square difference (test set): 0.00020\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 80, weight=0.50000, train-loss=2.25246, optimal-val-loss=0.01223, val-loss=2.22458, \n",
            "evaluation mean square difference (test set): 0.00020\n",
            "save new best model: last-best-loss: 2.22531, new-best-loss: 2.22458, epoch: 80\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 81, weight=0.50000, train-loss=2.03171, optimal-val-loss=0.01223, val-loss=2.22408, \n",
            "evaluation mean square difference (test set): 0.00021\n",
            "save new best model: last-best-loss: 2.22458, new-best-loss: 2.22408, epoch: 81\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 82, weight=0.50000, train-loss=2.49895, optimal-val-loss=0.01223, val-loss=2.22449, \n",
            "evaluation mean square difference (test set): 0.00020\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 83, weight=0.50000, train-loss=2.32647, optimal-val-loss=0.01223, val-loss=2.22369, \n",
            "evaluation mean square difference (test set): 0.00021\n",
            "save new best model: last-best-loss: 2.22408, new-best-loss: 2.22369, epoch: 83\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 84, weight=0.50000, train-loss=2.42837, optimal-val-loss=0.01223, val-loss=2.22232, \n",
            "evaluation mean square difference (test set): 0.00020\n",
            "save new best model: last-best-loss: 2.22369, new-best-loss: 2.22232, epoch: 84\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 85, weight=0.50000, train-loss=2.21410, optimal-val-loss=0.01223, val-loss=2.22480, \n",
            "evaluation mean square difference (test set): 0.00020\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 86, weight=0.50000, train-loss=2.04375, optimal-val-loss=0.01223, val-loss=2.22382, \n",
            "evaluation mean square difference (test set): 0.00020\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 87, weight=0.50000, train-loss=2.08787, optimal-val-loss=0.01223, val-loss=2.22225, \n",
            "evaluation mean square difference (test set): 0.00020\n",
            "save new best model: last-best-loss: 2.22232, new-best-loss: 2.22225, epoch: 87\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:23,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 88, weight=0.50000, train-loss=2.65039, optimal-val-loss=0.01223, val-loss=2.22351, \n",
            "evaluation mean square difference (test set): 0.00020\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 89, weight=0.50000, train-loss=2.09760, optimal-val-loss=0.01223, val-loss=2.22280, \n",
            "evaluation mean square difference (test set): 0.00021\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 90, weight=0.50000, train-loss=2.04636, optimal-val-loss=0.01223, val-loss=2.22467, \n",
            "evaluation mean square difference (test set): 0.00020\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 91, weight=0.50000, train-loss=1.96399, optimal-val-loss=0.01223, val-loss=2.22330, \n",
            "evaluation mean square difference (test set): 0.00020\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 92, weight=0.50000, train-loss=2.35488, optimal-val-loss=0.01223, val-loss=2.22071, \n",
            "evaluation mean square difference (test set): 0.00020\n",
            "save new best model: last-best-loss: 2.22225, new-best-loss: 2.22071, epoch: 92\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 93, weight=0.50000, train-loss=2.31324, optimal-val-loss=0.01223, val-loss=2.22091, \n",
            "evaluation mean square difference (test set): 0.00021\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 94, weight=0.50000, train-loss=2.28054, optimal-val-loss=0.01223, val-loss=2.22063, \n",
            "evaluation mean square difference (test set): 0.00020\n",
            "save new best model: last-best-loss: 2.22071, new-best-loss: 2.22063, epoch: 94\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 95, weight=0.50000, train-loss=2.08165, optimal-val-loss=0.01223, val-loss=2.21970, \n",
            "evaluation mean square difference (test set): 0.00020\n",
            "save new best model: last-best-loss: 2.22063, new-best-loss: 2.21970, epoch: 95\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 96, weight=0.50000, train-loss=2.40488, optimal-val-loss=0.01223, val-loss=2.21864, \n",
            "evaluation mean square difference (test set): 0.00020\n",
            "save new best model: last-best-loss: 2.21970, new-best-loss: 2.21864, epoch: 96\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 97, weight=0.50000, train-loss=2.36030, optimal-val-loss=0.01223, val-loss=2.22016, \n",
            "evaluation mean square difference (test set): 0.00020\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 98, weight=0.50000, train-loss=2.32637, optimal-val-loss=0.01223, val-loss=2.21900, \n",
            "evaluation mean square difference (test set): 0.00020\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 99, weight=0.50000, train-loss=2.28965, optimal-val-loss=0.01223, val-loss=2.21791, \n",
            "evaluation mean square difference (test set): 0.00020\n",
            "save new best model: last-best-loss: 2.21864, new-best-loss: 2.21791, epoch: 99\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:19,  2.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 100, weight=0.50000, train-loss=1.96164, optimal-val-loss=0.01223, val-loss=2.21879, \n",
            "evaluation mean square difference (test set): 0.00020\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model, df_metric, dl, dl_val, dl_test, stockmodel, stockmodel_test = train(**param_dict_BM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        },
        "id": "xef3GwObxfa3",
        "outputId": "0e98ff1a-9026-4497-804f-8a8354ee1d61"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "optimal loss (test): 0.012233841426095819\n",
            "model loss   (test): 2.412797451019287\n"
          ]
        }
      ],
      "source": [
        "batch = next(iter(dl_test))\n",
        "\n",
        "opt_loss, current_model_loss = plot_one_path_with_pred(\n",
        "    device=None, model=model, batch=batch, stockmodel=stockmodel_test,\n",
        "    delta_t=dataset_mu_metadata[\"dt\"], T=dataset_mu_metadata[\"maturity\"],\n",
        "    path_to_plot=(0,1), reuse_cond_exp=False,)\n",
        "print('optimal loss (test): {}'.format(opt_loss))\n",
        "print('model loss   (test): {}'.format(current_model_loss))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xieO_jBkLbYD"
      },
      "source": [
        "# Generate new paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSkUTmKOJ5Qk"
      },
      "outputs": [],
      "source": [
        "def generate_next_value( X_t, mu_t, sigma_t, delta_t):\n",
        "   \"\"\"\n",
        "   Generate the next value in the time series using the Euler-Maruyama scheme.\n",
        "\n",
        "   :param X_t: current value tensor of shape (batch_size, d)\n",
        "   :param mu_t: drift coefficient tensor of shape (batch_size, d)\n",
        "   :param sigma_t: diffusion coefficient tensor of shape ( d, d)\n",
        "   :param delta_t: time difference float\n",
        "   :return: next value tensor of shape (batch_size, d)\n",
        "   \"\"\"\n",
        "   delta_Wt = torch.randn_like(X_t) * np.sqrt(delta_t)\n",
        "   delta_Wt_sigma_t = delta_Wt * sigma_t\n",
        "   X_t_next = X_t + mu_t * delta_t + delta_Wt_sigma_t\n",
        "   return X_t_next\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=1\n",
        "dim=1\n",
        "times=np.array([])\n",
        "time_ptr = np.array([0])\n",
        "obs_idx = torch.tensor([],dtype=torch.long)\n",
        "Z = torch.tensor([], dtype=torch.float)\n",
        "delta_t=0.01\n",
        "X= torch.tensor([], dtype=torch.float)\n",
        "start_X = torch.tensor([1.0, 1.0**2], dtype=torch.float).unsqueeze(0)\n",
        "start_X = start_X.repeat(batch_size, dim)\n",
        "n_obs_ot=torch.tensor([0]*batch_size, dtype=torch.float)\n",
        "count=0\n",
        "\n",
        "T=0.01\n",
        "pred1=model.get_pred(times, time_ptr, X, obs_idx, delta_t, T, start_X, n_obs_ot)[\"pred\"][-1]\n",
        "mu_hat = (pred1[:,0] - start_X[:,0])/delta_t\n",
        "sigma_hat =  (pred1[:,1] - start_X[:,0]**2)/delta_t - 2*start_X[:,0]*mu_hat"
      ],
      "metadata": {
        "id": "7cyAqd0ccV8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mu_hat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0PgGhWXccDm",
        "outputId": "8ed2fd2c-872f-4a96-a07a-eec09db3f3de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.6189], grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sigma_hat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9aplsTilxuF",
        "outputId": "cb76aaac-f392-4044-d347-d1c62fd2461c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([17.9515], grad_fn=<SubBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DG9Vl3kcymT"
      },
      "outputs": [],
      "source": [
        "batch_size=10\n",
        "dim=1\n",
        "times=np.array([])\n",
        "time_ptr = np.array([0])\n",
        "obs_idx = torch.tensor([],dtype=torch.long)\n",
        "delta_t=0.01\n",
        "X= torch.tensor([], dtype=torch.float)\n",
        "start_X_value = 1.0\n",
        "start_X = torch.tensor([[start_X_value, start_X_value**2]], dtype=torch.float).repeat(batch_size, 1)\n",
        "n_obs_ot=torch.tensor([0]*batch_size, dtype=torch.float)\n",
        "count=0\n",
        "for i in range(1, 101):\n",
        "\n",
        "    T=delta_t*i\n",
        "\n",
        "    pred=model.get_pred(times, time_ptr, X, obs_idx, delta_t, T, start_X, n_obs_ot)[\"pred\"][-1]\n",
        "\n",
        "    if i==1:\n",
        "        X_t=start_X\n",
        "    else:\n",
        "        X_t = X_next\n",
        "\n",
        "\n",
        "    mu_hat_t = (pred[:,0] - X_t[:,0])/delta_t\n",
        "    sigma_hat_t =  (pred[:,1] - X_t[:,0]*X_t[:,0])/delta_t - 2*X_t[:,0]*mu_hat_t\n",
        "\n",
        "\n",
        "    vol = torch.sqrt(sigma_hat_t)\n",
        "\n",
        "    X_next = generate_next_value(X_t[:,0].unsqueeze(1), mu_hat_t.unsqueeze(1), vol.unsqueeze(1), delta_t)\n",
        "    X_next = torch.cat((X_next, X_next**2), dim=1)\n",
        "\n",
        "\n",
        "    X=torch.cat((X, X_next), dim=0)\n",
        "    times=np.append(times, delta_t*i)\n",
        "    time_ptr = np.append(time_ptr, i*batch_size)\n",
        "    obs_idx=torch.cat((obs_idx, torch.arange(batch_size)))\n",
        "    n_obs_ot+=torch.tensor([1]*batch_size, dtype=torch.float)\n",
        "X_new1 = X.view(100, batch_size, 2).permute(1, 2, 0)\n",
        "start_X_expanded1 = start_X.unsqueeze(2)\n",
        "X_final1=torch.cat((start_X_expanded1, X_new1), dim=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gn33EjZerXzJ"
      },
      "source": [
        "## Parameter estimates and Graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJ0cCZOhMoBd"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "# Compare (visualize) paths\n",
        "def compare_path(x_real, x_fake, titles=[\"Real\", \"Fake\"], file_path=None, return_figax=False, dim=0, plot_size=100):\n",
        "    fig, ax = plt.subplots(1, 2, figsize=[12, 4], sharex=True, sharey=True)\n",
        "    ax[0].plot(\n",
        "        x_real[:plot_size].numpy().T,\n",
        "        alpha=0.3,\n",
        "        marker=\"o\",\n",
        "        linewidth=1,\n",
        "        markersize=1,\n",
        "    )\n",
        "\n",
        "    ax[1].plot(\n",
        "        x_fake[:plot_size].numpy().T,\n",
        "        alpha=0.3,\n",
        "        marker=\"o\",\n",
        "        linewidth=1,\n",
        "        markersize=1,\n",
        "    )\n",
        "\n",
        "    if titles:\n",
        "        ax[0].set_title(titles[0])\n",
        "        ax[1].set_title(titles[1])\n",
        "\n",
        "    for i in range(2):\n",
        "        ax[i].set_xlabel(\"Time\")\n",
        "        ax[i].set_ylabel(\"Prices\")\n",
        "    if return_figax:\n",
        "        return fig, ax\n",
        "    if file_path is None:\n",
        "        plt.show()\n",
        "    else:\n",
        "        fig.savefig(os.path.join(file_path, 'bs_term.png'))\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cwGo8fEhk1x"
      },
      "outputs": [],
      "source": [
        "def estimate_params(X, dt=0.01):\n",
        "  rets = np.log(X[:,1:]/X[:,:-1])\n",
        "  #rets=X[:,1:]/X[:,:-1]-1\n",
        "  r=rets.ravel()\n",
        "\n",
        "  m=np.mean(r)\n",
        "  s=np.std(r)\n",
        "\n",
        "  sigma=s/np.sqrt(dt)\n",
        "  mu=m/dt+0.5*sigma**2\n",
        "  return mu, sigma\n",
        "  #return m, s"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compare_path(torch.tensor(dataset_mu[0][:,0,:]),X_final1[:,0,:].detach(),plot_size=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "LMldHAAjojAW",
        "outputId": "3a1a307e-0fd2-4317-a889-6abc1e9a9569"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "AWGbMtWLl3m5",
        "outputId": "3d9e2b82-4079-4eec-c979-b3d052ee4178"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "compare_path(torch.tensor(dataset_mu[0][:,0,:]),X_final1[:,0,:].detach(),plot_size=10)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}