{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import torch\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T08:57:00.234087500Z",
     "start_time": "2025-03-05T08:57:00.213060100Z"
    }
   },
   "id": "10b312d428780de1"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import NJODE.train as train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T08:57:04.868133700Z",
     "start_time": "2025-03-05T08:57:04.839110Z"
    }
   },
   "id": "a91393b45f083b5b"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "import NJODE.data_utils as data_util"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T08:57:08.895987800Z",
     "start_time": "2025-03-05T08:57:08.876694200Z"
    }
   },
   "id": "342c847eff86a8e4"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "ode_nn=((50, \"tanh\"), (50, \"tanh\"))\n",
    "readout_nn=((50, \"tanh\"), (50, \"tanh\"))\n",
    "enc_nn=((50, \"tanh\"), (50, \"tanh\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-04T15:55:47.752401100Z",
     "start_time": "2025-03-04T15:55:47.732676800Z"
    }
   },
   "id": "e01bce452956fa87"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FBMmethod': 'daviesharte', 'S0': 1, 'correlation': 0.5, 'dimension': 1, 'drift': 0.5, 'dt': 0.01, 'hurst': 0.75, 'maturity': 1.0, 'mean': 0.5, 'model_name': 'OrnsteinUhlenbeck', 'nb_paths': 20000, 'nb_steps': 100, 'obs_perc': 0.1, 'poisson_lambda': 3.0, 'return_vol': False, 'scheme': 'euler', 'speed': 0.5, 'v0': 1, 'volatility': 0.2}\n",
      "using loss: standard\n",
      "neuralODE use input scaling with tanh\n",
      "use residual network: input_size=1, output_size=10\n",
      "use residual network: input_size=10, output_size=1\n",
      "model-id: None\n",
      "\n",
      "using CPU\n",
      "input_coords: [0]\n",
      "output_coords: [0]\n",
      "input_size: 1\n",
      "output_size: 1\n",
      "signature_coords: [0]\n",
      "optimal val-loss (achieved by true cond exp): 0.00374\n",
      "new model_id=5\n",
      "model params:\n",
      "{\"batch_size\": 100, \"bias\": true, \"data_dict\": {\"FBMmethod\": \"daviesharte\", \"S0\": 1, \"correlation\": 0.5, \"dimension\": 1, \"drift\": 0.5, \"dt\": 0.01, \"hurst\": 0.75, \"maturity\": 1.0, \"mean\": 0.5, \"model_name\": \"OrnsteinUhlenbeck\", \"nb_paths\": 20000, \"nb_steps\": 100, \"obs_perc\": 0.1, \"poisson_lambda\": 3.0, \"return_vol\": false, \"scheme\": \"euler\", \"speed\": 0.5, \"v0\": 1, \"volatility\": 0.2}, \"dataset\": \"OrnsteinUhlenbeck\", \"dataset_id\": 13, \"dropout_rate\": 0.1, \"enc_nn\": [[50, \"tanh\"], [50, \"tanh\"]], \"epochs\": 100, \"hidden_size\": 10, \"input_size\": 1, \"learning_rate\": 0.001, \"ode_nn\": [[50, \"tanh\"], [50, \"tanh\"]], \"optimal_val_loss\": 0.0037369800620581373, \"options\": {}, \"output_size\": 1, \"readout_nn\": [[50, \"tanh\"], [50, \"tanh\"]], \"seed\": 398, \"solver\": \"euler\", \"test_size\": 0.2, \"use_rnn\": false, \"weight\": 0.5, \"weight_decay\": 1.0}\n",
      "initiate new model ...\n",
      "\n",
      "model overview:\n",
      "NJODE(\n",
      "  (ode_f): ODEFunc(\n",
      "    (f): Sequential(\n",
      "      (0): Linear(in_features=13, out_features=50, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "      (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "      (4): Tanh()\n",
      "      (5): Dropout(p=0.1, inplace=False)\n",
      "      (6): Linear(in_features=50, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (encoder_map): FFNN(\n",
      "    (ffnn): Sequential(\n",
      "      (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "      (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "      (4): Tanh()\n",
      "      (5): Dropout(p=0.1, inplace=False)\n",
      "      (6): Linear(in_features=50, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (readout_map): FFNN(\n",
      "    (ffnn): Sequential(\n",
      "      (0): Linear(in_features=10, out_features=50, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "      (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "      (4): Tanh()\n",
      "      (5): Dropout(p=0.1, inplace=False)\n",
      "      (6): Linear(in_features=50, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ") \n",
      "\n",
      "# parameters=10071\n",
      "\n",
      "# trainable parameters=10071\n",
      "\n",
      "start training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160it [00:52,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating ...\n",
      "epoch 1, weight=0.50000, train-loss=0.01103, optimal-val-loss=0.00374, val-loss=0.00385, \n",
      "plotting ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gg868\\thesis\\NJODE\\train.py:986: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_metric = pd.concat([df_metric, df_m_app], ignore_index=True)\n",
      "C:\\Users\\gg868\\thesis\\NJODE\\train.py:997: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_metric = pd.concat([df_metric, df_m_app], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal test-loss (with current weight=0.50000): 0.00374\n",
      "model test-loss (with current weight=0.50000): 0.00385\n",
      "save model ...\n",
      "saved!\n",
      "save new best model: last-best-loss: inf, new-best-loss: 0.00385, epoch: 1\n",
      "saved!\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160it [00:39,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating ...\n",
      "epoch 2, weight=0.50000, train-loss=0.00596, optimal-val-loss=0.00374, val-loss=0.00404, \n",
      "plotting ...\n",
      "optimal test-loss (with current weight=0.50000): 0.00374\n",
      "model test-loss (with current weight=0.50000): 0.00404\n",
      "save model ...\n",
      "saved!\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160it [00:40,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating ...\n",
      "epoch 3, weight=0.50000, train-loss=0.00501, optimal-val-loss=0.00374, val-loss=0.00403, \n",
      "plotting ...\n",
      "optimal test-loss (with current weight=0.50000): 0.00374\n",
      "model test-loss (with current weight=0.50000): 0.00403\n",
      "save model ...\n",
      "saved!\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160it [00:58,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating ...\n",
      "epoch 4, weight=0.50000, train-loss=0.00510, optimal-val-loss=0.00374, val-loss=0.00392, \n",
      "plotting ...\n",
      "optimal test-loss (with current weight=0.50000): 0.00374\n",
      "model test-loss (with current weight=0.50000): 0.00392\n",
      "save model ...\n",
      "saved!\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160it [00:56,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating ...\n",
      "epoch 5, weight=0.50000, train-loss=0.00473, optimal-val-loss=0.00374, val-loss=0.00387, \n",
      "plotting ...\n",
      "optimal test-loss (with current weight=0.50000): 0.00374\n",
      "model test-loss (with current weight=0.50000): 0.00387\n",
      "save model ...\n",
      "saved!\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160it [00:51,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating ...\n",
      "epoch 6, weight=0.50000, train-loss=0.00429, optimal-val-loss=0.00374, val-loss=0.00383, \n",
      "plotting ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gg868\\thesis\\NJODE\\train.py:997: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_metric = pd.concat([df_metric, df_m_app], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal test-loss (with current weight=0.50000): 0.00374\n",
      "model test-loss (with current weight=0.50000): 0.00383\n",
      "save model ...\n",
      "saved!\n",
      "save new best model: last-best-loss: 0.00385, new-best-loss: 0.00383, epoch: 6\n",
      "saved!\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [00:16,  1.51it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtrain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43manomaly_detection\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_dataset_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_gpu\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnb_cpus\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msend\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgpu_num\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msave_every\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.001\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m398\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhidden_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdropout_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mode_nn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mode_nn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreadout_nn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreadout_nn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43menc_nn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43menc_nn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_rnn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43msolver\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43meuler\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1.\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mOrnsteinUhlenbeck\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdataset_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m13\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdataset_dic\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m    \u001B[49m\u001B[43mplot\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpaths_to_plot\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[43m    \u001B[49m\u001B[43mDEBUG\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\thesis\\NJODE\\train.py:851\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(anomaly_detection, n_dataset_workers, use_gpu, nb_cpus, send, gpu_num, model_id, epochs, batch_size, save_every, learning_rate, test_size, seed, hidden_size, bias, dropout_rate, ode_nn, readout_nn, enc_nn, use_rnn, solver, weight, weight_decay, dataset, dataset_id, data_dict, plot, paths_to_plot, saved_models_path, DEBUG, **options)\u001B[0m\n\u001B[0;32m    849\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    850\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m\n\u001B[1;32m--> 851\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# compute gradient of each weight regarding loss function\u001B[39;00m\n\u001B[0;32m    852\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m gradient_clip \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    853\u001B[0m     nn\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mclip_grad_value_(\n\u001B[0;32m    854\u001B[0m         model\u001B[38;5;241m.\u001B[39mparameters(), clip_value\u001B[38;5;241m=\u001B[39mgradient_clip)\n",
      "File \u001B[1;32mC:\\Program Files\\Miniconda3\\envs\\thesis\\lib\\site-packages\\torch\\_tensor.py:626\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    616\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    617\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    618\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    619\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    624\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    625\u001B[0m     )\n\u001B[1;32m--> 626\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    627\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    628\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\Miniconda3\\envs\\thesis\\lib\\site-packages\\torch\\autograd\\__init__.py:347\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    342\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    344\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    345\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    346\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 347\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    348\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    349\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    350\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    351\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    352\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    353\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    355\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\Miniconda3\\envs\\thesis\\lib\\site-packages\\torch\\autograd\\graph.py:823\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    821\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    822\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 823\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    824\u001B[0m         t_outputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    825\u001B[0m     )  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    826\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    827\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "train.train(\n",
    "    anomaly_detection=None, n_dataset_workers=None, use_gpu=None,\n",
    "    nb_cpus=None, send=None, gpu_num=0,\n",
    "    model_id=None, epochs=100, batch_size=100, save_every=1,\n",
    "    learning_rate=0.001, test_size=0.2, seed=398,\n",
    "    hidden_size=10, bias=True, dropout_rate=0.1,\n",
    "    ode_nn=ode_nn, readout_nn=readout_nn,\n",
    "    enc_nn=enc_nn, use_rnn=False,\n",
    "    solver=\"euler\", weight=0.5, weight_decay=1.,\n",
    "    dataset=\"OrnsteinUhlenbeck\",\n",
    "    dataset_id=13, data_dict=dataset_dic,\n",
    "    plot=True, paths_to_plot=(0,),\n",
    "    DEBUG=0,)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-04T16:03:45.840855100Z",
     "start_time": "2025-03-04T15:58:12.546800700Z"
    }
   },
   "id": "c19dcf104d7d7f34"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8f8a6a9557ec9fa4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
